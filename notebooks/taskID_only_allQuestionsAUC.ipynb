{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pprint as pp\n",
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code can work with tf.VERSION = '1.4.1' (for MacOS High Sierra); functions may change for other versions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_split = 0.8\n",
    "validation_set_split = 0.1\n",
    "learning_rate = np.logspace(-5,0,5)\n",
    "num_units = 50 #number of units in RNN cell\n",
    "training_steps = 40 #number of epochs\n",
    "display_step = 20 #number of epochs after which to display progress\n",
    "optimize_using = \"adam\" #other option: \"momentum\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 1.4.1\n"
     ]
    }
   ],
   "source": [
    "print(\"Tensorflow version: \" + str(tf.VERSION))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading JSON file into dictionary called 'student_vectors'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"../data/student_vectors_n_task_10_n_limit_10000.json\"\n",
    "student_vectors = json.load(open(filepath))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecting unique CCSSM labels and Task IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique task IDs: 10\n",
      "Number of students: 1255\n"
     ]
    }
   ],
   "source": [
    "task_ids = []\n",
    "for i in student_vectors:\n",
    "    for j in student_vectors[i]:\n",
    "        if j['task_id'] not in task_ids:\n",
    "            task_ids.append(j['task_id'])\n",
    "print(\"Number of unique task IDs: \" + str(len(task_ids)))\n",
    "print(\"Number of students: \" + str(len(student_vectors)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating 1-hot encoding for Task IDs and CCSSM Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-processing for using MultiLabelBinarizer\n",
    "temp_ids = []\n",
    "for i in task_ids:\n",
    "    temp_ids.append([i])\n",
    "\n",
    "#generating encodings\n",
    "enc = MultiLabelBinarizer()\n",
    "task_ids_1hot = (enc.fit_transform(temp_ids)).astype(float)\n",
    "task_ids_classes = enc.classes_\n",
    "task_ids_dict = dict(zip(task_ids, task_ids_1hot))\n",
    "# print(\"\\n1-hot encoding for task IDs:\")\n",
    "# pp.pprint(task_ids_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating input sequences of interactions to feed the network. Say we have 3 task IDs; here is an example of interaction vectors generated:\n",
    "1. User correctly solves task 2 of label 3: [010   000]\n",
    "2. User incorrectly solves task 1 of label 2: [000   100]\n",
    "\n",
    "1-hot representation of task IDs: \n",
    "task ID 1: 1,0,0\n",
    "task ID 2: 0,1,0\n",
    "task ID 3: 0,0,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = []\n",
    "output_y_taskid = []\n",
    "output_y = []\n",
    "seqlen = []\n",
    "incorrect_tid_vec = np.zeros((len(task_ids)), dtype=np.float)\n",
    "for i in student_vectors:\n",
    "    temp_seq = []\n",
    "    for j in student_vectors[i]:\n",
    "        if(j['second_try'] == False): #ignoring second_try\n",
    "            if(j['correct'] == True):\n",
    "                vec = np.concatenate([task_ids_dict[j['task_id']],incorrect_tid_vec])\n",
    "                temp_seq.append(vec)\n",
    "            else:\n",
    "                vec = np.concatenate([incorrect_tid_vec,task_ids_dict[j['task_id']]])\n",
    "                temp_seq.append(vec)\n",
    "    seqlen.append(len(temp_seq))\n",
    "    last_one = temp_seq.pop() #remove last interaction vector\n",
    "    sequences.append(temp_seq) #add it to x\n",
    "    first_one = temp_seq.pop(0) #remove first interaction vector\n",
    "    temp_seq.append(last_one)\n",
    "    output_y.append(temp_seq) #concatenate with last vector, and append to output!\n",
    "    output_y_taskid.append(temp_seq)\n",
    "    \n",
    "# print(\"Sample interaction vector: \")\n",
    "# pp.pprint(sequences[0][0])\n",
    "length_interaction_vector = 2*(len(task_ids)) #length of interaction vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding maximum sequence length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sequence length: 186\n"
     ]
    }
   ],
   "source": [
    "max_seqlen = max(seqlen)\n",
    "print(\"Maximum sequence length: \"+str(max_seqlen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Padding the sequences according to maximum sequence length. Making padded sequences of shape: number of students, maximum sequence length, length of interaction vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequences have been padded according to the maximum sequence length. Final shape: (1255, 186, 20)\n"
     ]
    }
   ],
   "source": [
    "padded_sequences = np.zeros(shape=(len(student_vectors),max_seqlen,length_interaction_vector),dtype=float)\n",
    "for i in range(len(sequences)):\n",
    "    for j in range(len(sequences[i])):\n",
    "        padded_sequences[i][j] = sequences[i][j]\n",
    "print(\"Sequences have been padded according to the maximum sequence length. Final shape: \" + str(padded_sequences.shape))\n",
    "\n",
    "padded_output = np.zeros(shape=(len(student_vectors),max_seqlen,length_interaction_vector),dtype=float)\n",
    "for i in range(len(output_y)):\n",
    "    for j in range(len(output_y[i])):\n",
    "        padded_output[i][j] = output_y[i][j]\n",
    "        \n",
    "padded_output_taskid = np.zeros(shape=(len(student_vectors),max_seqlen,length_interaction_vector),dtype=float)\n",
    "for i in range(len(output_y_taskid)):\n",
    "    for j in range(len(output_y_taskid[i])):\n",
    "        padded_output_taskid[i][j] = output_y_taskid[i][j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into training and testing sets. Will take random validation sets at the time of training.<br>\n",
    "Review: **Try using sklearn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting 1255 rows into 1005 for training, 125 for validation and 125 for testing.\n",
      "Implemented 9-fold cross validation.\n"
     ]
    }
   ],
   "source": [
    "split = round((training_set_split+validation_set_split)*len(student_vectors))\n",
    "\n",
    "#separating training & validation set\n",
    "training_x = padded_sequences[:split]\n",
    "training_y = np.asarray(padded_output)[:split]\n",
    "training_y_taskid = np.asarray(padded_output_taskid)[:split]\n",
    "training_seqlen = seqlen[:split]\n",
    "\n",
    "#generating validation and training sets by implementing k-fold cross validation (k = maximum_position)\n",
    "validation_set_size = math.floor(validation_set_split * len(student_vectors))\n",
    "training_set_size = len(training_x) - validation_set_size\n",
    "maximum_position = math.floor(len(training_x) / validation_set_size)\n",
    "\n",
    "def get_next_train_valid_set(position):\n",
    "    if(position>=maximum_position):\n",
    "        position = position % maximum_position\n",
    "    print(\"Picking validation set from position: \"+str(position))\n",
    "    valid_start = position*validation_set_size\n",
    "    valid_end = valid_start + validation_set_size\n",
    "    \n",
    "    valid_set_x = training_x[valid_start : valid_end]\n",
    "    valid_set_y = training_y[valid_start : valid_end]\n",
    "    valid_set_y_taskid = np.asarray(training_y_taskid)[valid_start : valid_end]\n",
    "    valid_set_seqlen = np.asarray(training_seqlen[valid_start:valid_end])\n",
    "    \n",
    "    train_set_x = np.concatenate((training_x[:valid_start], training_x[valid_end:]))\n",
    "    train_set_y = np.concatenate((training_y[:valid_start], training_y[valid_end:]))\n",
    "    train_set_y_taskid = np.concatenate((np.asarray(training_y_taskid)[:valid_start], np.asarray(training_y_taskid)[valid_end:]))\n",
    "    train_set_seqlen = np.concatenate((np.asarray(training_seqlen)[:valid_start],np.asarray(training_seqlen)[valid_end:]))\n",
    "    \n",
    "    if(len(train_set_x) != training_set_size): #test\n",
    "        print(\"that's not good it is:\")\n",
    "        print(train_set_x.shape)\n",
    "    \n",
    "    return (train_set_seqlen,valid_set_seqlen,valid_set_x,valid_set_y,valid_set_y_taskid,train_set_x,train_set_y,train_set_y_taskid)\n",
    "\n",
    "#separating test set\n",
    "test_x = padded_sequences[split:]\n",
    "test_y = np.asarray(padded_output)[split:]\n",
    "test_y_taskid = np.asarray(padded_output_taskid)[split:]\n",
    "test_seqlen = seqlen[split:]\n",
    "\n",
    "print(\"Splitting \"+str(len(student_vectors))+\" rows into \"+str(training_set_size)+ \" for training, \"+str(validation_set_size)+\" for validation and \"+str(len(test_x)) + \" for testing.\")\n",
    "print(\"Implemented \"+str(maximum_position)+\"-fold cross validation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "#defining placeholders\n",
    "x = tf.placeholder(tf.float32, [None, max_seqlen, length_interaction_vector]) #(<batch_size>, <max_time>, <num_features>)\n",
    "y = tf.placeholder(tf.float32, [None, max_seqlen, length_interaction_vector]) #(<batch_size>, <num_features>)\n",
    "y_taskid = tf.placeholder(tf.float32, [None, max_seqlen, length_interaction_vector])\n",
    "seqlen_tf = tf.placeholder(tf.float32,[None])\n",
    "\n",
    "#defining tensorflow variables\n",
    "learning_tf_rate = tf.Variable(0.0, name=\"learning_tf_rate\",dtype=tf.float32)\n",
    "\n",
    "#dynamic RNN definition\n",
    "def dynamicRNN(x):\n",
    "    rnn_cell = tf.nn.rnn_cell.BasicLSTMCell(num_units)\n",
    "    outputs, states = tf.nn.dynamic_rnn(rnn_cell, x, dtype=tf.float32,sequence_length=seqlen_tf)\n",
    "    \n",
    "    #transformation on outputs needed, otherwise auc=0\n",
    "    #outputs = tf.transpose(outputs, [1, 0, 2])\n",
    "    out_size = length_interaction_vector\n",
    "    logit = tf.contrib.layers.fully_connected(outputs, out_size)\n",
    "    outputs = tf.nn.sigmoid(logit)\n",
    "    return outputs\n",
    "\n",
    "#making predictions\n",
    "pred = dynamicRNN(x)\n",
    "    \n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "if(optimize_using == \"momentum\"):\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate=learning_tf_rate,momentum=0.9).minimize(cost)\n",
    "elif (optimize_using == \"adagrad\"):\n",
    "    optimizer = tf.train.AdagradOptimizer(learning_rate=learning_tf_rate).minimize(cost)\n",
    "elif (optimize_using == \"adam\"):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_tf_rate).minimize(cost)\n",
    "    \n",
    "\n",
    "# Evaluate model - use AUC to evaluate model\n",
    "auc,  opts = tf.metrics.auc(labels = y_taskid, predictions = pred, curve='ROC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model for hyperparameter (learning rate) tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-fold cross-validation\n",
      "Current Learning Rate: 1e-05\n",
      "Picking validation set from position: 0\n",
      "Step 1, Loss = 0.9667708, Learning Rate = 1e-05, Train AUC:0.7380419\n",
      "Step 20, Loss = 0.9667416, Learning Rate = 1e-05, Train AUC:0.73790866\n",
      "Step 40, Loss = 0.9667096, Learning Rate = 1e-05, Train AUC:0.7376664\n",
      "Valid_auc_taskid: 0.73776305 with k = 1\n",
      "Optimization Finished!\n",
      "2-fold cross-validation\n",
      "Current Learning Rate: 1e-05\n",
      "Picking validation set from position: 1\n",
      "Step 1, Loss = 0.9666594, Learning Rate = 1e-05, Train AUC:0.63231206\n",
      "Step 20, Loss = 0.9666199, Learning Rate = 1e-05, Train AUC:0.63070047\n",
      "Step 40, Loss = 0.966586, Learning Rate = 1e-05, Train AUC:0.62925243\n",
      "Valid_auc_taskid: 0.6283644 with k = 2\n",
      "Optimization Finished!\n",
      "3-fold cross-validation\n",
      "Current Learning Rate: 1e-05\n",
      "Picking validation set from position: 2\n",
      "Step 1, Loss = 0.9665316, Learning Rate = 1e-05, Train AUC:0.62026703\n",
      "Step 20, Loss = 0.9665024, Learning Rate = 1e-05, Train AUC:0.6197806\n",
      "Step 40, Loss = 0.96647424, Learning Rate = 1e-05, Train AUC:0.61880815\n",
      "Valid_auc_taskid: 0.61863613 with k = 3\n",
      "Optimization Finished!\n",
      "4-fold cross-validation\n",
      "Current Learning Rate: 1e-05\n",
      "Picking validation set from position: 3\n",
      "Step 1, Loss = 0.966617, Learning Rate = 1e-05, Train AUC:0.7262423\n",
      "Step 20, Loss = 0.96659136, Learning Rate = 1e-05, Train AUC:0.7245219\n",
      "Step 40, Loss = 0.96656317, Learning Rate = 1e-05, Train AUC:0.72246456\n",
      "Valid_auc_taskid: 0.7223149 with k = 4\n",
      "Optimization Finished!\n",
      "5-fold cross-validation\n",
      "Current Learning Rate: 1e-05\n",
      "Picking validation set from position: 4\n",
      "Step 1, Loss = 0.9665634, Learning Rate = 1e-05, Train AUC:0.6679056\n",
      "Step 20, Loss = 0.9665396, Learning Rate = 1e-05, Train AUC:0.6676091\n",
      "Step 40, Loss = 0.9665122, Learning Rate = 1e-05, Train AUC:0.6673054\n",
      "Valid_auc_taskid: 0.667559 with k = 5\n",
      "Optimization Finished!\n",
      "6-fold cross-validation\n",
      "Current Learning Rate: 1e-05\n",
      "Picking validation set from position: 5\n",
      "Step 1, Loss = 0.9668911, Learning Rate = 1e-05, Train AUC:0.7752132\n",
      "Step 20, Loss = 0.96685714, Learning Rate = 1e-05, Train AUC:0.77314645\n",
      "Step 40, Loss = 0.96682435, Learning Rate = 1e-05, Train AUC:0.7717281\n",
      "Valid_auc_taskid: 0.7712974 with k = 6\n",
      "Optimization Finished!\n",
      "7-fold cross-validation\n",
      "Current Learning Rate: 1e-05\n",
      "Picking validation set from position: 6\n",
      "Step 1, Loss = 0.9664996, Learning Rate = 1e-05, Train AUC:0.62690914\n",
      "Step 20, Loss = 0.9664662, Learning Rate = 1e-05, Train AUC:0.6255097\n",
      "Step 40, Loss = 0.96643305, Learning Rate = 1e-05, Train AUC:0.62448734\n",
      "Valid_auc_taskid: 0.62417984 with k = 7\n",
      "Optimization Finished!\n",
      "8-fold cross-validation\n",
      "Current Learning Rate: 1e-05\n",
      "Picking validation set from position: 7\n",
      "Step 1, Loss = 0.96684617, Learning Rate = 1e-05, Train AUC:0.6584728\n",
      "Step 20, Loss = 0.966814, Learning Rate = 1e-05, Train AUC:0.6573965\n",
      "Step 40, Loss = 0.9667784, Learning Rate = 1e-05, Train AUC:0.6562895\n",
      "Valid_auc_taskid: 0.65565294 with k = 8\n",
      "Optimization Finished!\n",
      "9-fold cross-validation\n",
      "Current Learning Rate: 1e-05\n",
      "Picking validation set from position: 8\n",
      "Step 1, Loss = 0.9662617, Learning Rate = 1e-05, Train AUC:0.617665\n",
      "Step 20, Loss = 0.96623564, Learning Rate = 1e-05, Train AUC:0.61742616\n",
      "Step 40, Loss = 0.9662121, Learning Rate = 1e-05, Train AUC:0.61713785\n",
      "Valid_auc_taskid: 0.61766416 with k = 9\n",
      "Optimization Finished!\n",
      "Train_auc_taskid: 0.61777484\n",
      "Average Valid_auc_taskid: 0.67149246\n",
      "1-fold cross-validation\n",
      "Current Learning Rate: 0.00017782794\n",
      "Picking validation set from position: 0\n",
      "Step 1, Loss = 0.96693206, Learning Rate = 0.00017782794, Train AUC:0.66688573\n",
      "Step 20, Loss = 0.96639305, Learning Rate = 0.00017782794, Train AUC:0.65429604\n",
      "Step 40, Loss = 0.96603405, Learning Rate = 0.00017782794, Train AUC:0.64260745\n",
      "Valid_auc_taskid: 0.64200896 with k = 1\n",
      "Optimization Finished!\n",
      "2-fold cross-validation\n",
      "Current Learning Rate: 0.00017782794\n",
      "Picking validation set from position: 1\n",
      "Step 1, Loss = 0.966312, Learning Rate = 0.00017782794, Train AUC:0.64011306\n",
      "Step 20, Loss = 0.9659752, Learning Rate = 0.00017782794, Train AUC:0.6333059\n",
      "Step 40, Loss = 0.96577525, Learning Rate = 0.00017782794, Train AUC:0.6250976\n",
      "Valid_auc_taskid: 0.6249462 with k = 2\n",
      "Optimization Finished!\n",
      "3-fold cross-validation\n",
      "Current Learning Rate: 0.00017782794\n",
      "Picking validation set from position: 2\n",
      "Step 1, Loss = 0.9666119, Learning Rate = 0.00017782794, Train AUC:0.7754646\n",
      "Step 20, Loss = 0.9661635, Learning Rate = 0.00017782794, Train AUC:0.7543316\n",
      "Step 40, Loss = 0.96589065, Learning Rate = 0.00017782794, Train AUC:0.74106413\n",
      "Valid_auc_taskid: 0.73995167 with k = 3\n",
      "Optimization Finished!\n",
      "4-fold cross-validation\n",
      "Current Learning Rate: 0.00017782794\n",
      "Picking validation set from position: 3\n",
      "Step 1, Loss = 0.9664636, Learning Rate = 0.00017782794, Train AUC:0.6638817\n",
      "Step 20, Loss = 0.96610004, Learning Rate = 0.00017782794, Train AUC:0.6555071\n",
      "Step 40, Loss = 0.96583796, Learning Rate = 0.00017782794, Train AUC:0.6509691\n",
      "Valid_auc_taskid: 0.65029436 with k = 4\n",
      "Optimization Finished!\n",
      "5-fold cross-validation\n",
      "Current Learning Rate: 0.00017782794\n",
      "Picking validation set from position: 4\n",
      "Step 1, Loss = 0.96649015, Learning Rate = 0.00017782794, Train AUC:0.72521925\n",
      "Step 20, Loss = 0.9661503, Learning Rate = 0.00017782794, Train AUC:0.7162172\n",
      "Step 40, Loss = 0.96590865, Learning Rate = 0.00017782794, Train AUC:0.7048029\n",
      "Valid_auc_taskid: 0.70429593 with k = 5\n",
      "Optimization Finished!\n",
      "6-fold cross-validation\n",
      "Current Learning Rate: 0.00017782794\n",
      "Picking validation set from position: 5\n",
      "Step 1, Loss = 0.9668103, Learning Rate = 0.00017782794, Train AUC:0.6920486\n",
      "Step 20, Loss = 0.9662873, Learning Rate = 0.00017782794, Train AUC:0.68311024\n",
      "Step 40, Loss = 0.965973, Learning Rate = 0.00017782794, Train AUC:0.674011\n",
      "Valid_auc_taskid: 0.67285 with k = 6\n",
      "Optimization Finished!\n",
      "7-fold cross-validation\n",
      "Current Learning Rate: 0.00017782794\n",
      "Picking validation set from position: 6\n",
      "Step 1, Loss = 0.96681184, Learning Rate = 0.00017782794, Train AUC:0.77502155\n",
      "Step 20, Loss = 0.96631294, Learning Rate = 0.00017782794, Train AUC:0.7657758\n",
      "Step 40, Loss = 0.9659452, Learning Rate = 0.00017782794, Train AUC:0.75215787\n",
      "Valid_auc_taskid: 0.7520121 with k = 7\n",
      "Optimization Finished!\n",
      "8-fold cross-validation\n",
      "Current Learning Rate: 0.00017782794\n",
      "Picking validation set from position: 7\n",
      "Step 1, Loss = 0.9665412, Learning Rate = 0.00017782794, Train AUC:0.68194735\n",
      "Step 20, Loss = 0.966067, Learning Rate = 0.00017782794, Train AUC:0.6658577\n",
      "Step 40, Loss = 0.96578336, Learning Rate = 0.00017782794, Train AUC:0.64880514\n",
      "Valid_auc_taskid: 0.64684296 with k = 8\n",
      "Optimization Finished!\n",
      "9-fold cross-validation\n",
      "Current Learning Rate: 0.00017782794\n",
      "Picking validation set from position: 8\n",
      "Step 1, Loss = 0.96661, Learning Rate = 0.00017782794, Train AUC:0.68534464\n",
      "Step 20, Loss = 0.9661365, Learning Rate = 0.00017782794, Train AUC:0.6814323\n",
      "Step 40, Loss = 0.96585524, Learning Rate = 0.00017782794, Train AUC:0.6746779\n",
      "Valid_auc_taskid: 0.6725 with k = 9\n",
      "Optimization Finished!\n",
      "Train_auc_taskid: 0.6683642\n",
      "Average Valid_auc_taskid: 0.67841136\n",
      "1-fold cross-validation\n",
      "Current Learning Rate: 0.0031622776\n",
      "Picking validation set from position: 0\n",
      "Step 1, Loss = 0.96637094, Learning Rate = 0.0031622776, Train AUC:0.6305267\n",
      "Step 20, Loss = 0.9656417, Learning Rate = 0.0031622776, Train AUC:0.5993546\n",
      "Step 40, Loss = 0.96562684, Learning Rate = 0.0031622776, Train AUC:0.5899098\n",
      "Valid_auc_taskid: 0.5890487 with k = 1\n",
      "Optimization Finished!\n",
      "2-fold cross-validation\n",
      "Current Learning Rate: 0.0031622776\n",
      "Picking validation set from position: 1\n",
      "Step 1, Loss = 0.96634716, Learning Rate = 0.0031622776, Train AUC:0.6487908\n",
      "Step 20, Loss = 0.9656573, Learning Rate = 0.0031622776, Train AUC:0.6089989\n",
      "Step 40, Loss = 0.9656447, Learning Rate = 0.0031622776, Train AUC:0.5999511\n",
      "Valid_auc_taskid: 0.5994026 with k = 2\n",
      "Optimization Finished!\n",
      "3-fold cross-validation\n",
      "Current Learning Rate: 0.0031622776\n",
      "Picking validation set from position: 2\n",
      "Step 1, Loss = 0.96627307, Learning Rate = 0.0031622776, Train AUC:0.6476394\n",
      "Step 20, Loss = 0.9656402, Learning Rate = 0.0031622776, Train AUC:0.60534436\n",
      "Step 40, Loss = 0.96561134, Learning Rate = 0.0031622776, Train AUC:0.59170914\n",
      "Valid_auc_taskid: 0.5907042 with k = 3\n",
      "Optimization Finished!\n",
      "4-fold cross-validation\n",
      "Current Learning Rate: 0.0031622776\n",
      "Picking validation set from position: 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, Loss = 0.96632236, Learning Rate = 0.0031622776, Train AUC:0.6269261\n",
      "Step 20, Loss = 0.96559155, Learning Rate = 0.0031622776, Train AUC:0.56347305\n",
      "Step 40, Loss = 0.96559155, Learning Rate = 0.0031622776, Train AUC:0.54230756\n",
      "Valid_auc_taskid: 0.54067075 with k = 4\n",
      "Optimization Finished!\n",
      "5-fold cross-validation\n",
      "Current Learning Rate: 0.0031622776\n",
      "Picking validation set from position: 4\n",
      "Step 1, Loss = 0.9662424, Learning Rate = 0.0031622776, Train AUC:0.63925016\n",
      "Step 20, Loss = 0.96561134, Learning Rate = 0.0031622776, Train AUC:0.5751304\n",
      "Step 40, Loss = 0.96560794, Learning Rate = 0.0031622776, Train AUC:0.5542335\n",
      "Valid_auc_taskid: 0.5525202 with k = 5\n",
      "Optimization Finished!\n",
      "6-fold cross-validation\n",
      "Current Learning Rate: 0.0031622776\n",
      "Picking validation set from position: 5\n",
      "Step 1, Loss = 0.96640074, Learning Rate = 0.0031622776, Train AUC:0.5544811\n",
      "Step 20, Loss = 0.9656537, Learning Rate = 0.0031622776, Train AUC:0.5333892\n",
      "Step 40, Loss = 0.9656536, Learning Rate = 0.0031622776, Train AUC:0.5314959\n",
      "Valid_auc_taskid: 0.5312874 with k = 6\n",
      "Optimization Finished!\n",
      "7-fold cross-validation\n",
      "Current Learning Rate: 0.0031622776\n",
      "Picking validation set from position: 6\n",
      "Step 1, Loss = 0.9660956, Learning Rate = 0.0031622776, Train AUC:0.5735272\n",
      "Step 20, Loss = 0.96553147, Learning Rate = 0.0031622776, Train AUC:0.56673825\n",
      "Step 40, Loss = 0.96551895, Learning Rate = 0.0031622776, Train AUC:0.5645581\n",
      "Valid_auc_taskid: 0.5646521 with k = 7\n",
      "Optimization Finished!\n",
      "8-fold cross-validation\n",
      "Current Learning Rate: 0.0031622776\n",
      "Picking validation set from position: 7\n",
      "Step 1, Loss = 0.9661868, Learning Rate = 0.0031622776, Train AUC:0.62580836\n",
      "Step 20, Loss = 0.96558124, Learning Rate = 0.0031622776, Train AUC:0.59627235\n",
      "Step 40, Loss = 0.96556497, Learning Rate = 0.0031622776, Train AUC:0.5883964\n",
      "Valid_auc_taskid: 0.58790725 with k = 8\n",
      "Optimization Finished!\n",
      "9-fold cross-validation\n",
      "Current Learning Rate: 0.0031622776\n",
      "Picking validation set from position: 8\n",
      "Step 1, Loss = 0.9660587, Learning Rate = 0.0031622776, Train AUC:0.698414\n",
      "Step 20, Loss = 0.9655157, Learning Rate = 0.0031622776, Train AUC:0.66573226\n",
      "Step 40, Loss = 0.9654547, Learning Rate = 0.0031622776, Train AUC:0.6749023\n",
      "Valid_auc_taskid: 0.6760029 with k = 9\n",
      "Optimization Finished!\n",
      "Train_auc_taskid: 0.6805545\n",
      "Average Valid_auc_taskid: 0.5813551\n",
      "1-fold cross-validation\n",
      "Current Learning Rate: 0.056234132\n",
      "Picking validation set from position: 0\n",
      "Step 1, Loss = 0.9661853, Learning Rate = 0.056234132, Train AUC:0.7330726\n",
      "Step 20, Loss = 0.9656448, Learning Rate = 0.056234132, Train AUC:0.6167962\n",
      "Step 40, Loss = 0.9656448, Learning Rate = 0.056234132, Train AUC:0.5779218\n",
      "Valid_auc_taskid: 0.5745871 with k = 1\n",
      "Optimization Finished!\n",
      "2-fold cross-validation\n",
      "Current Learning Rate: 0.056234132\n",
      "Picking validation set from position: 1\n",
      "Step 1, Loss = 0.96567124, Learning Rate = 0.056234132, Train AUC:0.57684225\n",
      "Step 20, Loss = 0.9656593, Learning Rate = 0.056234132, Train AUC:0.5384174\n",
      "Step 40, Loss = 0.9656593, Learning Rate = 0.056234132, Train AUC:0.52561074\n",
      "Valid_auc_taskid: 0.5244903 with k = 2\n",
      "Optimization Finished!\n",
      "3-fold cross-validation\n",
      "Current Learning Rate: 0.056234132\n",
      "Picking validation set from position: 2\n",
      "Step 1, Loss = 0.96571547, Learning Rate = 0.056234132, Train AUC:0.5761261\n",
      "Step 20, Loss = 0.9656422, Learning Rate = 0.056234132, Train AUC:0.538088\n",
      "Step 40, Loss = 0.9656422, Learning Rate = 0.056234132, Train AUC:0.5253976\n",
      "Valid_auc_taskid: 0.52431613 with k = 3\n",
      "Optimization Finished!\n",
      "4-fold cross-validation\n",
      "Current Learning Rate: 0.056234132\n",
      "Picking validation set from position: 3\n",
      "Step 1, Loss = 0.9656096, Learning Rate = 0.056234132, Train AUC:0.5262192\n",
      "Step 20, Loss = 0.96559155, Learning Rate = 0.056234132, Train AUC:0.51311165\n",
      "Step 40, Loss = 0.96559155, Learning Rate = 0.056234132, Train AUC:0.5087415\n",
      "Valid_auc_taskid: 0.5084018 with k = 4\n",
      "Optimization Finished!\n",
      "5-fold cross-validation\n",
      "Current Learning Rate: 0.056234132\n",
      "Picking validation set from position: 4\n",
      "Step 1, Loss = 0.9656263, Learning Rate = 0.056234132, Train AUC:0.50242054\n",
      "Step 20, Loss = 0.965612, Learning Rate = 0.056234132, Train AUC:0.50120896\n",
      "Step 40, Loss = 0.965612, Learning Rate = 0.056234132, Train AUC:0.50080574\n",
      "Valid_auc_taskid: 0.5007729 with k = 5\n",
      "Optimization Finished!\n",
      "6-fold cross-validation\n",
      "Current Learning Rate: 0.056234132\n",
      "Picking validation set from position: 5\n",
      "Step 1, Loss = 0.9656541, Learning Rate = 0.056234132, Train AUC:0.5015163\n",
      "Step 20, Loss = 0.9656536, Learning Rate = 0.056234132, Train AUC:0.5007582\n",
      "Step 40, Loss = 0.9656536, Learning Rate = 0.056234132, Train AUC:0.50050545\n",
      "Valid_auc_taskid: 0.50048345 with k = 6\n",
      "Optimization Finished!\n",
      "7-fold cross-validation\n",
      "Current Learning Rate: 0.056234132\n",
      "Picking validation set from position: 6\n",
      "Step 1, Loss = 0.9659541, Learning Rate = 0.056234132, Train AUC:0.6301946\n",
      "Step 20, Loss = 0.96553415, Learning Rate = 0.056234132, Train AUC:0.56546736\n",
      "Step 40, Loss = 0.96553415, Learning Rate = 0.056234132, Train AUC:0.5437273\n",
      "Valid_auc_taskid: 0.5422317 with k = 7\n",
      "Optimization Finished!\n",
      "8-fold cross-validation\n",
      "Current Learning Rate: 0.056234132\n",
      "Picking validation set from position: 7\n",
      "Step 1, Loss = 0.9656137, Learning Rate = 0.056234132, Train AUC:0.49846575\n",
      "Step 20, Loss = 0.9655815, Learning Rate = 0.056234132, Train AUC:0.4992332\n",
      "Step 40, Loss = 0.9655815, Learning Rate = 0.056234132, Train AUC:0.4994888\n",
      "Valid_auc_taskid: 0.49950954 with k = 8\n",
      "Optimization Finished!\n",
      "9-fold cross-validation\n",
      "Current Learning Rate: 0.056234132\n",
      "Picking validation set from position: 8\n",
      "Step 1, Loss = 0.96590585, Learning Rate = 0.056234132, Train AUC:0.57354814\n",
      "Step 20, Loss = 0.96552414, Learning Rate = 0.056234132, Train AUC:0.53661156\n",
      "Step 40, Loss = 0.96552414, Learning Rate = 0.056234132, Train AUC:0.5243715\n",
      "Valid_auc_taskid: 0.52356124 with k = 9\n",
      "Optimization Finished!\n",
      "Train_auc_taskid: 0.5173698\n",
      "Average Valid_auc_taskid: 0.5220394\n",
      "1-fold cross-validation\n",
      "Current Learning Rate: 1.0\n",
      "Picking validation set from position: 0\n",
      "Step 1, Loss = 0.9657543, Learning Rate = 1.0, Train AUC:0.49955624\n",
      "Step 20, Loss = 0.9656448, Learning Rate = 1.0, Train AUC:0.49977824\n",
      "Step 40, Loss = 0.9656448, Learning Rate = 1.0, Train AUC:0.49985218\n",
      "Valid_auc_taskid: 0.4998577 with k = 1\n",
      "Optimization Finished!\n",
      "2-fold cross-validation\n",
      "Current Learning Rate: 1.0\n",
      "Picking validation set from position: 1\n",
      "Step 1, Loss = 0.970057, Learning Rate = 1.0, Train AUC:0.61518484\n",
      "Step 20, Loss = 0.9656593, Learning Rate = 1.0, Train AUC:0.5576729\n",
      "Step 40, Loss = 0.9656593, Learning Rate = 1.0, Train AUC:0.5384667\n",
      "Valid_auc_taskid: 0.53676444 with k = 2\n",
      "Optimization Finished!\n",
      "3-fold cross-validation\n",
      "Current Learning Rate: 1.0\n",
      "Picking validation set from position: 2\n",
      "Step 1, Loss = 0.9679935, Learning Rate = 1.0, Train AUC:0.5822338\n",
      "Step 20, Loss = 0.9656422, Learning Rate = 1.0, Train AUC:0.54105407\n",
      "Step 40, Loss = 0.9656422, Learning Rate = 1.0, Train AUC:0.5273553\n",
      "Valid_auc_taskid: 0.5261865 with k = 3\n",
      "Optimization Finished!\n",
      "4-fold cross-validation\n",
      "Current Learning Rate: 1.0\n",
      "Picking validation set from position: 3\n",
      "Step 1, Loss = 0.96559155, Learning Rate = 1.0, Train AUC:0.5\n",
      "Step 20, Loss = 0.96559155, Learning Rate = 1.0, Train AUC:0.5\n",
      "Step 40, Loss = 0.96559155, Learning Rate = 1.0, Train AUC:0.5\n",
      "Valid_auc_taskid: 0.5 with k = 4\n",
      "Optimization Finished!\n",
      "5-fold cross-validation\n",
      "Current Learning Rate: 1.0\n",
      "Picking validation set from position: 4\n",
      "Step 1, Loss = 0.9687023, Learning Rate = 1.0, Train AUC:0.6081498\n",
      "Step 20, Loss = 0.965612, Learning Rate = 1.0, Train AUC:0.5539411\n",
      "Step 40, Loss = 0.965612, Learning Rate = 1.0, Train AUC:0.5359309\n",
      "Valid_auc_taskid: 0.53447664 with k = 5\n",
      "Optimization Finished!\n",
      "6-fold cross-validation\n",
      "Current Learning Rate: 1.0\n",
      "Picking validation set from position: 5\n",
      "Step 1, Loss = 0.9656536, Learning Rate = 1.0, Train AUC:0.5\n",
      "Step 20, Loss = 0.9656536, Learning Rate = 1.0, Train AUC:0.5\n",
      "Step 40, Loss = 0.9656536, Learning Rate = 1.0, Train AUC:0.5\n",
      "Valid_auc_taskid: 0.5 with k = 6\n",
      "Optimization Finished!\n",
      "7-fold cross-validation\n",
      "Current Learning Rate: 1.0\n",
      "Picking validation set from position: 6\n",
      "Step 1, Loss = 0.96553415, Learning Rate = 1.0, Train AUC:0.5\n",
      "Step 20, Loss = 0.96553415, Learning Rate = 1.0, Train AUC:0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 40, Loss = 0.96553415, Learning Rate = 1.0, Train AUC:0.5\n",
      "Valid_auc_taskid: 0.5 with k = 7\n",
      "Optimization Finished!\n",
      "8-fold cross-validation\n",
      "Current Learning Rate: 1.0\n",
      "Picking validation set from position: 7\n",
      "Step 1, Loss = 0.96618456, Learning Rate = 1.0, Train AUC:0.5026301\n",
      "Step 20, Loss = 0.9655815, Learning Rate = 1.0, Train AUC:0.5013138\n",
      "Step 40, Loss = 0.9655817, Learning Rate = 1.0, Train AUC:0.5008754\n",
      "Valid_auc_taskid: 0.5008433 with k = 8\n",
      "Optimization Finished!\n",
      "9-fold cross-validation\n",
      "Current Learning Rate: 1.0\n",
      "Picking validation set from position: 8\n",
      "Step 1, Loss = 0.96552414, Learning Rate = 1.0, Train AUC:0.5\n",
      "Step 20, Loss = 0.96552414, Learning Rate = 1.0, Train AUC:0.5\n",
      "Step 40, Loss = 0.96552414, Learning Rate = 1.0, Train AUC:0.5\n",
      "Valid_auc_taskid: 0.5 with k = 9\n",
      "Optimization Finished!\n",
      "Train_auc_taskid: 0.5\n",
      "Average Valid_auc_taskid: 0.5109031\n"
     ]
    }
   ],
   "source": [
    "plot_lr = []\n",
    "plot_valid_auc_taskid = []\n",
    "plot_train_auc_taskid = []\n",
    "with tf.Session() as sess:\n",
    "    for l_r in learning_rate:\n",
    "        plot_lr.append(l_r)    \n",
    "        valid_taskid_list = []\n",
    "        for k_fold in range(1,maximum_position+1):\n",
    "            # Initialize the variables (i.e. assign their default value)\n",
    "            print(str(k_fold)+\"-fold cross-validation\")\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            sess.run(tf.local_variables_initializer())\n",
    "            assign_op = learning_tf_rate.assign(l_r)\n",
    "            sess.run(assign_op)\n",
    "            print(\"Current Learning Rate: \"+str(learning_tf_rate.eval()))\n",
    "            train_set_seqlen,valid_set_seqlen,valid_set_x,valid_set_y,valid_set_y_taskid,train_set_x,train_set_y,train_set_y_taskid = get_next_train_valid_set(k_fold-1)\n",
    "            for step in range(1, training_steps+1):\n",
    "                batch_x = train_set_x\n",
    "                batch_y = train_set_y\n",
    "                sess.run(optimizer, feed_dict={x: batch_x, y: batch_y, y_taskid: train_set_y_taskid, seqlen_tf: train_set_seqlen})\n",
    "\n",
    "                if step % display_step == 0 or step == 1:\n",
    "                    loss,trainAUC,trainOPTS = sess.run([cost, auc, opts], feed_dict={x: batch_x, y: batch_y, y_taskid: train_set_y_taskid, seqlen_tf: train_set_seqlen})\n",
    "                    #print status\n",
    "                    print(\"Step \" + str(step) + \", Loss = \" + str(loss) + \", Learning Rate = \"+str(learning_tf_rate.eval()) + \", Train AUC:\" + str(trainOPTS))\n",
    "            #calculate validation AUC\n",
    "            valid_auc_taskid, valid_opts_taskid = sess.run([auc, opts], feed_dict={x: valid_set_x, y: valid_set_y, y_taskid: valid_set_y_taskid, seqlen_tf: valid_set_seqlen})\n",
    "            print(\"Valid_auc_taskid: \" + str(valid_opts_taskid) + \" with k = \"+str(k_fold))\n",
    "            valid_taskid_list.append(valid_opts_taskid)\n",
    "            print(\"Optimization Finished!\")\n",
    "    \n",
    "        #calculate training AUC (it should take both validation and training sets)\n",
    "        train_auc_taskid, train_opts_taskid = sess.run([auc, opts], feed_dict={x: training_x, y: training_y, y_taskid: training_y_taskid, seqlen_tf: training_seqlen})\n",
    "\n",
    "        print(\"Train_auc_taskid: \" + str(train_opts_taskid))\n",
    "        plot_train_auc_taskid.append(train_opts_taskid)\n",
    "        \n",
    "        #take average of validation AUCs\n",
    "        valid_avg_taskid = np.mean(valid_taskid_list)\n",
    "        \n",
    "        print(\"Average Valid_auc_taskid: \" + str(valid_avg_taskid))\n",
    "        plot_valid_auc_taskid.append(valid_avg_taskid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting validation set ccssm auc across different learning rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1244c17f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.00000000e-05 1.77827941e-04 3.16227766e-03 5.62341325e-02\n",
      " 1.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "plt.title(\"Training Set AUC\")\n",
    "plt.xlabel(\"Learning Rate Index\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.plot(plot_train_auc_taskid,'r--',label='train')\n",
    "plt.plot(plot_valid_auc_taskid,label='valid')\n",
    "plt.legend(loc='best', fancybox=True, framealpha=0.5)\n",
    "plt.show()\n",
    "print(learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#http://www.wildml.com/2016/08/rnns-in-tensorflow-a-practical-guide-and-undocumented-features/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Training the model with hyperparameters chosen from above and calculating testing AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Learning Rate: 0.00017782794\n",
      "Step 1, Loss = [0.9665413], Learning Rate = 0.00017782794\n",
      "Step 20, Loss = [0.9660948], Learning Rate = 0.00017782794\n",
      "Step 40, Loss = [0.9657899], Learning Rate = 0.00017782794\n",
      "Step 60, Loss = [0.965599], Learning Rate = 0.00017782794\n",
      "Step 80, Loss = [0.96548843], Learning Rate = 0.00017782794\n",
      "Optimization Finished!\n",
      "Train_auc_taskid: 0.6155131\n",
      "Testing auc for taskid: 0.6163878\n"
     ]
    }
   ],
   "source": [
    "final_l_r = plot_lr[np.argmax(plot_valid_auc_taskid)]\n",
    "with tf.Session() as sess:\n",
    "    for l_r in [1.77827941e-04]:\n",
    "        # Initialize the variables (i.e. assign their default value)\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sess.run(tf.local_variables_initializer())\n",
    "        assign_op = learning_tf_rate.assign(l_r)\n",
    "        sess.run(assign_op)\n",
    "        print(\"Final Learning Rate: \"+str(learning_tf_rate.eval()))\n",
    "        for step in range(1, training_steps*2+1):\n",
    "            sess.run(optimizer, feed_dict={x: training_x, y: training_y, y_taskid: training_y_taskid, seqlen_tf: training_seqlen})\n",
    "            \n",
    "            if step % display_step == 0 or step == 1:\n",
    "                loss= sess.run([cost], feed_dict={x: training_x, y: training_y, y_taskid: training_y_taskid, seqlen_tf: training_seqlen})\n",
    "                #print status\n",
    "                print(\"Step \" + str(step) + \", Loss = \" + str(loss) + \", Learning Rate = \"+str(learning_tf_rate.eval()))\n",
    "        print(\"Optimization Finished!\")\n",
    "    \n",
    "        #calculate training AUC\n",
    "        train_auc_taskid, train_opts_taskid = sess.run([auc, opts], feed_dict={x: training_x, y: training_y, y_taskid: training_y_taskid, seqlen_tf: training_seqlen})\n",
    "        print(\"Train_auc_taskid: \" + str(train_opts_taskid))\n",
    "        \n",
    "    # Calculate test auc\n",
    "    temp_auc_taskid, temp_opts_taskid = sess.run([auc, opts], feed_dict={x: test_x, y: test_y, y_taskid: test_y_taskid,seqlen_tf: test_seqlen})\n",
    "    print(\"Testing auc for taskid: \" + str(temp_opts_taskid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Learning Rate: 0.00017782794\n",
      "Step 1, Loss = [0.9662086], Learning Rate = 0.00017782794\n",
      "Step 20, Loss = [0.96580964], Learning Rate = 0.00017782794\n",
      "Step 40, Loss = [0.96557605], Learning Rate = 0.00017782794\n",
      "Step 60, Loss = [0.96547127], Learning Rate = 0.00017782794\n",
      "Step 80, Loss = [0.9654327], Learning Rate = 0.00017782794\n",
      "Optimization Finished!\n",
      "Train_auc_taskid: 0.6355657\n",
      "Testing auc for taskid: 0.6331784\n"
     ]
    }
   ],
   "source": [
    "final_l_r = plot_lr[np.argmax(plot_valid_auc_taskid)]\n",
    "with tf.Session() as sess:\n",
    "    for l_r in [1.77827941e-04]:\n",
    "        # Initialize the variables (i.e. assign their default value)\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sess.run(tf.local_variables_initializer())\n",
    "        assign_op = learning_tf_rate.assign(l_r)\n",
    "        sess.run(assign_op)\n",
    "        print(\"Final Learning Rate: \"+str(learning_tf_rate.eval()))\n",
    "        for step in range(1, training_steps*2+1):\n",
    "            sess.run(optimizer, feed_dict={x: training_x, y: training_y, y_taskid: training_y_taskid, seqlen_tf: training_seqlen})\n",
    "            \n",
    "            if step % display_step == 0 or step == 1:\n",
    "                loss= sess.run([cost], feed_dict={x: training_x, y: training_y, y_taskid: training_y_taskid, seqlen_tf: training_seqlen})\n",
    "                #print status\n",
    "                print(\"Step \" + str(step) + \", Loss = \" + str(loss) + \", Learning Rate = \"+str(learning_tf_rate.eval()))\n",
    "        print(\"Optimization Finished!\")\n",
    "    \n",
    "        #calculate training AUC\n",
    "        train_auc_taskid, train_opts_taskid = sess.run([auc, opts], feed_dict={x: training_x, y: training_y, y_taskid: training_y_taskid, seqlen_tf: training_seqlen})\n",
    "        print(\"Train_auc_taskid: \" + str(train_opts_taskid))\n",
    "        \n",
    "    # Calculate test auc\n",
    "    temp_auc_taskid, temp_opts_taskid = sess.run([auc, opts], feed_dict={x: test_x, y: test_y, y_taskid: test_y_taskid,seqlen_tf: test_seqlen})\n",
    "    print(\"Testing auc for taskid: \" + str(temp_opts_taskid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Learning Rate: 0.0031622776\n",
      "Step 1, Loss = [0.965967], Learning Rate = 0.0031622776\n",
      "Step 20, Loss = [0.9654031], Learning Rate = 0.0031622776\n",
      "Step 40, Loss = [0.9653683], Learning Rate = 0.0031622776\n",
      "Step 60, Loss = [0.96532255], Learning Rate = 0.0031622776\n",
      "Step 80, Loss = [0.96525156], Learning Rate = 0.0031622776\n",
      "Optimization Finished!\n",
      "Train_auc_taskid: 0.6022035\n",
      "Testing auc for taskid: 0.6028356\n"
     ]
    }
   ],
   "source": [
    "final_l_r = plot_lr[np.argmax(plot_valid_auc_taskid)]\n",
    "with tf.Session() as sess:\n",
    "    for l_r in [3.16227766e-03]:\n",
    "        # Initialize the variables (i.e. assign their default value)\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sess.run(tf.local_variables_initializer())\n",
    "        assign_op = learning_tf_rate.assign(l_r)\n",
    "        sess.run(assign_op)\n",
    "        print(\"Final Learning Rate: \"+str(learning_tf_rate.eval()))\n",
    "        for step in range(1, training_steps*2+1):\n",
    "            sess.run(optimizer, feed_dict={x: training_x, y: training_y, y_taskid: training_y_taskid, seqlen_tf: training_seqlen})\n",
    "            \n",
    "            if step % display_step == 0 or step == 1:\n",
    "                loss= sess.run([cost], feed_dict={x: training_x, y: training_y, y_taskid: training_y_taskid, seqlen_tf: training_seqlen})\n",
    "                #print status\n",
    "                print(\"Step \" + str(step) + \", Loss = \" + str(loss) + \", Learning Rate = \"+str(learning_tf_rate.eval()))\n",
    "        print(\"Optimization Finished!\")\n",
    "    \n",
    "        #calculate training AUC\n",
    "        train_auc_taskid, train_opts_taskid = sess.run([auc, opts], feed_dict={x: training_x, y: training_y, y_taskid: training_y_taskid, seqlen_tf: training_seqlen})\n",
    "        print(\"Train_auc_taskid: \" + str(train_opts_taskid))\n",
    "        \n",
    "    # Calculate test auc\n",
    "    temp_auc_taskid, temp_opts_taskid = sess.run([auc, opts], feed_dict={x: test_x, y: test_y, y_taskid: test_y_taskid,seqlen_tf: test_seqlen})\n",
    "    print(\"Testing auc for taskid: \" + str(temp_opts_taskid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Learning Rate: 1e-05\n",
      "Step 1, Loss = [0.96649164], Learning Rate = 1e-05\n",
      "Step 20, Loss = [0.966464], Learning Rate = 1e-05\n",
      "Step 40, Loss = [0.966427], Learning Rate = 1e-05\n",
      "Step 60, Loss = [0.96639806], Learning Rate = 1e-05\n",
      "Step 80, Loss = [0.96637046], Learning Rate = 1e-05\n",
      "Optimization Finished!\n",
      "Train_auc_taskid: 0.6767011\n",
      "Testing auc for taskid: 0.68035626\n"
     ]
    }
   ],
   "source": [
    "final_l_r = plot_lr[np.argmax(plot_valid_auc_taskid)]\n",
    "with tf.Session() as sess:\n",
    "    for l_r in [0.00001]:\n",
    "        # Initialize the variables (i.e. assign their default value)\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sess.run(tf.local_variables_initializer())\n",
    "        assign_op = learning_tf_rate.assign(l_r)\n",
    "        sess.run(assign_op)\n",
    "        print(\"Final Learning Rate: \"+str(learning_tf_rate.eval()))\n",
    "        for step in range(1, training_steps*2+1):\n",
    "            sess.run(optimizer, feed_dict={x: training_x, y: training_y, y_taskid: training_y_taskid, seqlen_tf: training_seqlen})\n",
    "            \n",
    "            if step % display_step == 0 or step == 1:\n",
    "                loss= sess.run([cost], feed_dict={x: training_x, y: training_y, y_taskid: training_y_taskid, seqlen_tf: training_seqlen})\n",
    "                #print status\n",
    "                print(\"Step \" + str(step) + \", Loss = \" + str(loss) + \", Learning Rate = \"+str(learning_tf_rate.eval()))\n",
    "        print(\"Optimization Finished!\")\n",
    "    \n",
    "        #calculate training AUC\n",
    "        train_auc_taskid, train_opts_taskid = sess.run([auc, opts], feed_dict={x: training_x, y: training_y, y_taskid: training_y_taskid, seqlen_tf: training_seqlen})\n",
    "        print(\"Train_auc_taskid: \" + str(train_opts_taskid))\n",
    "        \n",
    "    # Calculate test auc\n",
    "    temp_auc_taskid, temp_opts_taskid = sess.run([auc, opts], feed_dict={x: test_x, y: test_y, y_taskid: test_y_taskid,seqlen_tf: test_seqlen})\n",
    "    print(\"Testing auc for taskid: \" + str(temp_opts_taskid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Container object of 10 artists>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x124dbbe48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "#frequency distribution of taskids\n",
    "cnt = Counter()\n",
    "cnt2 = Counter()\n",
    "another = {}\n",
    "position = 1\n",
    "another_2 = {}\n",
    "position_2 = 1\n",
    "for i in student_vectors:\n",
    "    for j in student_vectors[i]:\n",
    "        if j['ccssm'] not in another:\n",
    "            another[j['ccssm']] = \"label\" + str(position)\n",
    "            position = position + 1\n",
    "        cnt[another[j['ccssm']]] += 1\n",
    "        if j['task_id'] not in another_2:\n",
    "            another_2[j['task_id']] = \"task\" + str(position_2)\n",
    "            position_2 = position_2 + 1\n",
    "        cnt2[another_2[j['task_id']]] += 1\n",
    "plt.bar(cnt2.keys(), cnt2.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Container object of 4 artists>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x126d3fe80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(cnt.keys(), cnt.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
