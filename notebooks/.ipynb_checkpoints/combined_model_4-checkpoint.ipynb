{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing k-fold cross validation and mini-batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pprint as pp\n",
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "def save_obj(obj, name ):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f)\n",
    "        \n",
    "def load_obj(name ):\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"../data/student_vectors_n_task_10_n_limit_10000.json\"\n",
    "#filepath2 = \"../../../student_vectors_n_task_10_n_limit_100000.json\"\n",
    "student_vectors = json.load(open(filepath))\n",
    "#student_vectors2 = json.load(open(filepath2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stats about data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique task IDs: 10\n",
      "Number of students: 1255\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115847ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task IDs mapping: \n",
      "Task ID -> p7cfRPp-kQ.partb(1) is attempted 7259 times. Max seq len: 46\n",
      "Task ID -> Ok-iIHxjgx.partb(2) is attempted 2325 times. Max seq len: 27\n",
      "Task ID -> 1zsCldT4p8.set1(3) is attempted 6346 times. Max seq len: 39\n",
      "Task ID -> DebcfZEEmI.proper_fractions(4) is attempted 6897 times. Max seq len: 40\n",
      "Task ID -> 9wRCzK1G7F.partb(5) is attempted 6632 times. Max seq len: 43\n",
      "Task ID -> 1zsCldT4p8.set2(6) is attempted 6443 times. Max seq len: 28\n",
      "Task ID -> nl-M69Ez9k.parta(7) is attempted 4753 times. Max seq len: 56\n",
      "Task ID -> kvig7fcCVc.partb(8) is attempted 3473 times. Max seq len: 32\n",
      "Task ID -> Ok-iIHxjgx.parta(9) is attempted 1589 times. Max seq len: 39\n",
      "Task ID -> hyei4uD81i.parta(10) is attempted 1255 times. Max seq len: 40\n"
     ]
    }
   ],
   "source": [
    "task_ids = []\n",
    "for i in student_vectors:\n",
    "    for j in student_vectors[i]:\n",
    "        if j['task_id'] not in task_ids:\n",
    "            task_ids.append(j['task_id'])\n",
    "print(\"Number of unique task IDs: \" + str(len(task_ids)))\n",
    "print(\"Number of students: \" + str(len(student_vectors)))\n",
    "\n",
    "#frequency distribution of taskids\n",
    "cnt2 = Counter()\n",
    "another_2 = {}\n",
    "seqlen_tasks = {}\n",
    "temp_seqlen = {}\n",
    "position_2 = 1\n",
    "for i in student_vectors:\n",
    "    for k in temp_seqlen:\n",
    "        temp_seqlen[k] = 0\n",
    "    for j in student_vectors[i]:\n",
    "        if(j['second_try'] == False):\n",
    "            if j['task_id'] not in another_2:\n",
    "                another_2[j['task_id']] = str(position_2)\n",
    "                position_2 = position_2 + 1\n",
    "            if j['task_id'] not in seqlen_tasks:\n",
    "                seqlen_tasks[j['task_id']] = []\n",
    "\n",
    "            if j['task_id'] not in temp_seqlen:\n",
    "                temp_seqlen[j['task_id']] = 1\n",
    "            else:\n",
    "                temp_seqlen[j['task_id']] += 1\n",
    "            cnt2[another_2[j['task_id']]] += 1\n",
    "    for k in seqlen_tasks:\n",
    "        seqlen_tasks[k].append(temp_seqlen[k])\n",
    "plt.bar(cnt2.keys(), cnt2.values())\n",
    "plt.title(\"Task IDs distribution\")\n",
    "plt.xlabel(\"Frequency of task ID across all students\")\n",
    "plt.ylabel(\"Task IDs\")\n",
    "plt.show()\n",
    "print(\"Task IDs mapping: \")\n",
    "for i in another_2:\n",
    "    print(\"Task ID -> \"+str(i)+\"(\"+str(another_2[i])+\") is attempted \" + str(cnt2[another_2[i]]) + \" times.\" + \" Max seq len: \"+str(max(seqlen_tasks[i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating encodings in 'sequences' (x), 'seqlen' (sequence lengths) and 'output_y' (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-processing for using MultiLabelBinarizer\n",
    "temp_ids = []\n",
    "for i in task_ids:\n",
    "    temp_ids.append([i])\n",
    "\n",
    "#generating encodings\n",
    "enc = MultiLabelBinarizer()\n",
    "task_ids_1hot = (enc.fit_transform(temp_ids)).astype(float)\n",
    "task_ids_classes = enc.classes_\n",
    "task_ids_dict = dict(zip(task_ids, task_ids_1hot))\n",
    "# print(\"\\n1-hot encoding for task IDs:\")\n",
    "# pp.pprint(task_ids_dict)\n",
    "\n",
    "sequences = []\n",
    "output_y = []\n",
    "seqlen = []\n",
    "incorrect_tid_vec = np.zeros((len(task_ids)), dtype=np.float)\n",
    "for i in student_vectors:\n",
    "    temp_seq = []\n",
    "    temp_seq.append(np.concatenate([incorrect_tid_vec,incorrect_tid_vec])) #for taking first prediction into account\n",
    "    for j in student_vectors[i]:\n",
    "        if(j['second_try'] == False): #ignoring second_try\n",
    "            if(j['correct'] == True):\n",
    "                vec = np.concatenate([task_ids_dict[j['task_id']],incorrect_tid_vec])\n",
    "                temp_seq.append(np.asarray(vec))\n",
    "            else:\n",
    "                vec = np.concatenate([incorrect_tid_vec,task_ids_dict[j['task_id']]])\n",
    "                temp_seq.append(np.asarray(vec))\n",
    "    if(len(temp_seq)>1):\n",
    "        seqlen.append(len(temp_seq)-1)\n",
    "        last_one = temp_seq.pop() #remove last interaction vector\n",
    "        sequences.append(np.asarray(temp_seq)) #add it to x\n",
    "        first_one = temp_seq.pop(0) #remove first interaction vector\n",
    "        temp_seq.append(last_one)\n",
    "        output_y.append(np.asarray(temp_seq)) #concatenate with last vector, and append to output! \n",
    "\n",
    "length_interaction_vector = 2*(len(task_ids)) #length of interaction vector\n",
    "sequences_lengths1 = [[x] for x in seqlen]\n",
    "# print(\"Sample interaction vector: \")\n",
    "# pp.pprint(sequences[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing data per skill ID for calculating AUC per skill over epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_skill = {}\n",
    "per_skill['x'] = {}\n",
    "per_skill['y'] = {}\n",
    "per_skill['seqlen'] = {}\n",
    "for i in another_2:\n",
    "    per_skill['x'][i] = []\n",
    "    per_skill['y'][i] = []\n",
    "    per_skill['seqlen'][i] = []\n",
    "    for p in student_vectors:\n",
    "        interactions = []\n",
    "        interactions.append(np.concatenate([incorrect_tid_vec,incorrect_tid_vec]))\n",
    "        for j in student_vectors[p]:\n",
    "            if(j['task_id'] == i and j['second_try'] == False):\n",
    "                if(j['correct'] == True):\n",
    "                    vec = np.concatenate([task_ids_dict[j['task_id']],incorrect_tid_vec])\n",
    "                    interactions.append(vec)\n",
    "                else:\n",
    "                    interactions.append(np.concatenate([incorrect_tid_vec,task_ids_dict[j['task_id']]]))\n",
    "        if(len(interactions) > 1):\n",
    "            per_skill['seqlen'][i].append(len(interactions)-1)\n",
    "            last_one = interactions.pop()\n",
    "            per_skill['x'][i].append(interactions)\n",
    "            first_one = interactions.pop(0)\n",
    "            interactions.append(last_one)\n",
    "            per_skill['y'][i].append(interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sequence length: 187\n",
      "Splitting 1255 rows (or students) into 1004 for training and rest for testing.\n",
      "Batch Size = 251\n",
      "Number of recurrent units = 50\n",
      "Learning rate = 0.1\n",
      "display step = 20\n"
     ]
    }
   ],
   "source": [
    "max_seqlen = max(seqlen)\n",
    "print(\"Maximum sequence length across the whole dataset = \"+str(max_seqlen+1))\n",
    "training_set_split = 0.8\n",
    "split = int((training_set_split)*len(student_vectors))\n",
    "print(\"Splitting \"+str(len(student_vectors))+\" rows (or students) into \"+str(split)+ \" for training and rest for testing.\")\n",
    "BATCH_SIZE = 251\n",
    "print(\"Batch Size = \"+str(BATCH_SIZE))\n",
    "num_units = 50\n",
    "print(\"Number of recurrent units = \"+str(num_units))\n",
    "learning_tf_rate = 0.1\n",
    "print(\"Learning rate = \"+str(learning_tf_rate))\n",
    "display_step = 20\n",
    "print(\"display step = \"+str(display_step))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=np.nan)\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "def calculate_auc (y_true,y_pred,sequence_lengths=[],plot=False,debug=False):\n",
    "    if sequence_lengths == []:\n",
    "        return roc_auc_score(y_true, y_pred)\n",
    "    else:\n",
    "        con_y_true = np.zeros([sum(sequence_lengths),length_interaction_vector])\n",
    "        con_y_pred = np.zeros([sum(sequence_lengths),length_interaction_vector])\n",
    "        index = 0\n",
    "        for i in range(len(y_true)): #per student\n",
    "            for j in range(sequence_lengths[i]): #up to the sequence length\n",
    "                con_y_true[index] = y_true[i][j]\n",
    "                con_y_pred[index] = y_pred[i][j]\n",
    "                index += 1\n",
    "        con1_y_true = np.zeros([sum(sequence_lengths)])\n",
    "        con1_y_pred = np.zeros([sum(sequence_lengths)])\n",
    "        \n",
    "        for l in range(sum(sequence_lengths)):\n",
    "            index_one = np.argmax(con_y_true[l])\n",
    "            if(index_one >= int(length_interaction_vector/2)):\n",
    "                index_two = index_one - int(length_interaction_vector/2)\n",
    "            else:\n",
    "                index_two = index_one\n",
    "                index_one = index_one + int(length_interaction_vector/2)\n",
    "            if(np.argmax(con_y_true[l]) == index_one): #true is incorrect\n",
    "                con1_y_true[l] = 0.\n",
    "                con1_y_pred[l] = 1.0 - con_y_pred[l][index_one]\n",
    "            elif(np.argmax(con_y_true[l]) == index_two):\n",
    "                con1_y_true[l] = 1.\n",
    "                con1_y_pred[l] = con_y_pred[l][index_two]\n",
    "        debug=False\n",
    "        if(debug):\n",
    "            print(np.c_[con1_y_true,con1_y_pred])\n",
    "        fpr, tpr, thresholds = roc_curve(con1_y_true, con1_y_pred)\n",
    "        #print(\"tpr: \"+str(tpr) + \", fpr: \"+str(fpr) + \", thresholds: \"+str(thresholds))\n",
    "        if(plot):\n",
    "            return [roc_auc_score(con1_y_true, con1_y_pred),fpr,tpr]\n",
    "        else:\n",
    "            return roc_auc_score(con1_y_true, con1_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected binary or unicode string, got array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.]])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-d3439425913f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#split the input data into test and train set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudent_vectors\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mtrain_seqlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_seqlen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudent_vectors\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mtrain_seqlen1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_seqlen1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences_lengths1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudent_vectors\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(value, num_or_size_splits, axis, num, name)\u001b[0m\n\u001b[1;32m   1275\u001b[0m         \u001b[0msplit_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m         \u001b[0mnum_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1277\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   1278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36m_split_v\u001b[0;34m(value, size_splits, split_dim, num_split, name)\u001b[0m\n\u001b[1;32m   5135\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m   5136\u001b[0m         \u001b[0;34m\"SplitV\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize_splits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msplit_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5137\u001b[0;31m         num_split=num_split, name=name)\n\u001b[0m\u001b[1;32m   5138\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5139\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    511\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    514\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m               raise TypeError(\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    508\u001b[0m                 \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m                 \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_ref\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m                 preferred_dtype=default_dtype)\n\u001b[0m\u001b[1;32m    511\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx)\u001b[0m\n\u001b[1;32m    924\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    227\u001b[0m                                          as_ref=False):\n\u001b[1;32m    228\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[1;32m    206\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[1;32m    207\u001b[0m       tensor_util.make_tensor_proto(\n\u001b[0;32m--> 208\u001b[0;31m           value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n\u001b[0m\u001b[1;32m    209\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m   const_tensor = g.create_op(\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    481\u001b[0m     raise TypeError(\"Element type not supported in TensorProto: %s\" %\n\u001b[1;32m    482\u001b[0m                     numpy_dtype.name)\n\u001b[0;32m--> 483\u001b[0;31m   \u001b[0mappend_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_proto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtensor_proto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mtensorflow/python/framework/fast_tensor_util.pyx\u001b[0m in \u001b[0;36mtensorflow.python.framework.fast_tensor_util.AppendObjectArrayToTensorProto\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/util/compat.py\u001b[0m in \u001b[0;36mas_bytes\u001b[0;34m(bytes_or_text, encoding)\u001b[0m\n\u001b[1;32m     63\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     raise TypeError('Expected binary or unicode string, got %r' %\n\u001b[0;32m---> 65\u001b[0;31m                     (bytes_or_text,))\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected binary or unicode string, got array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.],\n       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.]])"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(1234)\n",
    "\n",
    "#define placeholders\n",
    "# x = tf.placeholder(tf.float32, [None, None, length_interaction_vector]) #batch_size, max_seqlen of that batch, inter.v\n",
    "# y = tf.placeholder(tf.float32, [None, None, length_interaction_vector])\n",
    "# seqlen_tf = tf.placeholder(tf.float32,[None])\n",
    "\n",
    "#split the input data into test and train set\n",
    "train_x, test_x = tf.split(np.asarray(sequences), [split,len(student_vectors) - split], 0)\n",
    "train_seqlen, test_seqlen = tf.split(seqlen, [split,len(student_vectors) - split], 0)\n",
    "train_seqlen1, test_seqlen1 = tf.split(sequences_lengths1, [split,len(student_vectors) - split], 0)\n",
    "train_y, test_y = tf.split(np.asarray(output_y), [split,len(student_vectors) - split], 0)\n",
    "\n",
    "#making batches\n",
    "train_x_batch, train_y_batch, train_seqlen_batch,train_seqlen_batch1 = tf.train.batch([train_x, train_y, train_seqlen, train_seqlen1], batch_size = BATCH_SIZE, dynamic_pad = True, allow_smaller_final_batch = True, enqueue_many = True)\n",
    "#https://www.tensorflow.org/api_docs/python/tf/train/batch \n",
    "\n",
    "#Dynamic RNN \n",
    "def dynamicRNN(x1, seqlen_tf1):\n",
    "    rnn_cell = tf.nn.rnn_cell.BasicLSTMCell(num_units,reuse=tf.AUTO_REUSE)\n",
    "    outputs, states = tf.nn.dynamic_rnn(rnn_cell, x1, dtype=tf.float32,sequence_length= seqlen_tf1)\n",
    "    out_size = int(length_interaction_vector / 2)\n",
    "    outputs = tf.contrib.layers.fully_connected(outputs, out_size, activation_fn = tf.nn.sigmoid, weights_initializer=tf.contrib.layers.xavier_initializer(uniform=False))\n",
    "    opposites = tf.subtract(tf.ones(tf.shape(outputs)),outputs)\n",
    "    outputs1 = tf.concat([outputs,opposites],2)\n",
    "    return outputs1\n",
    "\n",
    "#predictions for training and test set\n",
    "pred_train = dynamicRNN(train_x_batch, train_seqlen_batch)\n",
    "pred_train = pred_train * train_y_batch #masking output\n",
    "pred_test = dynamicRNN(test_x, test_seqlen)\n",
    "pred_test = pred_test * test_y #masking output\n",
    "#pred = dynamicRNN(x,seqlen_tf) #for generic evaluation, bypassing split and batching operation\n",
    "pred_train1 = dynamicRNN(train_x, train_seqlen)\n",
    "pred_train1 = pred_train1 * train_y #masking output\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost1 = tf.nn.sigmoid_cross_entropy_with_logits(logits=pred_train, labels=y)\n",
    "mask = tf.cast(tf.sequence_mask(lengths=train_seqlen_batch1, maxlen = tf.reduce_max(train_seqlen_batch1)), tf.float32)\n",
    "cost1 = tf.multiply(cost1,tf.transpose(mask, perm=[0, 2, 1]))\n",
    "cost1 = tf.reduce_sum(cost1, 1)\n",
    "cost1 /= tf.cast(train_seqlen_batch,tf.float32)\n",
    "cost = tf.reduce_mean(cost1)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_tf_rate).minimize(cost)\n",
    "\n",
    "saver = tf.train.Saver(max_to_keep=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-5e9d585fdb24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mstartTime1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moutput_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseqlen_tf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mseqlen\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdisplay_step\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1087\u001b[0m             \u001b[0mfeed_handles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubfeed_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m             \u001b[0mnp_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubfeed_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m           if (not is_tensor_handle_feed and\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m     \"\"\"\n\u001b[0;32m--> 492\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "startTime = time.time()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    stop = False\n",
    "    cost_prev = 1.0\n",
    "    step = 0\n",
    "    startTime1 = time.time()\n",
    "    while(stop==False):\n",
    "        sess.run(optimizer, feed_dict={x: sequences, y: output_y, seqlen_tf: seqlen})\n",
    "        step += 1\n",
    "        if step % display_step == 0 or step == 1:\n",
    "            print(\"\\t\\t Time taken: %f\" % (time.time() - startTime1))\n",
    "            startTime1 = time.time()\n",
    "            saver.save(sess, 'combined_model_4/model.ckpt',global_step=display_step)\n",
    "            loss = sess.run(cost, feed_dict={x: sequences, y: output_y, seqlen_tf: seqlen})\n",
    "            if cost_prev - loss <= 0.00005:\n",
    "                stop = True\n",
    "            else:\n",
    "                cost_prev = loss\n",
    "            #calculate and report AUCs\n",
    "            #overall first\n",
    "            train_seqlen_o, test_seqlen_o, true_train_o, true_test_o, pred_train_o, pred_test_o = sess.run([train_seqlen, test_seqlen, train_y, test_y, pred_train1, pred_test], feed_dict={x: sequences, y: output_y, seqlen_tf: seqlen, condition:0})\n",
    "            o_train_auc = calculate_auc(true_train_o,pred_train_o,train_seqlen_o)\n",
    "            o_test_auc = calculate_auc(true_test_o,pred_test_o,test_seqlen_o)\n",
    "            print(\"Overall Train AUC: \"+str(o_train_auc) + \", test AUC: \"+str(o_test_auc))\n",
    "print(\"Total Time taken: %f\" % (time.time() - startTime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suggestions for later:\n",
    "- https://www.tensorflow.org/versions/r1.5/api_docs/python/tf/contrib/learn/DynamicRnnEstimator#evaluate\n",
    "- we can also do dynamic partition of training and test set: http://ischlag.github.io/2016/06/19/tensorflow-input-pipeline-example/, but to compare with all the other models, I am fixing the test set.\n",
    "- try using shuffle_batch instead of tf.batch https://www.tensorflow.org/api_docs/python/tf/train/shuffle_batch \n",
    "- tried the suggestion, turns out one can't feed inconsistent dimensional tensors via feed_dict. And also, none of the functions (like - tf.train.batch etc. seem to be accepting the original variables). I need to try it on a small notebook first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 20)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(np.asarray(sequences)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
