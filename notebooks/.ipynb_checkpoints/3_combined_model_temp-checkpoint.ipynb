{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-14T23:17:06.363796Z",
     "start_time": "2018-04-14T23:17:06.343296Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pprint as pp\n",
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from collections import Counter\n",
    "%matplotlib inline\n",
    "np.set_printoptions(threshold=np.nan)\n",
    "import pickle\n",
    "def save_obj(obj, name ):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f)\n",
    "        \n",
    "def load_obj(name ):\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-14T23:17:08.228147Z",
     "start_time": "2018-04-14T23:17:07.984045Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Loading data from file\n",
    "'''\n",
    "filepath = \"../data/student_vectors_n_task_10_n_limit_10000.json\"\n",
    "student_vectors = json.load(open(filepath))\n",
    "#filepath2 = \"../../../student_vectors_n_task_10_n_limit_100000.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-14T23:17:10.159803Z",
     "start_time": "2018-04-14T23:17:10.138150Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Generate one hot encoding from task IDs\n",
    "'''\n",
    "#Collect task IDs\n",
    "task_ids = []\n",
    "for i in student_vectors:\n",
    "    for j in student_vectors[i]:\n",
    "        if j['task_id'] not in task_ids:\n",
    "            task_ids.append(j['task_id'])\n",
    "\n",
    "#pre-processing for using MultiLabelBinarizer\n",
    "temp_ids = [[x] for x in task_ids]\n",
    "\n",
    "#generating encodings\n",
    "enc = MultiLabelBinarizer()\n",
    "task_ids_1hot = (enc.fit_transform(temp_ids)).astype(float)\n",
    "task_ids_dict = dict(zip(task_ids, task_ids_1hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-14T23:17:26.612574Z",
     "start_time": "2018-04-14T23:17:26.592254Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Split train and test student_vectors\n",
    "'''\n",
    "split = int(0.8*len(student_vectors))\n",
    "train_student_vectors = {}\n",
    "test_student_vectors = {}\n",
    "\n",
    "for idx,keys in enumerate(student_vectors):\n",
    "    if(idx < split):\n",
    "        train_student_vectors[keys] = student_vectors[keys]\n",
    "    else:\n",
    "        test_student_vectors[keys] = student_vectors[keys]\n",
    "length_interaction_vector = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-14T23:43:56.660865Z",
     "start_time": "2018-04-14T23:43:56.297936Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sequence length is: 186\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Gather Training Data from train_student_vectors\n",
    "train_X, train_Y, train_Seqlen\n",
    "'''\n",
    "train_sequences = {}\n",
    "train_sequences['overall'] = []\n",
    "incorrect_vec = np.zeros((len(task_ids)), dtype=np.float)\n",
    "temp_seqlen = {}\n",
    "temp_seqlen['overall'] = []\n",
    "\n",
    "for i in task_ids: #go per task IDs\n",
    "    train_sequences[i] = []\n",
    "    temp_seqlen[i] = []\n",
    "    for j in train_student_vectors: #go per student\n",
    "        temp = [] #one student sequence\n",
    "        temp.append(np.concatenate([incorrect_vec,incorrect_vec])) #for getting first output\n",
    "        for k in train_student_vectors[j]: #per question\n",
    "            if(k['second_try'] == False and k['task_id'] == i):\n",
    "                if(k['correct'] == True):\n",
    "                    temp.append (np.concatenate( [task_ids_dict[k['task_id']], incorrect_vec] ))\n",
    "                else:\n",
    "                    temp.append (np.concatenate ([incorrect_vec, task_ids_dict[k['task_id']]]))\n",
    "        if(len(temp) > 1):\n",
    "            train_sequences[i].append(temp)\n",
    "            temp_seqlen[i].append(len(temp)-1)\n",
    "            \n",
    "\n",
    "for j in train_student_vectors: #go per student\n",
    "    temp = [] #one student sequence\n",
    "    temp.append(np.concatenate([incorrect_vec,incorrect_vec])) #for getting first output\n",
    "    for k in train_student_vectors[j]: #per question\n",
    "        if(k['second_try'] == False):\n",
    "            if(k['correct'] == True):\n",
    "                temp.append(np.concatenate([task_ids_dict[k['task_id']],incorrect_vec]))\n",
    "            else:\n",
    "                temp.append(np.concatenate([incorrect_vec,task_ids_dict[k['task_id']]]))\n",
    "    if(len(temp) > 1):\n",
    "        train_sequences['overall'].append(temp)\n",
    "#         random.shuffle(train_sequences['overall'])\n",
    "        temp_seqlen['overall'].append(len(temp)-1)\n",
    "\n",
    "print(\"Maximum sequence length is: \"+ str(max(temp_seqlen['overall'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-14T23:44:43.694707Z",
     "start_time": "2018-04-14T23:44:43.369745Z"
    }
   },
   "outputs": [],
   "source": [
    "'''continued\n",
    "Gather Training Data\n",
    "train_X, train_Y, train_Seqlen, train_mask\n",
    "'''\n",
    "train_X = {}\n",
    "train_Y = {}\n",
    "train_Seqlen = {}\n",
    "train_mask = {}\n",
    "\n",
    "for i in task_ids:\n",
    "    train_X[i] = np.zeros(shape=(len(train_sequences[i]), max(temp_seqlen[i]),len(train_sequences[i][0][0])),dtype=float)\n",
    "    train_Y[i] = np.zeros(shape=(len(train_sequences[i]), max(temp_seqlen[i]),len(train_sequences[i][0][0])),dtype=float)\n",
    "    train_Seqlen[i] = np.zeros(shape=(len(train_sequences[i])),dtype=int)\n",
    "    train_mask[i] = np.zeros(shape=(len(train_sequences[i]),1),dtype=int)\n",
    "    for idx, seq in enumerate(train_sequences[i]):\n",
    "        vec1 = np.concatenate([task_ids_dict[i],incorrect_vec])\n",
    "        vec2 = np.concatenate([incorrect_vec,task_ids_dict[i]])\n",
    "        if(np.argmax(train_sequences[i][idx][1]) == np.argmax(vec1) or np.argmax(train_sequences[i][idx][1]) == np.argmax(vec2)):\n",
    "            leng = len(train_sequences[i][idx])\n",
    "            train_Seqlen[i][idx] = leng-1\n",
    "            train_mask[i][idx] = [leng-1]\n",
    "            for pos in range(leng-1):\n",
    "                train_X[i][idx][pos] = train_sequences[i][idx][pos]\n",
    "                train_Y[i][idx][pos] = train_sequences[i][idx][pos+1]\n",
    "\n",
    "train_X['overall'] = np.zeros(shape =(len(train_sequences['overall']), max(temp_seqlen['overall']), len(train_sequences['overall'][0][0])),dtype=float)\n",
    "train_Y['overall'] = np.zeros(shape =(len(train_sequences['overall']), max(temp_seqlen['overall']), len(train_sequences['overall'][0][0])),dtype=float)\n",
    "train_Seqlen['overall'] = np.zeros(shape=(len(train_sequences['overall'])),dtype=int)\n",
    "train_mask['overall'] = np.zeros(shape=(len(train_sequences['overall']),1),dtype=int)\n",
    "\n",
    "for idx, seq in enumerate(train_sequences['overall']):\n",
    "    leng = len(seq)\n",
    "    train_Seqlen['overall'][idx] = leng-1\n",
    "    train_mask['overall'][idx] = [leng-1]\n",
    "    for pos in range(leng-1):\n",
    "        train_X['overall'][idx][pos] = train_sequences['overall'][idx][pos]\n",
    "        train_Y['overall'][idx][pos] = train_sequences['overall'][idx][pos+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-14T23:47:05.007874Z",
     "start_time": "2018-04-14T23:47:04.924736Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sequence length is: 39\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Gathering test data for evaluation metric 1 from test_student_vectors\n",
    "1) Input one skill at a time and get predictions for each separately\n",
    "a- calculate 10 separate AUCs\n",
    "b- concatenate separate predictions to calculate 1 AUC\n",
    "\n",
    "test_1_X, test_1_Y, test_1_Seqlen\n",
    "'''\n",
    "test_sequences = {}\n",
    "incorrect_vec = np.zeros((len(task_ids)), dtype=np.float)\n",
    "temp_seqlen = {}\n",
    "temp_seqlen['overall'] = []\n",
    "test_sequences['overall'] = []\n",
    "\n",
    "for i in task_ids: #go per task IDs\n",
    "    temp_seqlen[i] = []\n",
    "    test_sequences[i] = []\n",
    "    for j in test_student_vectors: #go per student\n",
    "        temp = [] #one student sequence\n",
    "        temp.append(np.concatenate([incorrect_vec,incorrect_vec])) #for getting first output\n",
    "        for k in test_student_vectors[j]: #per question\n",
    "            if(k['second_try'] == False and k['task_id'] == i):\n",
    "                if(k['correct'] == True):\n",
    "                    temp.append(np.concatenate([task_ids_dict[k['task_id']],incorrect_vec]))\n",
    "                else:\n",
    "                    temp.append(np.concatenate([incorrect_vec,task_ids_dict[k['task_id']]]))\n",
    "        if(len(temp) > 1):\n",
    "            test_sequences[i].append(temp)\n",
    "            test_sequences['overall'].append(temp)\n",
    "            temp_seqlen['overall'].append(len(temp)-1)\n",
    "            temp_seqlen[i].append(len(temp)-1)\n",
    "\n",
    "print(\"Maximum sequence length is: \"+ str(max(temp_seqlen['overall'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-14T23:47:06.180551Z",
     "start_time": "2018-04-14T23:47:06.028708Z"
    }
   },
   "outputs": [],
   "source": [
    "'''continued\n",
    "Gathering test data for evaluation metric 1\n",
    "test_1_X, test_1_Y, test_1_Seqlen\n",
    "'''\n",
    "test_1_X = {}\n",
    "test_1_Y = {}\n",
    "test_1_Seqlen = {}\n",
    "test_1_mask = {}\n",
    "\n",
    "for i in task_ids:\n",
    "    test_1_X[i] = np.zeros(shape=(len(test_sequences[i]),max(temp_seqlen[i]),len(test_sequences[i][0][0])),dtype=float)\n",
    "    test_1_Y[i] = np.zeros(shape=(len(test_sequences[i]),max(temp_seqlen[i]),len(test_sequences[i][0][0])),dtype=float)\n",
    "    test_1_Seqlen[i] = np.zeros(shape=(len(test_sequences[i])),dtype=int)\n",
    "    test_1_mask[i] = np.zeros(shape=(len(test_sequences[i]),1),dtype=int)\n",
    "\n",
    "    for idx, seq in enumerate(test_sequences[i]): #go per student\n",
    "        vec1 = np.concatenate([task_ids_dict[i],incorrect_vec])\n",
    "        vec2 = np.concatenate([incorrect_vec,task_ids_dict[i]])\n",
    "        if(test_sequences[i][idx][1].all() == vec1.all() or test_sequences[i][idx][1].all() == vec2.all()):\n",
    "            leng = len(test_sequences[i][idx])\n",
    "            test_1_Seqlen[i][idx] = leng-1\n",
    "            test_1_mask[i][idx] = [leng-1]\n",
    "            for pos in range(leng-1):\n",
    "                test_1_X[i][idx][pos] = test_sequences[i][idx][pos]\n",
    "                test_1_Y[i][idx][pos] = test_sequences[i][idx][pos+1]\n",
    "\n",
    "test_1_X['overall'] = np.zeros(shape=(len(test_sequences['overall']),max(temp_seqlen['overall']),len(test_sequences['overall'][0][0])),dtype=float)\n",
    "test_1_Y['overall'] = np.zeros(shape=(len(test_sequences['overall']),max(temp_seqlen['overall']),len(test_sequences['overall'][0][0])),dtype=float)\n",
    "test_1_Seqlen['overall'] = np.zeros(shape=(len(test_sequences['overall'])),dtype=int)\n",
    "test_1_mask['overall'] = np.zeros(shape=(len(test_sequences['overall']),1),dtype=int)\n",
    "for idx, seq in enumerate(test_sequences['overall']):\n",
    "    leng = len(seq)\n",
    "    test_1_Seqlen['overall'][idx] = leng-1\n",
    "    test_1_mask['overall'][idx] = [leng-1]\n",
    "    for pos in range(leng-1):\n",
    "        test_1_X['overall'][idx][pos] = test_sequences['overall'][idx][pos]\n",
    "        test_1_Y['overall'][idx][pos] = test_sequences['overall'][idx][pos+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-14T23:47:12.632585Z",
     "start_time": "2018-04-14T23:47:12.596056Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sequence length is: 85\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Gathering test data for evaluation metric 2 from test_student_vectors\n",
    "2) Input the natural sequence of students and get predictions for the same\n",
    "a- calculate 1 AUC with natural sequence predictions\n",
    "b- filter predictions per skill, and calculate 10 separate AUCs\n",
    "\n",
    "test_2_X, test_2_Y, test_2_Seqlen\n",
    "'''\n",
    "test_sequences_2 = {}\n",
    "incorrect_vec = np.zeros((len(task_ids)), dtype=np.float)\n",
    "temp_seqlen = {}\n",
    "temp_seqlen['overall'] = []\n",
    "test_sequences_2['overall'] = []\n",
    "\n",
    "#first lets get a natural sequence in overall!, rest part will be done after getting predictions from the model\n",
    "for j in test_student_vectors: #go per student\n",
    "    temp = [] #one student sequence\n",
    "    temp.append(np.concatenate([incorrect_vec,incorrect_vec])) #for getting first output\n",
    "    for k in test_student_vectors[j]: #per question\n",
    "        if(k['second_try'] == False):\n",
    "            if(k['correct'] == True):\n",
    "                temp.append(np.concatenate([task_ids_dict[k['task_id']],incorrect_vec]))\n",
    "            else:\n",
    "                temp.append(np.concatenate([incorrect_vec,task_ids_dict[k['task_id']]]))\n",
    "    if(len(temp) > 1):\n",
    "        test_sequences_2['overall'].append(temp)\n",
    "        temp_seqlen['overall'].append(len(temp)-1)\n",
    "\n",
    "print(\"Maximum sequence length is: \"+ str(max(temp_seqlen['overall'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-14T23:47:13.298270Z",
     "start_time": "2018-04-14T23:47:13.262259Z"
    }
   },
   "outputs": [],
   "source": [
    "'''continued\n",
    "Gathering test data for evaluation metric 2\n",
    "test_2_X, test_2_Y, test_2_Seqlen\n",
    "'''\n",
    "test_2_X = {}\n",
    "test_2_Y = {}\n",
    "test_2_Seqlen = {}\n",
    "test_2_mask = {}\n",
    "\n",
    "test_2_X['overall'] = np.zeros(shape=(len(test_sequences_2['overall']),max(temp_seqlen['overall']),len(test_sequences_2['overall'][0][0])),dtype=float)\n",
    "test_2_Y['overall'] = np.zeros(shape=(len(test_sequences_2['overall']),max(temp_seqlen['overall']),len(test_sequences_2['overall'][0][0])),dtype=float)\n",
    "test_2_Seqlen['overall'] = np.zeros(shape=(len(test_sequences_2['overall'])),dtype=int)\n",
    "test_2_mask['overall'] = np.zeros(shape=(len(test_sequences_2['overall']),1),dtype=int)\n",
    "for idx, seq in enumerate(test_sequences_2['overall']):\n",
    "    leng = len(seq)\n",
    "    test_2_Seqlen['overall'][idx] = leng-1\n",
    "    test_2_mask['overall'][idx] = [leng-1]\n",
    "    for pos in range(leng-1):\n",
    "        test_2_X['overall'][idx][pos] = test_sequences_2['overall'][idx][pos]\n",
    "        test_2_Y['overall'][idx][pos] = test_sequences_2['overall'][idx][pos+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-15T00:12:19.468821Z",
     "start_time": "2018-04-15T00:12:19.464606Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[39 20 20 27 51 30 25 33 62 24 20 32 52 24 31 75 59 31 27 20 32 55 21 26\n",
      " 30 38 65 24 43 24 20 43 64 31 25 20 52 37 33 38 42 45 24 24 31 28 23 32\n",
      " 34 24 20 24 32 26 23 26 70 52 28 85 36 29 51 28 31 22 50 71 23 44 27 24\n",
      " 30 37 38 36 28 38 30 23 23 36 47 20 33 24 26 20 32 27 30 23 32 26 21 34\n",
      " 47 74 37 26 35 24 35 36 20 27 24 20 23 30 20 27 26 37 20 34 28 22 21 36\n",
      " 23 28 34 27 24 38 27 20 28 20 33 25 24 39 29 41 74 23 24 28 24 26 32 27\n",
      " 39 33 34 37 46 20 27 22 24 20 23 21 32 43 23 27 29 46 34 27 31 28 23 30\n",
      " 23 22 41 24 21 33 36 39 20 24 31 64 50 36 17 33 26 38 20 31 29 20 20 27\n",
      " 20 32 20 20 20 50 26 40 20 26 41 30 27 28 36 25 27 32 23 29 31 24 24 34\n",
      " 31 29 28 58 33 44 52 52 57 20 41 64 24 45 58 23 53 69 36 70 65 23 28 23\n",
      " 79 64 33 44 42 45 39 53 26 20 45]\n"
     ]
    }
   ],
   "source": [
    "print(test_2_Seqlen['overall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-14T23:47:17.173265Z",
     "start_time": "2018-04-14T23:47:16.908430Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "let's define AUC functions\n",
    "'''\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "def calculate_auc (y_true, y_pred, sequence_lengths=[], plot=False, debug=False, idx = 0, _2b = False):\n",
    "    if sequence_lengths == []:\n",
    "        con1_y_true = np.zeros([len(y_true)])\n",
    "        con1_y_pred = np.zeros([len(y_true)])\n",
    "        index_two = idx\n",
    "        right = 0\n",
    "        index_one = index_two + int(length_interaction_vector/2)\n",
    "        for i in range(len(y_true)): #go up to sequence length\n",
    "            if(np.argmax(y_true[i]) == index_one):\n",
    "                print(\"incorrect true label\")\n",
    "                con1_y_true[i] = 0.\n",
    "                con1_y_pred[i] = 1.0 - y_pred[i][index_one]\n",
    "            elif (np.argmax(y_true[i]) == index_two):\n",
    "                print(\"correct true label\")\n",
    "                right += 1\n",
    "                con1_y_true[i] = 1.\n",
    "                con1_y_pred[i] = y_pred[i][index_two]\n",
    "        return [roc_auc_score(con1_y_true, con1_y_pred),con1_y_pred,con1_y_true, (right/len(y_true))]\n",
    "    \n",
    "    elif (_2b):\n",
    "        incorrect_vec = np.zeros((len(task_ids)), dtype=np.float)\n",
    "        # For evaluation algorithm 2b\n",
    "        auc = {}\n",
    "        for k in task_ids:\n",
    "            true = []\n",
    "            pred = []\n",
    "            for i in range(len(y_true)): #per student sequence\n",
    "                vec1 = np.concatenate([task_ids_dict[k],incorrect_vec])\n",
    "                vec2 = np.concatenate([incorrect_vec,task_ids_dict[k]])\n",
    "                temp = 0\n",
    "                for j in range(sequence_lengths[i]): #up to natural sequence length\n",
    "                    if(np.argmax(y_true[i][j]) == np.argmax(vec1)): #correct\n",
    "                        true.append(1.)\n",
    "                        pred.append(y_pred[i][j][np.argmax(vec1)])\n",
    "                    elif (np.argmax(y_true[i][j]) == np.argmax(vec2)): #incorrect\n",
    "                        true.append(0.)\n",
    "                        pred.append(1.0 - y_pred[i][j][np.argmax(vec2)])\n",
    "            auc[k] = roc_auc_score(true, pred)\n",
    "            print(str(k) + \": \"+str(auc[k]))\n",
    "        return auc\n",
    "    else:\n",
    "        con_y_true = np.zeros([sum(sequence_lengths), length_interaction_vector])\n",
    "        con_y_pred = np.zeros([sum(sequence_lengths), length_interaction_vector], dtype=np.float)\n",
    "        index = 0\n",
    "        for i in range(len(y_true)): #per sequence\n",
    "            for j in range(sequence_lengths[i]): #up to the sequence length\n",
    "                con_y_true[index] = y_true[i][j]\n",
    "                con_y_pred[index] = y_pred[i][j]\n",
    "                index += 1\n",
    "        con1_y_true = np.zeros([sum(sequence_lengths)])\n",
    "        con1_y_pred = np.zeros([sum(sequence_lengths)])\n",
    "        right = 0\n",
    "        for l in range(sum(sequence_lengths)): # go per interaction vector\n",
    "            index_one = np.argmax(con_y_true[l]) #detect its indices!, index_two => correct\n",
    "            if(index_one >= int(length_interaction_vector/2)):\n",
    "                index_two = index_one - int(length_interaction_vector/2)\n",
    "            else:\n",
    "                index_two = index_one\n",
    "                index_one = index_one + int(length_interaction_vector/2)\n",
    "            if(np.argmax(con_y_true[l]) == index_one): #true is incorrect\n",
    "                con1_y_true[l] = 0.\n",
    "                con1_y_pred[l] = 1.0 - con_y_pred[l][index_one]\n",
    "            elif(np.argmax(con_y_true[l]) == index_two):\n",
    "                right += 1\n",
    "                con1_y_true[l] = 1.\n",
    "                con1_y_pred[l] = con_y_pred[l][index_two]\n",
    "        if(debug):\n",
    "            print(np.c_[con1_y_true,con1_y_pred])\n",
    "        fpr, tpr, thresholds = roc_curve(con1_y_true, con1_y_pred)\n",
    "        #print(\"tpr: \"+str(tpr) + \", fpr: \"+str(fpr) + \", thresholds: \"+str(thresholds))\n",
    "        if(plot):\n",
    "            return [roc_auc_score(con1_y_true, con1_y_pred),fpr,tpr]\n",
    "        else:\n",
    "            return [roc_auc_score(con1_y_true, con1_y_pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-14T23:49:38.693481Z",
     "start_time": "2018-04-14T23:49:38.679592Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "load and save model functions\n",
    "'''\n",
    "def loadmodel(session, saver, checkpoint_dir):\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n",
    "        saver.restore(session, os.path.join(checkpoint_dir, ckpt_name))\n",
    "        print(\"Model restored successfully\")\n",
    "        return int(ckpt_name[6:])\n",
    "    else:\n",
    "        print(\"No pre-trained model exists, starting from the beginning!\")\n",
    "        return 0\n",
    "\n",
    "def save(session, saver, checkpoint_dir, step):\n",
    "    dir1 = os.path.join(checkpoint_dir, \"model\")\n",
    "    saver.save(session, dir1, global_step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-15T00:02:02.768370Z",
     "start_time": "2018-04-15T00:02:01.962672Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Build the model\n",
    "'''\n",
    "\n",
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(1234)\n",
    "\n",
    "#defining placeholders\n",
    "x = tf.placeholder(tf.float32, [None, None, length_interaction_vector])\n",
    "y = tf.placeholder(tf.float32, [None, None, length_interaction_vector])\n",
    "seqlen_tf = tf.placeholder(tf.float32,[None])\n",
    "\n",
    "#variables\n",
    "converged = tf.Variable(0,trainable=False)\n",
    "number_of_units = 50\n",
    "learning_rate = 0.01\n",
    "\n",
    "#dynamic RNN definition\n",
    "def dynamicRNN(x):\n",
    "    rnn_cell = tf.nn.rnn_cell.BasicLSTMCell(number_of_units)\n",
    "    outputs, states = tf.nn.dynamic_rnn(rnn_cell, x, dtype=tf.float32,sequence_length=seqlen_tf)\n",
    "    out_size = int(length_interaction_vector / 2)\n",
    "    outputs = tf.contrib.layers.fully_connected(outputs, out_size, activation_fn = tf.nn.sigmoid, weights_initializer=tf.contrib.layers.xavier_initializer(uniform=False))\n",
    "    opposites = tf.subtract(tf.ones(tf.shape(outputs)),outputs)\n",
    "    outputs1 = tf.concat([outputs,opposites],2)\n",
    "    return outputs1\n",
    "\n",
    "#making predictions\n",
    "pred = dynamicRNN(x)\n",
    "pred = pred*y\n",
    "# Define loss and optimizer\n",
    "cost1 = tf.nn.sigmoid_cross_entropy_with_logits(logits=pred, labels=y)\n",
    "mask = tf.cast(tf.sequence_mask(lengths = train_mask['overall'], maxlen = max(train_Seqlen['overall'])), tf.float32)\n",
    "cost1 = tf.multiply(cost1,tf.transpose(mask, perm=[0, 2, 1]))\n",
    "cost1 = tf.reduce_sum(cost1, 1)\n",
    "cost1 /= tf.cast(train_mask['overall'],tf.float32)\n",
    "cost = tf.reduce_mean(cost1)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "saver = tf.train.Saver(max_to_keep=5)\n",
    "saver_url = 'saved_models/3_combined_model_C_temp/model.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-15T00:02:06.744481Z",
     "start_time": "2018-04-15T00:02:06.724224Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "All the recorders\n",
    "'''\n",
    "predictions = {}\n",
    "for i in ['train','test1','test2']:\n",
    "    predictions[i] = {}\n",
    "    for j in task_ids:\n",
    "        predictions[i][j] = []\n",
    "    predictions[i]['overall'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-15T00:03:00.524633Z",
     "start_time": "2018-04-15T00:02:06.987560Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No pre-trained model exists, starting from the beginning!\n",
      "converged = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:10: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC (similar to 1b): [0.5349127843683255]\n",
      "Training AUC (similar to 1a): \n",
      "p7cfRPp-kQ.partb: [0.5302671543327089]\n",
      "Ok-iIHxjgx.partb: [0.617363705497917]\n",
      "1zsCldT4p8.set1: [0.5583886691389912]\n",
      "DebcfZEEmI.proper_fractions: [0.5279045138430832]\n",
      "9wRCzK1G7F.partb: [0.40397778990220423]\n",
      "1zsCldT4p8.set2: [0.5313520979124996]\n",
      "nl-M69Ez9k.parta: [0.5655908573571657]\n",
      "kvig7fcCVc.partb: [0.5755679310749697]\n",
      "Ok-iIHxjgx.parta: [0.6940359477124182]\n",
      "hyei4uD81i.parta: [0.5979811778992107]\n",
      "Test AUC 1b: [0.6176039047875846]\n",
      "Test AUC 1a: \n",
      "p7cfRPp-kQ.partb: [0.6271112670200603]\n",
      "Ok-iIHxjgx.partb: [0.6721561565642837]\n",
      "1zsCldT4p8.set1: [0.48478472714386955]\n",
      "DebcfZEEmI.proper_fractions: [0.5516947840891503]\n",
      "9wRCzK1G7F.partb: [0.4008856528496306]\n",
      "1zsCldT4p8.set2: [0.5427974257187538]\n",
      "nl-M69Ez9k.parta: [0.5253882355878461]\n",
      "kvig7fcCVc.partb: [0.6565848214285714]\n",
      "Ok-iIHxjgx.parta: [0.7087287712287713]\n",
      "hyei4uD81i.parta: [0.5453576687592032]\n",
      "Test AUC 2a: [0.5967403896059364]\n",
      "Test AUC 2b: \n",
      "p7cfRPp-kQ.partb: 0.6271112670200603\n",
      "Ok-iIHxjgx.partb: 0.6976658059255232\n",
      "1zsCldT4p8.set1: 0.47727675407512404\n",
      "DebcfZEEmI.proper_fractions: 0.45096634396952434\n",
      "9wRCzK1G7F.partb: 0.427536848977738\n",
      "1zsCldT4p8.set2: 0.5345122097918922\n",
      "nl-M69Ez9k.parta: 0.5131357201707738\n",
      "kvig7fcCVc.partb: 0.6829241071428571\n",
      "Ok-iIHxjgx.parta: 0.7199363136863136\n",
      "hyei4uD81i.parta: 0.6289235061613578\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training AUC (similar to 1b): [0.5234493681226631]\n",
      "Training AUC (similar to 1a): \n",
      "p7cfRPp-kQ.partb: [0.5267366730810894]\n",
      "Ok-iIHxjgx.partb: [0.5113358004852195]\n",
      "1zsCldT4p8.set1: [0.5480495216433388]\n",
      "DebcfZEEmI.proper_fractions: [0.5090042315338903]\n",
      "9wRCzK1G7F.partb: [0.47660709870238777]\n",
      "1zsCldT4p8.set2: [0.501713188753502]\n",
      "nl-M69Ez9k.parta: [0.5404720295656567]\n",
      "kvig7fcCVc.partb: [0.5584014526727479]\n",
      "Ok-iIHxjgx.parta: [0.5592787114845938]\n",
      "hyei4uD81i.parta: [0.6809097348714834]\n",
      "Test AUC 1b: [0.5747815606993175]\n",
      "Test AUC 1a: \n",
      "p7cfRPp-kQ.partb: [0.5783377507535599]\n",
      "Ok-iIHxjgx.partb: [0.5510430823593367]\n",
      "1zsCldT4p8.set1: [0.5126461729270021]\n",
      "DebcfZEEmI.proper_fractions: [0.5148458992166398]\n",
      "9wRCzK1G7F.partb: [0.46167848246790566]\n",
      "1zsCldT4p8.set2: [0.5072356549981956]\n",
      "nl-M69Ez9k.parta: [0.526752053529074]\n",
      "kvig7fcCVc.partb: [0.5982142857142857]\n",
      "Ok-iIHxjgx.parta: [0.6083916083916084]\n",
      "hyei4uD81i.parta: [0.6257265752150662]\n",
      "Test AUC 2a: [0.561072312526399]\n",
      "Test AUC 2b: \n",
      "p7cfRPp-kQ.partb: 0.5783377507535599\n",
      "Ok-iIHxjgx.partb: 0.5367898885566731\n",
      "1zsCldT4p8.set1: 0.49264705882352944\n",
      "DebcfZEEmI.proper_fractions: 0.49945828819068255\n",
      "9wRCzK1G7F.partb: 0.5\n",
      "1zsCldT4p8.set2: 0.5\n",
      "nl-M69Ez9k.parta: 0.5\n",
      "kvig7fcCVc.partb: 0.5\n",
      "Ok-iIHxjgx.parta: 0.5\n",
      "hyei4uD81i.parta: 0.5885646748818104\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Model has converged!\n",
      "Training AUC (similar to 1b): [0.5233219671228552]\n",
      "Training AUC (similar to 1a): \n",
      "p7cfRPp-kQ.partb: [0.5267366730810894]\n",
      "Ok-iIHxjgx.partb: [0.5113358004852195]\n",
      "1zsCldT4p8.set1: [0.5480495216433388]\n",
      "DebcfZEEmI.proper_fractions: [0.5090042315338903]\n",
      "9wRCzK1G7F.partb: [0.47660709870238777]\n",
      "1zsCldT4p8.set2: [0.501713188753502]\n",
      "nl-M69Ez9k.parta: [0.5404720295656567]\n",
      "kvig7fcCVc.partb: [0.5584014526727479]\n",
      "Ok-iIHxjgx.parta: [0.5592787114845938]\n",
      "hyei4uD81i.parta: [0.5381786328678405]\n",
      "Test AUC 1b: [0.5738012919324748]\n",
      "Test AUC 1a: \n",
      "p7cfRPp-kQ.partb: [0.5783377507535599]\n",
      "Ok-iIHxjgx.partb: [0.5510430823593367]\n",
      "1zsCldT4p8.set1: [0.5126461729270021]\n",
      "DebcfZEEmI.proper_fractions: [0.5148458992166398]\n",
      "9wRCzK1G7F.partb: [0.46167848246790566]\n",
      "1zsCldT4p8.set2: [0.5072356549981956]\n",
      "nl-M69Ez9k.parta: [0.526752053529074]\n",
      "kvig7fcCVc.partb: [0.5982142857142857]\n",
      "Ok-iIHxjgx.parta: [0.6083916083916084]\n",
      "hyei4uD81i.parta: [0.5731419049833373]\n",
      "Test AUC 2a: [0.5610140594485323]\n",
      "Test AUC 2b: \n",
      "p7cfRPp-kQ.partb: 0.5783377507535599\n",
      "Ok-iIHxjgx.partb: 0.5367898885566731\n",
      "1zsCldT4p8.set1: 0.49264705882352944\n",
      "DebcfZEEmI.proper_fractions: 0.5\n",
      "9wRCzK1G7F.partb: 0.5\n",
      "1zsCldT4p8.set2: 0.5\n",
      "nl-M69Ez9k.parta: 0.5\n",
      "kvig7fcCVc.partb: 0.5\n",
      "Ok-iIHxjgx.parta: 0.5\n",
      "hyei4uD81i.parta: 0.5651302022785398\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Training the model\n",
    "'''\n",
    "display_step = 20\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    cost_prev = 1.0\n",
    "    stop = False\n",
    "    step = loadmodel(sess, saver,saver_url)\n",
    "    print(\"converged = \"+str(converged.eval()))\n",
    "    if(sess.run(converged) == 1):\n",
    "        print(\"Model has already converged! Stop training\")\n",
    "        stop = True\n",
    "        \n",
    "    \n",
    "    while(stop == False):\n",
    "        # train on train_X['overall']\n",
    "        sess.run(optimizer, feed_dict={x: train_X['overall'], y: train_Y['overall'], seqlen_tf: train_Seqlen['overall']})\n",
    "        step += 1\n",
    "        if step % display_step == 0 or step == 1:\n",
    "            # first lets check convergence\n",
    "            loss = sess.run(cost, feed_dict={x: train_X['overall'], y: train_Y['overall'], seqlen_tf: train_Seqlen['overall']})\n",
    "            cost_current = loss\n",
    "            if cost_prev - cost_current <= 0.00005:\n",
    "                stop = True\n",
    "                sess.run(converged.assign(1))\n",
    "                print(\"Model has converged!\")\n",
    "            else:\n",
    "                cost_prev = cost_current\n",
    "                \n",
    "            # save the model\n",
    "            save(sess, saver, saver_url, step)\n",
    "\n",
    "            # report the AUC scores till now\n",
    "            # train AUC\n",
    "            predict = sess.run(pred, feed_dict={x: train_X['overall'], y: train_Y['overall'], seqlen_tf: train_Seqlen['overall']})\n",
    "            predictions['train']['overall'].append(predict)\n",
    "            print(\"Training AUC (similar to 1b): \"+str(calculate_auc(train_Y['overall'], predict, train_Seqlen['overall'])))\n",
    "            print(\"Training AUC (similar to 1a): \")\n",
    "            for i in task_ids:\n",
    "                predict = sess.run(pred, feed_dict={x: train_X[i], y: train_Y[i], seqlen_tf: train_Seqlen[i]})\n",
    "                predictions['train'][i].append(predict)\n",
    "                print(str(i)+\": \"+str(calculate_auc(train_Y[i], predict, sequence_lengths= train_Seqlen[i])))\n",
    "            \n",
    "            \n",
    "            # test AUC 1\n",
    "            predict = sess.run(pred, feed_dict={x: test_1_X['overall'], y: test_1_Y['overall'], seqlen_tf: test_1_Seqlen['overall']})\n",
    "            predictions['test1']['overall'].append(predict)\n",
    "            print(\"Test AUC 1b: \"+str(calculate_auc(test_1_Y['overall'], predict, test_1_Seqlen['overall'])))\n",
    "            print(\"Test AUC 1a: \")\n",
    "            for i in task_ids:\n",
    "                predict = sess.run(pred, feed_dict={x: test_1_X[i], y: test_1_Y[i], seqlen_tf: test_1_Seqlen[i]})\n",
    "                predictions['test1'][i].append(predict)\n",
    "                print(str(i)+\": \"+str(calculate_auc(test_1_Y[i], predict, test_1_Seqlen[i])))\n",
    "            \n",
    "            # test AUC 2\n",
    "            predict = sess.run(pred, feed_dict={x: test_2_X['overall'], y: test_2_Y['overall'], seqlen_tf: test_2_Seqlen['overall']})\n",
    "            predictions['test2']['overall'].append(predict)\n",
    "            print(\"Test AUC 2a: \"+str(calculate_auc(test_2_Y['overall'], predict, test_2_Seqlen['overall'])))\n",
    "            print(\"Test AUC 2b: \")\n",
    "            ans = calculate_auc(test_2_Y['overall'], predict, test_2_Seqlen['overall'], _2b = True)\n",
    "            print(\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
