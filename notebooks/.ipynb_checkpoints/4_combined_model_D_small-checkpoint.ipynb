{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-10T19:02:13.345219Z",
     "start_time": "2018-04-10T19:02:10.322369Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pprint as pp\n",
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from collections import Counter\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "def save_obj(obj, name ):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f)\n",
    "        \n",
    "def load_obj(name ):\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-10T19:02:14.792014Z",
     "start_time": "2018-04-10T19:02:14.788469Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 1.4.1\n"
     ]
    }
   ],
   "source": [
    "print(\"Tensorflow version: \" + str(tf.VERSION))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-10T19:02:16.894286Z",
     "start_time": "2018-04-10T19:02:16.744716Z"
    }
   },
   "outputs": [],
   "source": [
    "filepath = \"../data/student_vectors_n_task_10_n_limit_10000.json\"\n",
    "student_vectors = json.load(open(filepath))\n",
    "#filepath2 = \"../../../student_vectors_n_task_10_n_limit_100000.json\"\n",
    "#student_vectors2 = json.load(open(filepath2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stats on Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-10T19:12:24.518079Z",
     "start_time": "2018-04-10T19:12:24.223848Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique task IDs: 10\n",
      "Number of students: 1255\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1176c4ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task IDs mapping: \n",
      "Task ID -> p7cfRPp-kQ.partb(1) is attempted 7259 times. Max seq len: 46\n",
      "Task ID -> Ok-iIHxjgx.partb(2) is attempted 2325 times. Max seq len: 27\n",
      "Task ID -> 1zsCldT4p8.set1(3) is attempted 6346 times. Max seq len: 39\n",
      "Task ID -> DebcfZEEmI.proper_fractions(4) is attempted 6897 times. Max seq len: 40\n",
      "Task ID -> 9wRCzK1G7F.partb(5) is attempted 6632 times. Max seq len: 43\n",
      "Task ID -> 1zsCldT4p8.set2(6) is attempted 6443 times. Max seq len: 28\n",
      "Task ID -> nl-M69Ez9k.parta(7) is attempted 4753 times. Max seq len: 56\n",
      "Task ID -> kvig7fcCVc.partb(8) is attempted 3473 times. Max seq len: 32\n",
      "Task ID -> Ok-iIHxjgx.parta(9) is attempted 1589 times. Max seq len: 39\n",
      "Task ID -> hyei4uD81i.parta(10) is attempted 1255 times. Max seq len: 40\n"
     ]
    }
   ],
   "source": [
    "#Stats on data and building another_2\n",
    "'''\n",
    "task_ids = skill IDs stored in a list.\n",
    "cnt2 = counter of all attempts of skill IDs \n",
    "another_2 = a dictionary with skill IDs as keys and position (int key) of that skill in cnt2 as values\n",
    "seqlen_tasks = dictionary with skill IDs as keys and sequence lengths for that skill as array as keys\n",
    "'''\n",
    "\n",
    "# we make task_ids now\n",
    "task_ids = []\n",
    "for i in student_vectors:\n",
    "    for j in student_vectors[i]:\n",
    "        if j['task_id'] not in task_ids:\n",
    "            task_ids.append(j['task_id'])\n",
    "print(\"Number of unique task IDs: \" + str(len(task_ids)))\n",
    "print(\"Number of students: \" + str(len(student_vectors)))\n",
    "\n",
    "# making another_2 and cnt2 now\n",
    "# plotting frequency distribution of taskids\n",
    "cnt2 = Counter()\n",
    "another_2 = {}\n",
    "seqlen_tasks = {}\n",
    "temp_seqlen = {}\n",
    "position_2 = 1\n",
    "for i in student_vectors:\n",
    "    for k in temp_seqlen:\n",
    "        temp_seqlen[k] = 0\n",
    "    for j in student_vectors[i]:\n",
    "        if(j['second_try'] == False):\n",
    "            if j['task_id'] not in another_2:\n",
    "                another_2[j['task_id']] = str(position_2)\n",
    "                position_2 = position_2 + 1\n",
    "            if j['task_id'] not in seqlen_tasks:\n",
    "                seqlen_tasks[j['task_id']] = []\n",
    "\n",
    "            if j['task_id'] not in temp_seqlen:\n",
    "                temp_seqlen[j['task_id']] = 1\n",
    "            else:\n",
    "                temp_seqlen[j['task_id']] += 1\n",
    "            cnt2[another_2[j['task_id']]] += 1\n",
    "    for k in seqlen_tasks:\n",
    "        seqlen_tasks[k].append(temp_seqlen[k])\n",
    "plt.bar(cnt2.keys(), cnt2.values())\n",
    "plt.title(\"Task IDs distribution\")\n",
    "plt.xlabel(\"Frequency of task ID across all students\")\n",
    "plt.ylabel(\"Task IDs\")\n",
    "plt.show()\n",
    "print(\"Task IDs mapping: \")\n",
    "for i in another_2:\n",
    "    print(\"Task ID -> \"+str(i)+\"(\"+str(another_2[i])+\") is attempted \" + str(cnt2[another_2[i]]) + \" times.\" + \" Max seq len: \"+str(max(seqlen_tasks[i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-10T19:31:42.387711Z",
     "start_time": "2018-04-10T19:31:42.181155Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Till now, there has been no split between test and train set!\n",
    "task_ids_dict = dictionary with skill IDs as keys and their one-hot encoding as values\n",
    "sequences = X\n",
    "output_y = Y\n",
    "seqlen = sequence length\n",
    "length_interaction_vector = twice the number of skill IDs because that's how our encoding works, right now\n",
    "'''\n",
    "\n",
    "#pre-processing for using MultiLabelBinarizer\n",
    "temp_ids = [[x] for x in task_ids]\n",
    "\n",
    "#generating encodings\n",
    "enc = MultiLabelBinarizer()\n",
    "task_ids_1hot = (enc.fit_transform(temp_ids)).astype(float)\n",
    "task_ids_dict = dict(zip(task_ids, task_ids_1hot))\n",
    "# print(\"\\n1-hot encoding for task IDs:\")\n",
    "# pp.pprint(task_ids_dict)\n",
    "\n",
    "sequences = []\n",
    "output_y = []\n",
    "seqlen = []\n",
    "incorrect_tid_vec = np.zeros((len(task_ids)), dtype=np.float)\n",
    "for i in student_vectors:\n",
    "    temp_seq = []\n",
    "    temp_seq.append(np.concatenate([incorrect_tid_vec,incorrect_tid_vec])) #for taking first prediction into account\n",
    "    for j in student_vectors[i]:\n",
    "        if(j['second_try'] == False): #ignoring second_try\n",
    "            if(j['correct'] == True):\n",
    "                vec = np.concatenate([task_ids_dict[j['task_id']],incorrect_tid_vec])\n",
    "                temp_seq.append(np.asarray(vec))\n",
    "            else:\n",
    "                vec = np.concatenate([incorrect_tid_vec,task_ids_dict[j['task_id']]])\n",
    "                temp_seq.append(np.asarray(vec))\n",
    "    if(len(temp_seq)>1):\n",
    "        seqlen.append(len(temp_seq)-1)\n",
    "        last_one = temp_seq.pop() #remove last interaction vector\n",
    "        sequences.append(np.asarray(temp_seq)) #add it to x\n",
    "        first_one = temp_seq.pop(0) #remove first interaction vector\n",
    "        temp_seq.append(last_one)\n",
    "        output_y.append(np.asarray(temp_seq)) #concatenate with last vector, and append to output! \n",
    "\n",
    "length_interaction_vector = 2*(len(task_ids)) #length of interaction vector\n",
    "# print(\"Sample interaction vector: \")\n",
    "# pp.pprint(sequences[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-10T19:31:52.981411Z",
     "start_time": "2018-04-10T19:31:52.972760Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting 1255 rows (or students) into 1004 for training and rest for testing.\n",
      "Number of recurrent units = 50\n",
      "Learning rate = 0.1\n",
      "display step = 20\n"
     ]
    }
   ],
   "source": [
    "training_set_split = 0.8\n",
    "split = int((training_set_split)*len(student_vectors))\n",
    "print(\"Splitting \"+str(len(student_vectors))+\" rows (or students) into \"+str(split)+ \" for training and rest for testing.\")\n",
    "num_units = 50\n",
    "print(\"Number of recurrent units = \"+str(num_units))\n",
    "l_r1 = 0.1\n",
    "print(\"Learning rate = \"+str(l_r1))\n",
    "display_step = 20\n",
    "print(\"display step = \"+str(display_step))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-10T19:40:14.666997Z",
     "start_time": "2018-04-10T19:40:14.395188Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "We take one skill at a time and go through student_vectors each time. This way, all skill IDs will be in sequence, all skill IDs 1 will be before skill ID 2. Then we randomize this.\n",
    "This is the exact data to prepare for training with model D! \n",
    "The test set is for evaluation: 2a... FOUND THE BUG! this is not 2a\n",
    "sequences_test = X for test set\n",
    "sequences_train = X for train set\n",
    "output_y_train = Y for train set\n",
    "output_y_test = Y for test set\n",
    "seqlen_train = sequence length for train set\n",
    "seqlen_test = sequence length for test set\n",
    "sequences_lengths1_train = for using as mask in train set\n",
    "sequences_lengths1_test = for using as mask in test set\n",
    "'''\n",
    "\n",
    "sequences_test = []\n",
    "sequences_train = []\n",
    "output_y_train = []\n",
    "output_y_test = []\n",
    "seqlen_train = []\n",
    "seqlen_test = []\n",
    "sequences_lengths1_train = [] #for passing to mask\n",
    "sequences_lengths1_test = [] #for passing to mask\n",
    "incorrect_tid_vec = np.zeros((len(task_ids)), dtype=np.float)\n",
    "\n",
    "for l in another_2:\n",
    "    for idx,i in enumerate(student_vectors):\n",
    "        temp_seq = []\n",
    "        temp_seq.append(np.concatenate([incorrect_tid_vec,incorrect_tid_vec])) #for taking first prediction into account\n",
    "        for j in student_vectors[i]:\n",
    "            if(j['second_try'] == False and j['task_id'] == l): #ignoring second_try\n",
    "                if(j['correct'] == True):\n",
    "                    vec = np.concatenate([task_ids_dict[j['task_id']],incorrect_tid_vec])\n",
    "                    temp_seq.append(vec)\n",
    "                else:\n",
    "                    vec = np.concatenate([incorrect_tid_vec,task_ids_dict[j['task_id']]])\n",
    "                    temp_seq.append(vec)\n",
    "        if(len(temp_seq)>1):\n",
    "            if(idx < split):\n",
    "                seqlen_train.append(len(temp_seq)-1)\n",
    "                sequences_lengths1_train.append([len(temp_seq)-1]) \n",
    "                last_one = temp_seq.pop() #remove last interaction vector\n",
    "                sequences_train.append(temp_seq) #add it to x\n",
    "                first_one = temp_seq.pop(0) #remove first interaction vector\n",
    "                temp_seq.append(last_one)\n",
    "                output_y_train.append(temp_seq) #concatenate with last vector, and append to output! \n",
    "            else:\n",
    "                seqlen_test.append(len(temp_seq)-1)\n",
    "                sequences_lengths1_test.append([len(temp_seq)-1]) \n",
    "                last_one = temp_seq.pop() #remove last interaction vector\n",
    "                sequences_test.append(temp_seq) #add it to x\n",
    "                first_one = temp_seq.pop(0) #remove first interaction vector\n",
    "                temp_seq.append(last_one)\n",
    "                output_y_test.append(temp_seq) #concatenate with last vector, and append to output! \n",
    "    \n",
    "# print(\"Sample interaction vector: \")\n",
    "# pp.pprint(sequences[0][0])\n",
    "length_interaction_vector = 2*(len(task_ids)) #length of interaction vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding maximum sequence length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-10T19:40:30.631770Z",
     "start_time": "2018-04-10T19:40:30.627145Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sequence length: 56\n"
     ]
    }
   ],
   "source": [
    "max_seqlen1 = max(seqlen_train)\n",
    "max_seqlen2 = max(seqlen_test)\n",
    "max_seqlen = max(max_seqlen1,max_seqlen2)\n",
    "print(\"Maximum sequence length: \"+str(max_seqlen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-10T18:59:35.616164Z",
     "start_time": "2018-04-10T18:59:35.440318Z"
    }
   },
   "outputs": [],
   "source": [
    "training_x = np.zeros(shape=(len(sequences_train),max_seqlen,length_interaction_vector),dtype=float)\n",
    "training_y = np.zeros(shape=(len(sequences_train),max_seqlen,length_interaction_vector),dtype=float)\n",
    "for i in range(len(sequences_train)):\n",
    "    for j in range(len(sequences_train[i])):\n",
    "        training_x[i][j] = sequences_train[i][j]\n",
    "        training_y[i][j] = output_y_train[i][j]\n",
    "training_seqlen = np.zeros_like(seqlen_train)\n",
    "training_seqlen = seqlen_train\n",
    "print(\"Sequences have been padded according to the maximum sequence length. Final shape: \" + str(training_x.shape))\n",
    "\n",
    "test_x = np.zeros(shape=(len(sequences_test),max_seqlen,length_interaction_vector),dtype=float)\n",
    "test_y = np.zeros(shape=(len(sequences_test),max_seqlen,length_interaction_vector),dtype=float)\n",
    "test_seqlen = np.zeros_like(seqlen_test)\n",
    "test_seqlen = seqlen_test\n",
    "for i in range(len(sequences_test)):\n",
    "    for j in range(len(sequences_test[i])):\n",
    "        test_x[i][j] = sequences_test[i][j]        \n",
    "        test_y[i][j] = output_y_test[i][j]\n",
    "print(\"Final test shape: \" + str(test_x.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-10T07:15:31.734362Z",
     "start_time": "2018-04-10T07:15:29.725196Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(1234)\n",
    "#defining placeholders\n",
    "x = tf.placeholder(tf.float32, [None, None, length_interaction_vector])\n",
    "y = tf.placeholder(tf.float32, [None, None, length_interaction_vector])\n",
    "seqlen_tf = tf.placeholder(tf.float32,[None])\n",
    "condition = tf.placeholder(tf.int32, shape=[], name=\"condition\")\n",
    "converged = tf.Variable(0)\n",
    "\n",
    "#defining tensorflow variables\n",
    "learning_tf_rate = tf.Variable(0.0, name=\"learning_tf_rate\",dtype=tf.float32,trainable=False)\n",
    "\n",
    "#dynamic RNN definition\n",
    "def dynamicRNN(x):\n",
    "    rnn_cell = tf.nn.rnn_cell.BasicLSTMCell(num_units)\n",
    "    outputs, states = tf.nn.dynamic_rnn(rnn_cell, x, dtype=tf.float32,sequence_length=seqlen_tf)\n",
    "    out_size = int(length_interaction_vector / 2)\n",
    "    outputs = tf.contrib.layers.fully_connected(outputs, out_size, activation_fn = tf.nn.sigmoid, weights_initializer=tf.contrib.layers.xavier_initializer(uniform=False))\n",
    "    opposites = tf.subtract(tf.ones(tf.shape(outputs)),outputs)\n",
    "    outputs1 = tf.concat([outputs,opposites],2)\n",
    "    return outputs1\n",
    "\n",
    "#making predictions\n",
    "pred = dynamicRNN(x)\n",
    "pred = pred*y\n",
    "# Define loss and optimizer\n",
    "cost1 = tf.nn.sigmoid_cross_entropy_with_logits(logits=pred, labels=y)\n",
    "mask = tf.cond(condition < 1, lambda: tf.cast(tf.sequence_mask(lengths=sequences_lengths1_train, maxlen = max_seqlen), tf.float32), lambda: tf.cast(tf.sequence_mask(lengths=sequences_lengths1_test, maxlen = max_seqlen), tf.float32))\n",
    "cost1 = tf.multiply(cost1,tf.transpose(mask, perm=[0, 2, 1]))\n",
    "cost1 = tf.reduce_sum(cost1, 1)\n",
    "cost1 /= tf.cond(condition < 1, lambda: tf.cast(sequences_lengths1_train,tf.float32), lambda: tf.cast(sequences_lengths1_test,tf.float32) )\n",
    "cost = tf.reduce_mean(cost1)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_tf_rate).minimize(cost)\n",
    "\n",
    "saver = tf.train.Saver(max_to_keep=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partitioning test set into separate task IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-10T07:15:56.296074Z",
     "start_time": "2018-04-10T07:15:55.995212Z"
    }
   },
   "outputs": [],
   "source": [
    "test_x_list_dict = {}\n",
    "test_y_list_dict = {}\n",
    "test_seqlen_list_dict = {}\n",
    "train_x_list_dict = {}\n",
    "train_y_list_dict = {}\n",
    "train_seqlen_list_dict = {}\n",
    "split_dict = {}\n",
    "\n",
    "for i in another_2: \n",
    "    #generate encoding here! \n",
    "    sequences = []\n",
    "    sequences_lengths = []\n",
    "    for p in student_vectors:\n",
    "        interactions = []\n",
    "        interactions.append(np.concatenate([incorrect_tid_vec,incorrect_tid_vec])) #for getting the first prediction!\n",
    "        for j in student_vectors[p]:\n",
    "            if(j['task_id'] == i and j['second_try'] == False):\n",
    "                if(j['correct'] == True):\n",
    "                    vec = np.concatenate([task_ids_dict[j['task_id']],incorrect_tid_vec])\n",
    "                    interactions.append(vec)\n",
    "                else:\n",
    "                    interactions.append(np.concatenate([incorrect_tid_vec,task_ids_dict[j['task_id']]]))\n",
    "        if(len(interactions) > 1):\n",
    "            sequences_lengths.append(len(interactions)-1)\n",
    "            sequences.append(interactions)\n",
    "    split = int(0.8*len(sequences))\n",
    "    #add padding\n",
    "    padded_sequences = np.zeros([len(sequences),max_seqlen+1,length_interaction_vector])\n",
    "    for p in range(len(sequences)):\n",
    "        for j in range(len(sequences[p])):\n",
    "            padded_sequences[p][j] = sequences[p][j]\n",
    "    test_x_list_dict[i] = padded_sequences[split:,:-1]\n",
    "    test_y_list_dict[i] = padded_sequences[split:,1:]\n",
    "    test_seqlen_list_dict[i] = sequences_lengths[split:]\n",
    "    train_x_list_dict[i] = padded_sequences[:split,:-1]\n",
    "    train_y_list_dict[i] = padded_sequences[:split,1:]\n",
    "    train_seqlen_list_dict[i] = sequences_lengths[:split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-10T07:16:04.303819Z",
     "start_time": "2018-04-10T07:16:04.193582Z"
    }
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=np.nan)\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "def calculate_auc (y_true,y_pred,sequence_lengths=[],plot=False,debug=False):\n",
    "    if sequence_lengths == []:\n",
    "        return roc_auc_score(y_true, y_pred)\n",
    "    else:\n",
    "        con_y_true = np.zeros([sum(sequence_lengths),length_interaction_vector])\n",
    "        con_y_pred = np.zeros([sum(sequence_lengths),length_interaction_vector])\n",
    "        index = 0\n",
    "        for i in range(len(y_true)): #per student\n",
    "            for j in range(sequence_lengths[i]): #up to the sequence length\n",
    "                con_y_true[index] = y_true[i][j]\n",
    "                con_y_pred[index] = y_pred[i][j]\n",
    "                index += 1\n",
    "        con1_y_true = np.zeros([sum(sequence_lengths)])\n",
    "        con1_y_pred = np.zeros([sum(sequence_lengths)])\n",
    "        \n",
    "        for l in range(sum(sequence_lengths)):\n",
    "            index_one = np.argmax(con_y_true[l])\n",
    "            if(index_one >= int(length_interaction_vector/2)):\n",
    "                index_two = index_one - int(length_interaction_vector/2)\n",
    "            else:\n",
    "                index_two = index_one\n",
    "                index_one = index_one + int(length_interaction_vector/2)\n",
    "            if(np.argmax(con_y_true[l]) == index_one): #true is incorrect\n",
    "                con1_y_true[l] = 0.\n",
    "                con1_y_pred[l] = 1.0 - con_y_pred[l][index_one]\n",
    "            elif(np.argmax(con_y_true[l]) == index_two):\n",
    "                con1_y_true[l] = 1.\n",
    "                con1_y_pred[l] = con_y_pred[l][index_two]\n",
    "        debug=False\n",
    "        if(debug):\n",
    "            print(np.c_[con1_y_true,con1_y_pred])\n",
    "        fpr, tpr, thresholds = roc_curve(con1_y_true, con1_y_pred)\n",
    "        #print(\"tpr: \"+str(tpr) + \", fpr: \"+str(fpr) + \", thresholds: \"+str(thresholds))\n",
    "        if(plot):\n",
    "            return [roc_auc_score(con1_y_true, con1_y_pred),fpr,tpr]\n",
    "        else:\n",
    "            return roc_auc_score(con1_y_true, con1_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-10T07:16:05.549869Z",
     "start_time": "2018-04-10T07:16:05.536764Z"
    }
   },
   "outputs": [],
   "source": [
    "def loadmodel(session, saver, checkpoint_dir):\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n",
    "        saver.restore(session, os.path.join(checkpoint_dir, ckpt_name))\n",
    "        print(\"Model restored successfully\")\n",
    "        return int(ckpt_name[6:])\n",
    "    else:\n",
    "        print(\"No pre-trained model exists, starting from the beginning!\")\n",
    "        return 0\n",
    "\n",
    "def save(session, saver, checkpoint_dir, step):\n",
    "    dir1 = os.path.join(checkpoint_dir, \"model\")\n",
    "    saver.save(session, dir1, global_step=step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-10T07:17:51.069852Z",
     "start_time": "2018-04-10T07:16:33.343773Z"
    }
   },
   "outputs": [],
   "source": [
    "true_all_tasks = {}\n",
    "true_all_tasks['train'] = {}\n",
    "true_all_tasks['test'] = {}\n",
    "predictions_all_tasks = {}\n",
    "predictions_all_tasks['train'] = {}\n",
    "predictions_all_tasks['test'] = {}\n",
    "seqlen_all_tasks = {}\n",
    "seqlen_all_tasks['train'] = {}\n",
    "seqlen_all_tasks['test'] = {}\n",
    "c_seqlen = {}\n",
    "c_seqlen['train'] = {}\n",
    "c_seqlen['test'] = {}\n",
    "for i in another_2:\n",
    "    seqlen_all_tasks['train'][i] = []\n",
    "    seqlen_all_tasks['test'][i] = []\n",
    "    predictions_all_tasks['train'][i] = []\n",
    "    predictions_all_tasks['test'][i] = []\n",
    "    true_all_tasks['train'][i] = []\n",
    "    true_all_tasks['test'][i] = []\n",
    "    c_seqlen['train'][i] = []\n",
    "    c_seqlen['test'][i] = []\n",
    "seqlen_all_tasks['train']['overall'] = []\n",
    "seqlen_all_tasks['test']['overall'] = []\n",
    "predictions_all_tasks['train']['overall'] = []\n",
    "predictions_all_tasks['test']['overall'] = []\n",
    "true_all_tasks['train']['overall'] = []\n",
    "true_all_tasks['test']['overall'] = []\n",
    "c_seqlen['train']['overall'] = []\n",
    "c_seqlen['test']['overall'] = []\n",
    "l_r = l_r1\n",
    "with tf.Session() as sess:\n",
    "    # Initialize the variables (i.e. assign their default value)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    assign_op = learning_tf_rate.assign(l_r)\n",
    "    sess.run(assign_op)\n",
    "    cost_prev = 1.0\n",
    "    stop = False\n",
    "    saver_url = 'saved_models/4_combined_model_D_small/model.ckpt'\n",
    "    step = loadmodel(sess, saver,saver_url)\n",
    "    print(\"converged = \"+str(converged.eval()))\n",
    "    if(sess.run(converged) == 1):\n",
    "        print(\"model already converged!\")\n",
    "        stop = True\n",
    "        #calculate overall training AUC\n",
    "        loss = sess.run(cost, feed_dict={x: training_x, y: training_y, seqlen_tf: training_seqlen,condition:0})\n",
    "        pred_train,train_cost = sess.run([pred,cost], feed_dict={x: training_x, y: training_y, seqlen_tf: training_seqlen,condition:0})\n",
    "        o_train_opts_taskid = calculate_auc(training_y,pred_train,training_seqlen)\n",
    "        true_all_tasks['train']['overall'].append(training_y)\n",
    "        predictions_all_tasks['train']['overall'].append(pred_train)\n",
    "        seqlen_all_tasks['train']['overall'].append(o_train_opts_taskid)\n",
    "        c_seqlen['train']['overall'].append(training_seqlen)\n",
    "        # Calculate overall test auc\n",
    "        pred_test,test_cost = sess.run([pred,cost],feed_dict={x: test_x, y: test_y, seqlen_tf: test_seqlen,condition:1})\n",
    "        o_temp_opts_taskid = calculate_auc(test_y,pred_test,test_seqlen)\n",
    "        true_all_tasks['test']['overall'].append(test_y)\n",
    "        predictions_all_tasks['test']['overall'].append(pred_test)\n",
    "        seqlen_all_tasks['test']['overall'].append(o_temp_opts_taskid)\n",
    "        c_seqlen['test']['overall'].append(test_seqlen)\n",
    "        #print status\n",
    "        print(\"Epoch \" + str(step) + \", Train loss = \" + str(train_cost) + \", Train AUC = \"+str(o_train_opts_taskid) +\", Test Loss: \"+str(test_cost)+ \", Test AUC: \"+str(o_temp_opts_taskid))\n",
    "        #calculate train and test AUCs on task IDs separately!\n",
    "        for idx,i in enumerate(another_2):\n",
    "            pred_train = sess.run(pred, feed_dict={x: train_x_list_dict[i], y: train_y_list_dict[i], seqlen_tf: train_seqlen_list_dict[i] ,condition:0})\n",
    "            train_opts_taskid = calculate_auc(train_y_list_dict[i],pred_train,train_seqlen_list_dict[i])\n",
    "            true_all_tasks['train'][i].append(train_y_list_dict[i])\n",
    "            predictions_all_tasks['train'][i].append(pred_train)\n",
    "            seqlen_all_tasks['train'][i].append(train_opts_taskid)\n",
    "            c_seqlen['train'][i].append(train_seqlen_list_dict[i])\n",
    "            pred_test = sess.run(pred,feed_dict={x: test_x_list_dict[i], y: test_y_list_dict[i], seqlen_tf: test_seqlen_list_dict[i] ,condition:1})\n",
    "            temp_opts_taskid = calculate_auc(test_y_list_dict[i],pred_test,test_seqlen_list_dict[i])\n",
    "            true_all_tasks['test'][i].append(test_y_list_dict[i])\n",
    "            predictions_all_tasks['test'][i].append(pred_test)\n",
    "            seqlen_all_tasks['test'][i].append(temp_opts_taskid)\n",
    "            c_seqlen['test'][i].append(test_seqlen_list_dict[i])\n",
    "            print(str(i) + \" -> Train AUC = \"+str(train_opts_taskid) + \", Test AUC: \"+str(temp_opts_taskid))\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "        \n",
    "    while(stop == False):\n",
    "    #for step in range(1, training_steps):\n",
    "        sess.run(optimizer, feed_dict={x: training_x, y: training_y, seqlen_tf: training_seqlen,condition:0})\n",
    "        step += 1\n",
    "        if step % display_step == 0 or step == 1:\n",
    "            loss = sess.run(cost, feed_dict={x: training_x, y: training_y, seqlen_tf: training_seqlen,condition:0})\n",
    "            cost_current = loss\n",
    "            if cost_prev - cost_current <= 0.00005:\n",
    "                stop = True\n",
    "                sess.run(converged.assign(1))\n",
    "                print(\"Model has converged!\" + str(converged.eval()))\n",
    "            else:\n",
    "                cost_prev = cost_current\n",
    "            save(sess,saver,saver_url,step)\n",
    "\n",
    "            #calculate overall training AUC\n",
    "            pred_train,train_cost = sess.run([pred,cost], feed_dict={x: training_x, y: training_y, seqlen_tf: training_seqlen,condition:0})\n",
    "            o_train_opts_taskid = calculate_auc(training_y,pred_train,training_seqlen)\n",
    "            true_all_tasks['train']['overall'].append(training_y)\n",
    "            predictions_all_tasks['train']['overall'].append(pred_train)\n",
    "            seqlen_all_tasks['train']['overall'].append(o_train_opts_taskid)\n",
    "            c_seqlen['train']['overall'].append(training_seqlen)\n",
    "            # Calculate overall test auc\n",
    "            pred_test,test_cost = sess.run([pred,cost],feed_dict={x: test_x, y: test_y, seqlen_tf: test_seqlen,condition:1})\n",
    "            o_temp_opts_taskid = calculate_auc(test_y,pred_test,test_seqlen)\n",
    "            true_all_tasks['test']['overall'].append(test_y)\n",
    "            predictions_all_tasks['test']['overall'].append(pred_test)\n",
    "            seqlen_all_tasks['test']['overall'].append(o_temp_opts_taskid)\n",
    "            c_seqlen['test']['overall'].append(test_seqlen)\n",
    "            #print status\n",
    "            print(\"Epoch \" + str(step) + \", Train loss = \" + str(train_cost) + \", Train AUC = \"+str(o_train_opts_taskid) +\", Test Loss: \"+str(test_cost)+ \", Test AUC: \"+str(o_temp_opts_taskid))\n",
    "\n",
    "            #calculate train and test AUCs on task IDs separately!\n",
    "            for idx,i in enumerate(another_2):\n",
    "                pred_train = sess.run(pred, feed_dict={x: train_x_list_dict[i], y: train_y_list_dict[i], seqlen_tf: train_seqlen_list_dict[i] ,condition:0})\n",
    "                train_opts_taskid = calculate_auc(train_y_list_dict[i],pred_train,train_seqlen_list_dict[i])\n",
    "                true_all_tasks['train'][i].append(train_y_list_dict[i])\n",
    "                predictions_all_tasks['train'][i].append(pred_train)\n",
    "                seqlen_all_tasks['train'][i].append(train_opts_taskid)\n",
    "                c_seqlen['train'][i].append(train_seqlen_list_dict[i])\n",
    "                pred_test = sess.run(pred,feed_dict={x: test_x_list_dict[i], y: test_y_list_dict[i], seqlen_tf: test_seqlen_list_dict[i] ,condition:1})\n",
    "                temp_opts_taskid = calculate_auc(test_y_list_dict[i],pred_test,test_seqlen_list_dict[i])\n",
    "                true_all_tasks['test'][i].append(test_y_list_dict[i])\n",
    "                predictions_all_tasks['test'][i].append(pred_test)\n",
    "                seqlen_all_tasks['test'][i].append(temp_opts_taskid)\n",
    "                c_seqlen['test'][i].append(test_seqlen_list_dict[i])\n",
    "                print(str(i) + \" -> Train AUC = \"+str(train_opts_taskid) + \", Test AUC: \"+str(temp_opts_taskid))            \n",
    "            print(\"\\n\\n\")\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "    for idx,i in enumerate(another_2):\n",
    "        pred_test = sess.run(pred,feed_dict={x: test_x_list_dict[i], y: test_y_list_dict[i], seqlen_tf: test_seqlen_list_dict[i] ,condition:1})\n",
    "        true_all_tasks['test'][i].append(test_y_list_dict[i])\n",
    "        predictions_all_tasks['test'][i].append(pred_test)\n",
    "        seqlen_all_tasks['test'][i].append(test_seqlen_list_dict[i])\n",
    "        pred_train = sess.run(pred, feed_dict={x: train_x_list_dict[i], y: train_y_list_dict[i], seqlen_tf: train_seqlen_list_dict[i] ,condition:0})\n",
    "        true_all_tasks['train'][i].append(train_y_list_dict[i])\n",
    "        predictions_all_tasks['train'][i].append(pred_train)\n",
    "        seqlen_all_tasks['train'][i].append(train_seqlen_list_dict[i])\n",
    "\n",
    "    pred_test,test_cost = sess.run([pred,cost],feed_dict={x: test_x, y: test_y, seqlen_tf: test_seqlen,condition:1})\n",
    "    true_all_tasks['test']['overall'].append(test_y)\n",
    "    predictions_all_tasks['test']['overall'].append(pred_test)\n",
    "    seqlen_all_tasks['test']['overall'].append(test_seqlen)\n",
    "    c_seqlen['test']['overall'].append(test_seqlen)\n",
    "    pred_train,train_cost = sess.run([pred,cost], feed_dict={x: training_x, y: training_y, seqlen_tf: training_seqlen,condition:0})\n",
    "    true_all_tasks['train']['overall'].append(training_y)\n",
    "    predictions_all_tasks['train']['overall'].append(pred_train)\n",
    "    seqlen_all_tasks['train']['overall'].append(training_seqlen)\n",
    "    c_seqlen['train']['overall'].append(training_seqlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_all_tasks = {}\n",
    "true_all_tasks['train'] = {}\n",
    "true_all_tasks['test'] = {}\n",
    "predictions_all_tasks = {}\n",
    "predictions_all_tasks['train'] = {}\n",
    "predictions_all_tasks['test'] = {}\n",
    "seqlen_all_tasks = {}\n",
    "seqlen_all_tasks['train'] = {}\n",
    "seqlen_all_tasks['test'] = {}\n",
    "c_seqlen = {}\n",
    "c_seqlen['train'] = {}\n",
    "c_seqlen['test'] = {}\n",
    "for i in another_2:\n",
    "    seqlen_all_tasks['train'][i] = []\n",
    "    seqlen_all_tasks['test'][i] = []\n",
    "    predictions_all_tasks['train'][i] = []\n",
    "    predictions_all_tasks['test'][i] = []\n",
    "    true_all_tasks['train'][i] = []\n",
    "    true_all_tasks['test'][i] = []\n",
    "    c_seqlen['train'][i] = []\n",
    "    c_seqlen['test'][i] = []\n",
    "seqlen_all_tasks['train']['overall'] = []\n",
    "seqlen_all_tasks['test']['overall'] = []\n",
    "predictions_all_tasks['train']['overall'] = []\n",
    "predictions_all_tasks['test']['overall'] = []\n",
    "true_all_tasks['train']['overall'] = []\n",
    "true_all_tasks['test']['overall'] = []\n",
    "c_seqlen['train']['overall'] = []\n",
    "c_seqlen['test']['overall'] = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, 'combined_model_4_n/model.ckpt-20')\n",
    "    for idx,i in enumerate(another_2):\n",
    "        pred_test = sess.run(pred,feed_dict={x: test_x_list_dict[i], y: test_y_list_dict[i], seqlen_tf: test_seqlen_list_dict[i] ,condition:1})\n",
    "        true_all_tasks['test'][i].append(test_y_list_dict[i])\n",
    "        predictions_all_tasks['test'][i].append(pred_test)\n",
    "        seqlen_all_tasks['test'][i].append(test_seqlen_list_dict[i])\n",
    "        pred_train = sess.run(pred, feed_dict={x: train_x_list_dict[i], y: train_y_list_dict[i], seqlen_tf: train_seqlen_list_dict[i] ,condition:0})\n",
    "        true_all_tasks['train'][i].append(train_y_list_dict[i])\n",
    "        predictions_all_tasks['train'][i].append(pred_train)\n",
    "        seqlen_all_tasks['train'][i].append(train_seqlen_list_dict[i])\n",
    "        \n",
    "        view_point = np.argsort(test_seqlen)[1]\n",
    "        prediction = sess.run(pred, feed_dict={x: [test_x[view_point]], y: [test_y[view_point]], seqlen_tf: [test_seqlen[view_point]],condition:1})\n",
    "        print(\"\\n\\ntrue:prediction\\n\")\n",
    "        print(np.c_[test_x[view_point][:test_seqlen[view_point]],prediction[0][:test_seqlen[view_point]]])\n",
    "\n",
    "    pred_test,test_cost = sess.run([pred,cost],feed_dict={x: test_x, y: test_y, seqlen_tf: test_seqlen,condition:1})\n",
    "    true_all_tasks['test']['overall'].append(test_y)\n",
    "    predictions_all_tasks['test']['overall'].append(pred_test)\n",
    "    seqlen_all_tasks['test']['overall'].append(test_seqlen)\n",
    "    c_seqlen['test']['overall'].append(test_seqlen)\n",
    "    pred_train,train_cost = sess.run([pred,cost], feed_dict={x: training_x, y: training_y, seqlen_tf: training_seqlen,condition:0})\n",
    "    true_all_tasks['train']['overall'].append(training_y)\n",
    "    predictions_all_tasks['train']['overall'].append(pred_train)\n",
    "    seqlen_all_tasks['train']['overall'].append(training_seqlen)\n",
    "    c_seqlen['train']['overall'].append(training_seqlen)\n",
    "\n",
    "# predictions_all_tasks = load_obj('predictions_all_tasks')\n",
    "# seqlen_all_tasks = load_obj('seqlen_all_tasks')\n",
    "# c_seqlen = load_obj('c_seqlen')\n",
    "# true_all_tasks = load_obj('true_all_tasks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Calculating over-all AUC\")\n",
    "o_train = calculate_auc(true_all_tasks['train']['overall'][-1],predictions_all_tasks['train']['overall'][-1],c_seqlen['train']['overall'][-1],plot=False)\n",
    "o_test = calculate_auc(true_all_tasks['test']['overall'][-1],predictions_all_tasks['test']['overall'][-1],c_seqlen['test']['overall'][-1],plot=False)\n",
    "print(\"Overall AUC train: \"+str(o_train) + \", test: \"+str(o_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Printing individual AUCs from overall AUC\")\n",
    "\n",
    "true__ = {}\n",
    "true__['train'] = {}\n",
    "true__['test'] = {}\n",
    "pred__ = {}\n",
    "pred__['train'] = {}\n",
    "pred__['test'] = {}\n",
    "roc__ = {}\n",
    "roc__['train'] = {}\n",
    "roc__['test'] = {}\n",
    "vec1 = {}\n",
    "vec2 = {}\n",
    "vec3 = np.concatenate([incorrect_tid_vec,incorrect_tid_vec])\n",
    "for i in another_2:\n",
    "    true__['train'][i] = []\n",
    "    true__['test'][i] = []\n",
    "    pred__['test'][i] = []\n",
    "    pred__['train'][i] = []\n",
    "    vec1[i] = np.concatenate([task_ids_dict[i],incorrect_tid_vec])\n",
    "    vec2[i] = np.concatenate([incorrect_tid_vec,task_ids_dict[i]])\n",
    "for k in ['test','train']:\n",
    "    print(k)\n",
    "    for idx1,i in enumerate(true_all_tasks[k]['overall'][-1]): #per student\n",
    "        #detect the task ID from true_all_tasks\n",
    "        for idx,j in enumerate(i): #to individual interactions vector (all up to padding too!)\n",
    "            for l in another_2:\n",
    "                if(np.count_nonzero(j) != 0):\n",
    "                    if(np.argmax(j) == np.argmax(vec1[l])):#correct\n",
    "                        true__[k][l].append(1.0)\n",
    "                        pred__[k][l].append(predictions_all_tasks[k]['overall'][-1][idx1][idx][np.argmax(j)])\n",
    "                    elif(np.argmax(j) == np.argmax(vec2[l])):#incorrect\n",
    "                        true__[k][l].append(0.0)\n",
    "                        pred__[k][l].append(1.0 - predictions_all_tasks[k]['overall'][-1][idx1][idx][np.argmax(j)])\n",
    "                    \n",
    "    for l in another_2:\n",
    "        print(str(l) + \" -> auc: \" + str(roc_auc_score(true__[k][l],pred__[k][l])))\n",
    "        #print(np.c_[true__[k][l][:],pred__[k][l][:]])\n",
    "        roc__[k][l] = roc_curve(true__[k][l],pred__[k][l])\n",
    "        true__[k][l] = []            \n",
    "        pred__[k][l] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(14, 9), dpi= 200, facecolor='w', edgecolor='k')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Bayesian Knowledge Tracing (DKT combined, per-skill)')\n",
    "for k in ['train','test']:\n",
    "    for task_id in another_2:\n",
    "        plt.plot(roc__[k][task_id][0], roc__[k][task_id][1], label=str(task_id) + \" - \" + str(k))\n",
    "\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Calculating concatenated AUC\")\n",
    "for k in ['train','test']:\n",
    "    print(k)\n",
    "    sql = seqlen_all_tasks[k]['nl-M69Ez9k.parta'][0]\n",
    "    prd = predictions_all_tasks[k]['nl-M69Ez9k.parta'][0]\n",
    "    tre = true_all_tasks[k]['nl-M69Ez9k.parta'][0]\n",
    "    for i in another_2:\n",
    "        if(i != 'nl-M69Ez9k.parta'):\n",
    "            sql = np.concatenate([sql,seqlen_all_tasks[k][i][0]])\n",
    "            prd = np.concatenate([prd,predictions_all_tasks[k][i][0]])\n",
    "            tre = np.concatenate([tre,true_all_tasks[k][i][0]])\n",
    "    print(calculate_auc(tre,prd,sql))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(14, 9), dpi= 80, facecolor='w', edgecolor='k')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Bayesian Knowledge Tracing (combined model, test set)')\n",
    "\n",
    "for task_id in another_2:\n",
    "    roc = calculate_auc(true_all_tasks['test'][task_id][-1] , predictions_all_tasks['test'][task_id][-1] , seqlen_all_tasks['test'][task_id][-1],plot=True)\n",
    "    plt.plot(roc[1], roc[2], label=task_id)\n",
    "\n",
    "roc = calculate_auc(true_all_tasks['test']['overall'][-1],predictions_all_tasks['test']['overall'][-1],c_seqlen['test']['overall'][-1],plot=True)\n",
    "plt.plot(roc[1], roc[2], label='DKT (input combined)')\n",
    "\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(14, 9), dpi= 80, facecolor='w', edgecolor='k')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Bayesian Knowledge Tracing (combined model, Train set)')\n",
    "\n",
    "for task_id in another_2:\n",
    "    roc = calculate_auc(true_all_tasks['train'][task_id][-1],predictions_all_tasks['train'][task_id][-1], seqlen_all_tasks['train'][task_id][-1], plot=True)\n",
    "    plt.plot(roc[1], roc[2], label=task_id)\n",
    "\n",
    "roc = calculate_auc(true_all_tasks['train']['overall'][-1],predictions_all_tasks['train']['overall'][-1],c_seqlen['train']['overall'][-1],plot=True)\n",
    "plt.plot(roc[1], roc[2], label='overall-train')\n",
    "\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "print(\"test set roc plots\")\n",
    "fig=plt.figure(figsize=(14, 9), dpi= 200, facecolor='w', edgecolor='k')\n",
    "matplotlib.rcParams.update({'font.size': 15})\n",
    "#BKT (Separate, per skill)\n",
    "filepath = \"bkt_large_concat_roc.pickle\"\n",
    "roc_curves = pickle.load( open(filepath, \"rb\" ) )\n",
    "for task_id, roc in roc_curves.items():\n",
    "  plt.plot(roc[0], roc[1], label=\"BKT\")\n",
    "\n",
    "#DKT (Separate, per skill)\n",
    "roc = load_obj('dkt_sep_roc_overall')\n",
    "plt.plot(roc[1], roc[2], label='DKTSS-5')\n",
    "\n",
    "#DKT (Combined, per skill)\n",
    "# roc = calculate_auc(tre,prd,sql,plot=True)\n",
    "# plt.plot(roc[1], roc[2], label='DKT (combined, per skill)')\n",
    "\n",
    "#DKT (combined, combined)\n",
    "roc = calculate_auc(true_all_tasks['test']['overall'][-1],predictions_all_tasks['test']['overall'][-1],c_seqlen['test']['overall'][-1],plot=True)\n",
    "plt.plot(roc[1], roc[2], label='DKTCS')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--',label = \"Baseline\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "#plt.xlabel('False Positive Rate')\n",
    "#plt.ylabel('True Positive Rate')\n",
    "\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('final_roc_10x.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(6,2, figsize=(10, 20), facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = .5, wspace=0.1)\n",
    "\n",
    "axs = axs.ravel()\n",
    "\n",
    "for i,value in enumerate(another_2):\n",
    "    train_auc = seqlen_all_tasks['train'][value][:]\n",
    "    test_auc = seqlen_all_tasks['test'][value][:]\n",
    "    axs[i-1].plot(test_auc,label='test')\n",
    "    axs[i-1].plot(train_auc,label='train')\n",
    "    axs[i-1].set_ylim(0,1.1)\n",
    "    axs[i-1].set_xlim(0,12)\n",
    "    axs[i-1].set_xlabel(\"Epochs\")\n",
    "    axs[i-1].set_ylabel(\"AUC\")\n",
    "    axs[i-1].legend(loc=\"best\")\n",
    "    axs[i-1].set_title(\"Task ID = \"+str(value))\n",
    "    \n",
    "train_auc = seqlen_all_tasks['train']['overall'][:]\n",
    "test_auc = seqlen_all_tasks['test']['overall'][:]\n",
    "axs[i].plot(test_auc,label='test')\n",
    "axs[i].plot(train_auc,label='train')\n",
    "axs[i].set_ylim(0,1.1)\n",
    "axs[i].set_xlim(0,12)\n",
    "axs[i].set_xlabel(\"Epochs\")\n",
    "axs[i].set_ylabel(\"AUC\")\n",
    "axs[i].legend(loc=\"best\")\n",
    "axs[i].set_title(\"Overall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in another_2:\n",
    "    print(i + \" final train acc: \" + str(calculate_auc(true_all_tasks['train'][i][-1],predictions_all_tasks['train'][i][-1], seqlen_all_tasks['train'][i][-1])) + \"; final test acc: \"+str(calculate_auc(true_all_tasks['test'][i][-1] , predictions_all_tasks['test'][i][-1] , seqlen_all_tasks['test'][i][-1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**No longer maintained below this point.**<br>Training the model for hyperparameter (learning rate) tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot_lr = []\n",
    "# plot_valid_auc_taskid = []\n",
    "# plot_train_auc_taskid = []\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#     for l_r in learning_rate:\n",
    "#         plot_lr.append(l_r)    \n",
    "#         valid_taskid_list = []\n",
    "#         for k_fold in range(1,maximum_position+1):\n",
    "#             # Initialize the variables (i.e. assign their default value)\n",
    "#             tf.reset_default_graph()\n",
    "#             print(str(k_fold)+\"-fold cross-validation\")\n",
    "#             sess.run(tf.global_variables_initializer())\n",
    "#             sess.run(tf.local_variables_initializer())\n",
    "#             assign_op = learning_tf_rate.assign(l_r)\n",
    "#             sess.run(assign_op)\n",
    "#             print(\"Current Learning Rate: \"+str(learning_tf_rate.eval()))\n",
    "#             train_set_seqlen, valid_set_seqlen, valid_set_x, valid_set_y, valid_set_y_taskid, train_set_x, train_set_y, train_set_y_taskid = get_next_train_valid_set(k_fold-1)\n",
    "            \n",
    "#             for step in range(1, training_steps+1):\n",
    "#                 batch_x = train_set_x\n",
    "#                 batch_y = train_set_y\n",
    "#                 sess.run(optimizer, feed_dict={x: batch_x, y: batch_y, y_taskid: train_set_y_taskid, seqlen_tf: train_set_seqlen})\n",
    "\n",
    "#                 if step % display_step == 0 or step == 1:\n",
    "#                     loss,trainAUC,trainOPTS = sess.run([cost, auc, opts], feed_dict={x: batch_x, y: batch_y, y_taskid: train_set_y_taskid, seqlen_tf: train_set_seqlen})\n",
    "#                     #print status\n",
    "#                     print(\"Step \" + str(step) + \", Loss = \" + str(loss) + \", Learning Rate = \"+str(learning_tf_rate.eval()) + \", Train AUC:\" + str(trainOPTS))\n",
    "#             #calculate validation AUC\n",
    "#             valid_auc_taskid, valid_opts_taskid = sess.run([auc, opts], feed_dict={x: valid_set_x, y: valid_set_y, y_taskid: valid_set_y_taskid, seqlen_tf: valid_set_seqlen})\n",
    "#             print(\"Valid_auc_taskid: \" + str(valid_opts_taskid) + \" with k = \"+str(k_fold))\n",
    "#             valid_taskid_list.append(valid_opts_taskid)\n",
    "#             print(\"Optimization Finished!\")\n",
    "    \n",
    "#         #calculate training AUC (it should take both validation and training sets)\n",
    "#         train_auc_taskid, train_opts_taskid = sess.run([auc, opts], feed_dict={x: training_x, y: training_y, y_taskid: training_y_taskid, seqlen_tf: training_seqlen})\n",
    "\n",
    "#         print(\"Train_auc_taskid: \" + str(train_opts_taskid))\n",
    "#         plot_train_auc_taskid.append(train_opts_taskid)\n",
    "        \n",
    "#         #take average of validation AUCs\n",
    "#         valid_avg_taskid = np.mean(valid_taskid_list)\n",
    "        \n",
    "#         print(\"Average Valid_auc_taskid: \" + str(valid_avg_taskid))\n",
    "#         plot_valid_auc_taskid.append(valid_avg_taskid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting validation set ccssm auc across different learning rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.title(\"Training Set AUC\")\n",
    "# plt.xlabel(\"Learning Rate Index\")\n",
    "# plt.ylabel(\"AUC\")\n",
    "# plt.plot(plot_train_auc_taskid,'r--',label='train')\n",
    "# plt.plot(plot_valid_auc_taskid,label='valid')\n",
    "# plt.legend(loc='best', fancybox=True, framealpha=0.5)\n",
    "# plt.show()\n",
    "# print(learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#http://www.wildml.com/2016/08/rnns-in-tensorflow-a-practical-guide-and-undocumented-features/\n",
    "Suggestions for later:\n",
    "- https://www.tensorflow.org/versions/r1.5/api_docs/python/tf/contrib/learn/DynamicRnnEstimator#evaluate\n",
    "- we can also do dynamic partition of training and test set: http://ischlag.github.io/2016/06/19/tensorflow-input-pipeline-example/, but to compare with all the other models, I am fixing the test set.\n",
    "- try using shuffle_batch instead of tf.batch https://www.tensorflow.org/api_docs/python/tf/train/shuffle_batch \n",
    "- tried the suggestion, turns out one can't feed inconsistent dimensional tensors via feed_dict. And also, none of the functions (like - tf.train.batch etc. seem to be accepting the original variables). I need to try it on a small notebook first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
