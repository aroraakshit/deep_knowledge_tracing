{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pprint as pp\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code can work with either tf.VERSION = '1.4.1' (for MacOS High Sierra) or tf.VERSION = '0.12.1' (for RedHat based SuperComputer), functions may change for other versions. Also, this model does not have mini-batches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_split = 0.8\n",
    "validation_set_split = 0.1\n",
    "learning_rate = [0.001,0.01,0.1,1.0,1.5]\n",
    "num_units = 5 #number of units in RNN cell\n",
    "training_steps = 80 #number of epochs\n",
    "display_step = 40 #number of epochs after which to display progress\n",
    "optimize_using = \"adagrad\" #other option: \"momentum\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version being used: 1.4.1\n"
     ]
    }
   ],
   "source": [
    "print(\"Tensorflow version being used: \" + str(tf.VERSION))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading JSON file into dictionary called 'student_vectors'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"../data/student_vectors_n_task_10_n_limit_10000.json\"\n",
    "student_vectors = json.load(open(filepath))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecting unique CCSSM labels and Task IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique CCSSM Labels: 4\n",
      "Number of unique task IDs: 10\n",
      "Number of students: 1255\n"
     ]
    }
   ],
   "source": [
    "ccssm_labels = []\n",
    "task_ids = []\n",
    "for i in student_vectors:\n",
    "    for j in student_vectors[i]:\n",
    "        if j['ccssm'] not in ccssm_labels:\n",
    "            ccssm_labels.append(j['ccssm'])\n",
    "        if j['task_id'] not in task_ids:\n",
    "            task_ids.append(j['task_id'])\n",
    "print(\"Number of unique CCSSM Labels: \" + str(len(ccssm_labels)))\n",
    "print(\"Number of unique task IDs: \" + str(len(task_ids)))\n",
    "print(\"Number of students: \" + str(len(student_vectors)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating 1-hot encoding for Task IDs and CCSSM Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-hot encoding for CCSSM Labels:\n",
      "{'CCSS.Math.3.NF.A.1': array([1., 0., 0., 0.]),\n",
      " 'CCSS.Math.3.NF.A.3d': array([0., 1., 0., 0.]),\n",
      " 'CCSS.Math.4.NF.B.3a': array([0., 0., 1., 0.]),\n",
      " 'CCSS.Math.4.NF.B.3c': array([0., 0., 0., 1.])}\n",
      "\n",
      "1-hot encoding for task IDs:\n",
      "{'1zsCldT4p8.set1': array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
      " '1zsCldT4p8.set2': array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
      " '9wRCzK1G7F.partb': array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
      " 'DebcfZEEmI.proper_fractions': array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
      " 'Ok-iIHxjgx.parta': array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
      " 'Ok-iIHxjgx.partb': array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
      " 'hyei4uD81i.parta': array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]),\n",
      " 'kvig7fcCVc.partb': array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
      " 'nl-M69Ez9k.parta': array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]),\n",
      " 'p7cfRPp-kQ.partb': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])}\n"
     ]
    }
   ],
   "source": [
    "#pre-processing for using MultiLabelBinarizer\n",
    "temp_ids = []\n",
    "for i in task_ids:\n",
    "    temp_ids.append([i])\n",
    "temp_labels = []\n",
    "for i in ccssm_labels:\n",
    "    temp_labels.append([i])\n",
    "    \n",
    "#generating encodings\n",
    "enc = MultiLabelBinarizer()\n",
    "task_ids_1hot = (enc.fit_transform(temp_ids)).astype(float)\n",
    "task_ids_classes = enc.classes_\n",
    "task_ids_dict = dict(zip(task_ids, task_ids_1hot))\n",
    "labels_1hot = enc.fit_transform(temp_labels).astype(float)\n",
    "labels_classes = enc.classes_\n",
    "labels_dict = dict(zip(ccssm_labels,labels_1hot))\n",
    "print(\"1-hot encoding for CCSSM Labels:\")\n",
    "pp.pprint(labels_dict)\n",
    "print(\"\\n1-hot encoding for task IDs:\")\n",
    "pp.pprint(task_ids_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating input sequences of interactions to feed the network. Say we have 3 task IDs and 3 labels; here is an example of interaction vectors generated:\n",
    "1. User correctly solves task 2 of label 3: [010   000   001 000]\n",
    "2. User incorrectly solves task 1 of label 2: [000   100   000   010]\n",
    "\n",
    "1-hot representation of task IDs: \n",
    "task ID 1: 1,0,0 ; \n",
    "task ID 2: 0,1,0 ; \n",
    "task ID 3: 0,0,1 ; \n",
    "and similarly for labels!\n",
    "\n",
    "In the interaction vector, first 3 bits belong to taskID that user solved correctly; next 3 bits belong to taskID that user solved incorrectly; next 3 bits belong to label corresponding to task ID solved by user correctly and last 3 bits belong to label corresponding to the task ID solved by the user incorrectly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample interaction vector: \n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "sequences = []\n",
    "output_y_ccssm = []\n",
    "output_y_taskid = []\n",
    "output_y = []\n",
    "seqlen = []\n",
    "incorrect_tid_vec = np.zeros((len(task_ids)), dtype=np.float)\n",
    "incorrect_csm_vec = np.zeros((len(ccssm_labels)),dtype=np.float)\n",
    "for i in student_vectors:\n",
    "    temp_seq = []\n",
    "    for j in student_vectors[i]:\n",
    "        if(j['second_try'] == False): #ignoring second_try\n",
    "            if(j['correct'] == True):\n",
    "                vec = np.concatenate([task_ids_dict[j['task_id']],incorrect_tid_vec,labels_dict[j['ccssm']],incorrect_csm_vec])\n",
    "                temp_seq.append(vec)\n",
    "            else:\n",
    "                vec = np.concatenate([incorrect_tid_vec,task_ids_dict[j['task_id']],incorrect_csm_vec,labels_dict[j['ccssm']]])\n",
    "                temp_seq.append(vec)\n",
    "    seqlen.append(len(temp_seq))\n",
    "    last_one = temp_seq.pop()\n",
    "    output_y.append(last_one)\n",
    "    output_y_ccssm.append(last_one[2*len(task_ids):])\n",
    "    output_y_taskid.append(last_one[:2*len(task_ids)])\n",
    "    sequences.append(temp_seq)\n",
    "print(\"Sample interaction vector: \")\n",
    "pp.pprint(sequences[0][0])\n",
    "length_interaction_vector = 2*(len(task_ids)+len(ccssm_labels)) #length of interaction vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding maximum sequence length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sequence length: 186\n"
     ]
    }
   ],
   "source": [
    "max_seqlen = max(seqlen)\n",
    "print(\"Maximum sequence length: \"+str(max_seqlen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Padding the sequences according to maximum sequence length. Making padded sequences of shape: number of students, maximum sequence length, length of interaction vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequences have been padded according to the maximum sequence length. Final shape: (1255, 186, 28)\n"
     ]
    }
   ],
   "source": [
    "padded_sequences = np.zeros(shape=(len(student_vectors),max_seqlen,length_interaction_vector),dtype=float)\n",
    "for i in range(len(sequences)):\n",
    "    for j in range(len(sequences[i])):\n",
    "        padded_sequences[i][j] = sequences[i][j]\n",
    "print(\"Sequences have been padded according to the maximum sequence length. Final shape: \" + str(padded_sequences.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into training and testing sets. Will take random validation sets at the time of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting 1255 rows into 1005 for training, 125 for validation and 125 for testing.\n",
      "Implemented 9-fold cross validation.\n"
     ]
    }
   ],
   "source": [
    "split = round((training_set_split+validation_set_split)*len(student_vectors))\n",
    "\n",
    "#separating training & validation set\n",
    "training_x = padded_sequences[:split]\n",
    "training_y = np.asarray(output_y)[:split]\n",
    "training_y_ccssm = np.asarray(output_y_ccssm)[:split]\n",
    "training_y_taskid = np.asarray(output_y_taskid)[:split]\n",
    "training_seqlen = seqlen[:split]\n",
    "\n",
    "#generating validation and training sets by implementing k-fold cross validation (k = maximum_position)\n",
    "validation_set_size = math.floor(validation_set_split * len(student_vectors))\n",
    "training_set_size = len(training_x) - validation_set_size\n",
    "maximum_position = math.floor(len(training_x) / validation_set_size)\n",
    "def get_next_train_valid_set(position):\n",
    "    if(position>=maximum_position):\n",
    "        position = position % maximum_position\n",
    "    print(\"Picking validation set from position: \"+str(position))\n",
    "    valid_start = position*validation_set_size\n",
    "    valid_end = valid_start + validation_set_size\n",
    "    \n",
    "    valid_set_x = training_x[valid_start : valid_end]\n",
    "    valid_set_y = training_y[valid_start : valid_end]\n",
    "    valid_set_y_ccssm = np.asarray(training_y_ccssm)[valid_start : valid_end]\n",
    "    valid_set_y_taskid = np.asarray(training_y_taskid)[valid_start : valid_end]\n",
    "    valid_set_seqlen = np.asarray(training_seqlen[valid_start:valid_end])\n",
    "    \n",
    "    train_set_x = np.concatenate((training_x[:valid_start], training_x[valid_end:]))\n",
    "    train_set_y = np.concatenate((training_y[:valid_start], training_y[valid_end:]))\n",
    "    train_set_y_ccssm = np.concatenate((np.asarray(training_y_ccssm)[:valid_start], np.asarray(training_y_ccssm)[valid_end:]))\n",
    "    train_set_y_taskid = np.concatenate((np.asarray(training_y_taskid)[:valid_start], np.asarray(training_y_taskid)[valid_end:]))\n",
    "    train_set_seqlen = np.concatenate((np.asarray(training_seqlen)[:valid_start],np.asarray(training_seqlen)[valid_end:]))\n",
    "    \n",
    "    if(len(train_set_x) != training_set_size): #just as a test\n",
    "        print(\"that's not good it is:\")\n",
    "        print(train_set_x.shape)\n",
    "    \n",
    "    return (train_set_seqlen,valid_set_seqlen,valid_set_x,valid_set_y,valid_set_y_ccssm,valid_set_y_taskid,train_set_x,train_set_y,train_set_y_ccssm,train_set_y_taskid)\n",
    "\n",
    "#separating test set\n",
    "test_x = padded_sequences[split:]\n",
    "test_y = np.asarray(output_y)[split:]\n",
    "test_y_ccssm = np.asarray(output_y_ccssm)[split:]\n",
    "test_y_taskid = np.asarray(output_y_taskid)[split:]\n",
    "test_seqlen = seqlen[split:]\n",
    "\n",
    "print(\"Splitting \"+str(len(student_vectors))+\" rows into \"+str(training_set_size)+ \" for training, \"+str(validation_set_size)+\" for validation and \"+str(len(test_x)) + \" for testing.\")\n",
    "print(\"Implemented \"+str(maximum_position)+\"-fold cross validation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:96: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "#defining placeholders\n",
    "x = tf.placeholder(tf.float32, [None, max_seqlen, length_interaction_vector]) #(<batch_size>, <max_time>, <num_features>)\n",
    "y = tf.placeholder(tf.float32, [None, length_interaction_vector]) #(<batch_size>, <num_features>)\n",
    "y_taskid = tf.placeholder(tf.float32, [None, 2*len(task_ids)])\n",
    "y_ccssm = tf.placeholder(tf.float32, [None, 2*len(ccssm_labels)])\n",
    "seqlen_tf = tf.placeholder(tf.float32,[None])\n",
    "\n",
    "#defining tensorflow variables\n",
    "learning_tf_rate = tf.Variable(0.0, name=\"learning_tf_rate\",dtype=tf.float32)\n",
    "\n",
    "#dynamic RNN definition\n",
    "def dynamicRNN(x):\n",
    "    rnn_cell = tf.nn.rnn_cell.BasicRNNCell(num_units)\n",
    "    outputs, states = tf.nn.dynamic_rnn(rnn_cell, x, dtype=tf.float32,sequence_length=seqlen_tf)\n",
    "    \n",
    "    #transformation on outputs needed, otherwise auc=0\n",
    "    outputs = tf.transpose(outputs, [1, 0, 2])\n",
    "    outputs = tf.gather(outputs, int(outputs.get_shape()[0]) - 1)\n",
    "    out_size = length_interaction_vector\n",
    "    logit = tf.contrib.layers.fully_connected(outputs, out_size, activation_fn=None)\n",
    "    if tf.VERSION == '0.12.1': #summit's tensorflow version API doc: https://www.tensorflow.org/versions/r0.12/api_docs/\n",
    "        outputs = tf.sigmoid(logit)\n",
    "    else:\n",
    "        outputs = tf.nn.sigmoid(logit)\n",
    "    return outputs\n",
    "\n",
    "#making predictions\n",
    "pred = dynamicRNN(x)\n",
    "if tf.VERSION == '0.12.1': #summit's tensorflow version API doc: https://www.tensorflow.org/versions/r0.12/api_docs/\n",
    "    pred_task,pred_ccssm = tf.split_v(value=pred,size_splits=[2*len(task_ids),2*len(ccssm_labels)],split_dim=1)\n",
    "else:\n",
    "    pred_task,pred_ccssm = tf.split(value=pred,num_or_size_splits=[2*len(task_ids),2*len(ccssm_labels)],axis=1)\n",
    "    \n",
    "# Define loss and optimizer\n",
    "if tf.VERSION == '0.12.1': #summit's tensorflow version API doc: https://www.tensorflow.org/versions/r0.12/api_docs/\n",
    "    cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=pred, targets=y))\n",
    "else:\n",
    "    cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "if(optimize_using == \"momentum\"):\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate=learning_tf_rate,momentum=0.9).minimize(cost)\n",
    "elif (optimize_using == \"adagrad\"):\n",
    "    optimizer = tf.train.AdagradOptimizer(learning_rate=learning_tf_rate).minimize(cost)\n",
    "\n",
    "# Evaluate model - use AUC to evaluate model\n",
    "if tf.VERSION == '0.12.1': #summit's tensorflow version API doc: https://www.tensorflow.org/versions/r0.12/api_docs/\n",
    "    auc,  opts = tf.contrib.metrics.streaming_auc(labels = test_y_taskid, predictions = pred_task, curve='ROC')\n",
    "    auc_ccssm,  opts_ccssm = tf.contrib.metrics.streaming_auc(labels = test_y_ccssm, predictions = pred_ccssm, curve='ROC')\n",
    "else:\n",
    "    auc,  opts = tf.metrics.auc(labels = y_taskid, predictions = pred_task, curve='ROC')\n",
    "    auc_ccssm,  opts_ccssm = tf.metrics.auc(labels = y_ccssm, predictions = pred_ccssm, curve='ROC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model for hyperparameter (learning rate) tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-fold cross-validation\n",
      "Current Learning Rate: 0.001\n",
      "Picking validation set from position: 0\n",
      "Step 1, Loss = [0.9383799], Learning Rate = 0.001\n",
      "Step 40, Loss = [0.9382248], Learning Rate = 0.001\n",
      "Step 80, Loss = [0.9381633], Learning Rate = 0.001\n",
      "Valid_auc_taskid: 0.5 Valid_auc_ccssm: 0.5 with k = 1\n",
      "Optimization Finished!\n",
      "2-fold cross-validation\n",
      "Current Learning Rate: 0.001\n",
      "Picking validation set from position: 1\n",
      "Step 1, Loss = [0.93838996], Learning Rate = 0.001\n",
      "Step 40, Loss = [0.93823534], Learning Rate = 0.001\n",
      "Step 80, Loss = [0.93817365], Learning Rate = 0.001\n",
      "Valid_auc_taskid: 0.5 Valid_auc_ccssm: 0.5 with k = 2\n",
      "Optimization Finished!\n",
      "3-fold cross-validation\n",
      "Current Learning Rate: 0.001\n",
      "Picking validation set from position: 2\n",
      "Step 1, Loss = [0.9383853], Learning Rate = 0.001\n",
      "Step 40, Loss = [0.9382307], Learning Rate = 0.001\n",
      "Step 80, Loss = [0.93816894], Learning Rate = 0.001\n",
      "Valid_auc_taskid: 0.5 Valid_auc_ccssm: 0.5 with k = 3\n",
      "Optimization Finished!\n",
      "4-fold cross-validation\n",
      "Current Learning Rate: 0.001\n",
      "Picking validation set from position: 3\n",
      "Step 1, Loss = [0.93839425], Learning Rate = 0.001\n",
      "Step 40, Loss = [0.9382395], Learning Rate = 0.001\n",
      "Step 80, Loss = [0.93817776], Learning Rate = 0.001\n",
      "Valid_auc_taskid: 0.5 Valid_auc_ccssm: 0.5 with k = 4\n",
      "Optimization Finished!\n",
      "5-fold cross-validation\n",
      "Current Learning Rate: 0.001\n",
      "Picking validation set from position: 4\n",
      "Step 1, Loss = [0.93839204], Learning Rate = 0.001\n",
      "Step 40, Loss = [0.9382374], Learning Rate = 0.001\n",
      "Step 80, Loss = [0.93817556], Learning Rate = 0.001\n",
      "Valid_auc_taskid: 0.5 Valid_auc_ccssm: 0.5 with k = 5\n",
      "Optimization Finished!\n",
      "6-fold cross-validation\n",
      "Current Learning Rate: 0.001\n",
      "Picking validation set from position: 5\n",
      "Step 1, Loss = [0.93839043], Learning Rate = 0.001\n",
      "Step 40, Loss = [0.93823564], Learning Rate = 0.001\n",
      "Step 80, Loss = [0.93817383], Learning Rate = 0.001\n",
      "Valid_auc_taskid: 0.5 Valid_auc_ccssm: 0.5 with k = 6\n",
      "Optimization Finished!\n",
      "7-fold cross-validation\n",
      "Current Learning Rate: 0.001\n",
      "Picking validation set from position: 6\n",
      "Step 1, Loss = [0.93839055], Learning Rate = 0.001\n",
      "Step 40, Loss = [0.93823576], Learning Rate = 0.001\n",
      "Step 80, Loss = [0.93817395], Learning Rate = 0.001\n",
      "Valid_auc_taskid: 0.5 Valid_auc_ccssm: 0.5 with k = 7\n",
      "Optimization Finished!\n",
      "8-fold cross-validation\n",
      "Current Learning Rate: 0.001\n",
      "Picking validation set from position: 7\n",
      "Step 1, Loss = [0.9383892], Learning Rate = 0.001\n",
      "Step 40, Loss = [0.93823445], Learning Rate = 0.001\n",
      "Step 80, Loss = [0.9381726], Learning Rate = 0.001\n",
      "Valid_auc_taskid: 0.49728337 Valid_auc_ccssm: 0.5005714 with k = 8\n",
      "Optimization Finished!\n",
      "9-fold cross-validation\n",
      "Current Learning Rate: 0.001\n",
      "Picking validation set from position: 8\n",
      "Step 1, Loss = [0.9383925], Learning Rate = 0.001\n",
      "Step 40, Loss = [0.93823785], Learning Rate = 0.001\n",
      "Step 80, Loss = [0.93817604], Learning Rate = 0.001\n",
      "Valid_auc_taskid: 0.5 Valid_auc_ccssm: 0.5 with k = 9\n",
      "Optimization Finished!\n",
      "Train_auc_taskid: 0.49947605\n",
      "Train_auc_ccssm: 0.49948797\n",
      "Average Valid_auc_taskid: 0.49969816\n",
      "Average Valid_auc_ccssm: 0.5000635\n",
      "1-fold cross-validation\n",
      "Current Learning Rate: 0.01\n",
      "Picking validation set from position: 0\n",
      "Step 1, Loss = [0.93835795], Learning Rate = 0.01\n",
      "Step 40, Loss = [0.9373206], Learning Rate = 0.01\n",
      "Step 80, Loss = [0.93633497], Learning Rate = 0.01\n",
      "Valid_auc_taskid: 0.9578948 Valid_auc_ccssm: 0.98628575 with k = 1\n",
      "Optimization Finished!\n",
      "2-fold cross-validation\n",
      "Current Learning Rate: 0.01\n",
      "Picking validation set from position: 1\n",
      "Step 1, Loss = [0.938346], Learning Rate = 0.01\n",
      "Step 40, Loss = [0.93731034], Learning Rate = 0.01\n",
      "Step 80, Loss = [0.93632585], Learning Rate = 0.01\n",
      "Valid_auc_taskid: 0.99578947 Valid_auc_ccssm: 0.99542856 with k = 2\n",
      "Optimization Finished!\n",
      "3-fold cross-validation\n",
      "Current Learning Rate: 0.01\n",
      "Picking validation set from position: 2\n",
      "Step 1, Loss = [0.93836075], Learning Rate = 0.01\n",
      "Step 40, Loss = [0.93732405], Learning Rate = 0.01\n",
      "Step 80, Loss = [0.93633914], Learning Rate = 0.01\n",
      "Valid_auc_taskid: 0.9831579 Valid_auc_ccssm: 0.98171425 with k = 3\n",
      "Optimization Finished!\n",
      "4-fold cross-validation\n",
      "Current Learning Rate: 0.01\n",
      "Picking validation set from position: 3\n",
      "Step 1, Loss = [0.9383496], Learning Rate = 0.01\n",
      "Step 40, Loss = [0.9373129], Learning Rate = 0.01\n",
      "Step 80, Loss = [0.93632764], Learning Rate = 0.01\n",
      "Valid_auc_taskid: 0.9789474 Valid_auc_ccssm: 0.9771429 with k = 4\n",
      "Optimization Finished!\n",
      "5-fold cross-validation\n",
      "Current Learning Rate: 0.01\n",
      "Picking validation set from position: 4\n",
      "Step 1, Loss = [0.9383477], Learning Rate = 0.01\n",
      "Step 40, Loss = [0.93731076], Learning Rate = 0.01\n",
      "Step 80, Loss = [0.93632543], Learning Rate = 0.01\n",
      "Valid_auc_taskid: 0.9747368 Valid_auc_ccssm: 0.97257143 with k = 5\n",
      "Optimization Finished!\n",
      "6-fold cross-validation\n",
      "Current Learning Rate: 0.01\n",
      "Picking validation set from position: 5\n",
      "Step 1, Loss = [0.9383528], Learning Rate = 0.01\n",
      "Step 40, Loss = [0.9373156], Learning Rate = 0.01\n",
      "Step 80, Loss = [0.93632984], Learning Rate = 0.01\n",
      "Valid_auc_taskid: 0.97052634 Valid_auc_ccssm: 0.968 with k = 6\n",
      "Optimization Finished!\n",
      "7-fold cross-validation\n",
      "Current Learning Rate: 0.01\n",
      "Picking validation set from position: 6\n",
      "Step 1, Loss = [0.9383512], Learning Rate = 0.01\n",
      "Step 40, Loss = [0.9373144], Learning Rate = 0.01\n",
      "Step 80, Loss = [0.9363293], Learning Rate = 0.01\n",
      "Valid_auc_taskid: 0.9789474 Valid_auc_ccssm: 0.9771429 with k = 7\n",
      "Optimization Finished!\n",
      "8-fold cross-validation\n",
      "Current Learning Rate: 0.01\n",
      "Picking validation set from position: 7\n",
      "Step 1, Loss = [0.9383521], Learning Rate = 0.01\n",
      "Step 40, Loss = [0.9373155], Learning Rate = 0.01\n",
      "Step 80, Loss = [0.9363311], Learning Rate = 0.01\n",
      "Valid_auc_taskid: 0.98069215 Valid_auc_ccssm: 0.9800365 with k = 8\n",
      "Optimization Finished!\n",
      "9-fold cross-validation\n",
      "Current Learning Rate: 0.01\n",
      "Picking validation set from position: 8\n",
      "Step 1, Loss = [0.93834585], Learning Rate = 0.01\n",
      "Step 40, Loss = [0.9373091], Learning Rate = 0.01\n",
      "Step 80, Loss = [0.936324], Learning Rate = 0.01\n",
      "Valid_auc_taskid: 0.9789474 Valid_auc_ccssm: 0.9771429 with k = 9\n",
      "Optimization Finished!\n",
      "Train_auc_taskid: 0.9772639\n",
      "Train_auc_ccssm: 0.97929525\n",
      "Average Valid_auc_taskid: 0.9777377\n",
      "Average Valid_auc_ccssm: 0.9794961\n",
      "1-fold cross-validation\n",
      "Current Learning Rate: 0.1\n",
      "Picking validation set from position: 0\n",
      "Step 1, Loss = [0.9381191], Learning Rate = 0.1\n",
      "Step 40, Loss = [0.9281306], Learning Rate = 0.1\n",
      "Step 80, Loss = [0.9181846], Learning Rate = 0.1\n",
      "Valid_auc_taskid: 0.96378946 Valid_auc_ccssm: 0.9965714 with k = 1\n",
      "Optimization Finished!\n",
      "2-fold cross-validation\n",
      "Current Learning Rate: 0.1\n",
      "Picking validation set from position: 1\n",
      "Step 1, Loss = [0.9381155], Learning Rate = 0.1\n",
      "Step 40, Loss = [0.9281498], Learning Rate = 0.1\n",
      "Step 80, Loss = [0.9182232], Learning Rate = 0.1\n",
      "Valid_auc_taskid: 0.99957895 Valid_auc_ccssm: 0.99885714 with k = 2\n",
      "Optimization Finished!\n",
      "3-fold cross-validation\n",
      "Current Learning Rate: 0.1\n",
      "Picking validation set from position: 2\n",
      "Step 1, Loss = [0.93812203], Learning Rate = 0.1\n",
      "Step 40, Loss = [0.9281488], Learning Rate = 0.1\n",
      "Step 80, Loss = [0.91820514], Learning Rate = 0.1\n",
      "Valid_auc_taskid: 0.9831579 Valid_auc_ccssm: 0.99542856 with k = 3\n",
      "Optimization Finished!\n",
      "4-fold cross-validation\n",
      "Current Learning Rate: 0.1\n",
      "Picking validation set from position: 3\n",
      "Step 1, Loss = [0.938117], Learning Rate = 0.1\n",
      "Step 40, Loss = [0.9281415], Learning Rate = 0.1\n",
      "Step 80, Loss = [0.9181957], Learning Rate = 0.1\n",
      "Valid_auc_taskid: 0.9789474 Valid_auc_ccssm: 0.9771429 with k = 4\n",
      "Optimization Finished!\n",
      "5-fold cross-validation\n",
      "Current Learning Rate: 0.1\n",
      "Picking validation set from position: 4\n",
      "Step 1, Loss = [0.93811965], Learning Rate = 0.1\n",
      "Step 40, Loss = [0.9281404], Learning Rate = 0.1\n",
      "Step 80, Loss = [0.91819197], Learning Rate = 0.1\n",
      "Valid_auc_taskid: 0.9747368 Valid_auc_ccssm: 0.97257143 with k = 5\n",
      "Optimization Finished!\n",
      "6-fold cross-validation\n",
      "Current Learning Rate: 0.1\n",
      "Picking validation set from position: 5\n",
      "Step 1, Loss = [0.9381184], Learning Rate = 0.1\n",
      "Step 40, Loss = [0.928136], Learning Rate = 0.1\n",
      "Step 80, Loss = [0.9181838], Learning Rate = 0.1\n",
      "Valid_auc_taskid: 0.97052634 Valid_auc_ccssm: 0.968 with k = 6\n",
      "Optimization Finished!\n",
      "7-fold cross-validation\n",
      "Current Learning Rate: 0.1\n",
      "Picking validation set from position: 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, Loss = [0.9381178], Learning Rate = 0.1\n",
      "Step 40, Loss = [0.9281423], Learning Rate = 0.1\n",
      "Step 80, Loss = [0.9181964], Learning Rate = 0.1\n",
      "Valid_auc_taskid: 0.9789474 Valid_auc_ccssm: 0.9771429 with k = 7\n",
      "Optimization Finished!\n",
      "8-fold cross-validation\n",
      "Current Learning Rate: 0.1\n",
      "Picking validation set from position: 7\n",
      "Step 1, Loss = [0.93811893], Learning Rate = 0.1\n",
      "Step 40, Loss = [0.9281477], Learning Rate = 0.1\n",
      "Step 80, Loss = [0.91821086], Learning Rate = 0.1\n",
      "Valid_auc_taskid: 0.9982535 Valid_auc_ccssm: 0.9863223 with k = 8\n",
      "Optimization Finished!\n",
      "9-fold cross-validation\n",
      "Current Learning Rate: 0.1\n",
      "Picking validation set from position: 8\n",
      "Step 1, Loss = [0.9381254], Learning Rate = 0.1\n",
      "Step 40, Loss = [0.92814976], Learning Rate = 0.1\n",
      "Step 80, Loss = [0.91820407], Learning Rate = 0.1\n",
      "Valid_auc_taskid: 0.9789474 Valid_auc_ccssm: 0.9771429 with k = 9\n",
      "Optimization Finished!\n",
      "Train_auc_taskid: 0.9781258\n",
      "Train_auc_ccssm: 0.9795083\n",
      "Average Valid_auc_taskid: 0.98076504\n",
      "Average Valid_auc_ccssm: 0.98324215\n",
      "1-fold cross-validation\n",
      "Current Learning Rate: 1.0\n",
      "Picking validation set from position: 0\n",
      "Step 1, Loss = [0.93581206], Learning Rate = 1.0\n",
      "Step 40, Loss = [0.84815073], Learning Rate = 1.0\n",
      "Step 80, Loss = [0.79058504], Learning Rate = 1.0\n",
      "Valid_auc_taskid: 0.96378946 Valid_auc_ccssm: 0.9965714 with k = 1\n",
      "Optimization Finished!\n",
      "2-fold cross-validation\n",
      "Current Learning Rate: 1.0\n",
      "Picking validation set from position: 1\n",
      "Step 1, Loss = [0.93581444], Learning Rate = 1.0\n",
      "Step 40, Loss = [0.8483257], Learning Rate = 1.0\n",
      "Step 80, Loss = [0.79086417], Learning Rate = 1.0\n",
      "Valid_auc_taskid: 0.99957895 Valid_auc_ccssm: 0.99885714 with k = 2\n",
      "Optimization Finished!\n",
      "3-fold cross-validation\n",
      "Current Learning Rate: 1.0\n",
      "Picking validation set from position: 2\n",
      "Step 1, Loss = [0.93581563], Learning Rate = 1.0\n",
      "Step 40, Loss = [0.8482347], Learning Rate = 1.0\n",
      "Step 80, Loss = [0.7907154], Learning Rate = 1.0\n",
      "Valid_auc_taskid: 0.99831575 Valid_auc_ccssm: 0.99542856 with k = 3\n",
      "Optimization Finished!\n",
      "4-fold cross-validation\n",
      "Current Learning Rate: 1.0\n",
      "Picking validation set from position: 3\n",
      "Step 1, Loss = [0.93581617], Learning Rate = 1.0\n",
      "Step 40, Loss = [0.8482048], Learning Rate = 1.0\n",
      "Step 80, Loss = [0.79066676], Learning Rate = 1.0\n",
      "Valid_auc_taskid: 0.9978947 Valid_auc_ccssm: 0.9942857 with k = 4\n",
      "Optimization Finished!\n",
      "5-fold cross-validation\n",
      "Current Learning Rate: 1.0\n",
      "Picking validation set from position: 4\n",
      "Step 1, Loss = [0.9358122], Learning Rate = 1.0\n",
      "Step 40, Loss = [0.84817153], Learning Rate = 1.0\n",
      "Step 80, Loss = [0.79061496], Learning Rate = 1.0\n",
      "Valid_auc_taskid: 0.99747366 Valid_auc_ccssm: 0.99314284 with k = 5\n",
      "Optimization Finished!\n",
      "6-fold cross-validation\n",
      "Current Learning Rate: 1.0\n",
      "Picking validation set from position: 5\n",
      "Step 1, Loss = [0.93581146], Learning Rate = 1.0\n",
      "Step 40, Loss = [0.84813744], Learning Rate = 1.0\n",
      "Step 80, Loss = [0.7905677], Learning Rate = 1.0\n",
      "Valid_auc_taskid: 0.9970526 Valid_auc_ccssm: 0.99200004 with k = 6\n",
      "Optimization Finished!\n",
      "7-fold cross-validation\n",
      "Current Learning Rate: 1.0\n",
      "Picking validation set from position: 6\n",
      "Step 1, Loss = [0.93581575], Learning Rate = 1.0\n",
      "Step 40, Loss = [0.8482044], Learning Rate = 1.0\n",
      "Step 80, Loss = [0.7906666], Learning Rate = 1.0\n",
      "Valid_auc_taskid: 0.9978947 Valid_auc_ccssm: 0.9942857 with k = 7\n",
      "Optimization Finished!\n",
      "8-fold cross-validation\n",
      "Current Learning Rate: 1.0\n",
      "Picking validation set from position: 7\n",
      "Step 1, Loss = [0.9358157], Learning Rate = 1.0\n",
      "Step 40, Loss = [0.8482666], Learning Rate = 1.0\n",
      "Step 80, Loss = [0.790767], Learning Rate = 1.0\n",
      "Valid_auc_taskid: 0.9986055 Valid_auc_ccssm: 0.99648917 with k = 8\n",
      "Optimization Finished!\n",
      "9-fold cross-validation\n",
      "Current Learning Rate: 1.0\n",
      "Picking validation set from position: 8\n",
      "Step 1, Loss = [0.9358129], Learning Rate = 1.0\n",
      "Step 40, Loss = [0.84820193], Learning Rate = 1.0\n",
      "Step 80, Loss = [0.7906655], Learning Rate = 1.0\n",
      "Valid_auc_taskid: 0.9978947 Valid_auc_ccssm: 0.9942857 with k = 9\n",
      "Optimization Finished!\n",
      "Train_auc_taskid: 0.9971056\n",
      "Train_auc_ccssm: 0.9948736\n",
      "Average Valid_auc_taskid: 0.9942777\n",
      "Average Valid_auc_ccssm: 0.99503845\n",
      "1-fold cross-validation\n",
      "Current Learning Rate: 1.5\n",
      "Picking validation set from position: 0\n",
      "Step 1, Loss = [0.9344959], Learning Rate = 1.5\n",
      "Step 40, Loss = [0.8153955], Learning Rate = 1.5\n",
      "Step 80, Loss = [0.75657654], Learning Rate = 1.5\n",
      "Valid_auc_taskid: 0.96378946 Valid_auc_ccssm: 0.9965714 with k = 1\n",
      "Optimization Finished!\n",
      "2-fold cross-validation\n",
      "Current Learning Rate: 1.5\n",
      "Picking validation set from position: 1\n",
      "Step 1, Loss = [0.93449557], Learning Rate = 1.5\n",
      "Step 40, Loss = [0.8156233], Learning Rate = 1.5\n",
      "Step 80, Loss = [0.7568989], Learning Rate = 1.5\n",
      "Valid_auc_taskid: 0.99957895 Valid_auc_ccssm: 0.99885714 with k = 2\n",
      "Optimization Finished!\n",
      "3-fold cross-validation\n",
      "Current Learning Rate: 1.5\n",
      "Picking validation set from position: 2\n",
      "Step 1, Loss = [0.9344991], Learning Rate = 1.5\n",
      "Step 40, Loss = [0.8155009], Learning Rate = 1.5\n",
      "Step 80, Loss = [0.7567257], Learning Rate = 1.5\n",
      "Valid_auc_taskid: 0.9983158 Valid_auc_ccssm: 0.99542856 with k = 3\n",
      "Optimization Finished!\n",
      "4-fold cross-validation\n",
      "Current Learning Rate: 1.5\n",
      "Picking validation set from position: 3\n",
      "Step 1, Loss = [0.9344973], Learning Rate = 1.5\n",
      "Step 40, Loss = [0.8154573], Learning Rate = 1.5\n",
      "Step 80, Loss = [0.7566657], Learning Rate = 1.5\n",
      "Valid_auc_taskid: 0.99789476 Valid_auc_ccssm: 0.99428576 with k = 4\n",
      "Optimization Finished!\n",
      "5-fold cross-validation\n",
      "Current Learning Rate: 1.5\n",
      "Picking validation set from position: 4\n",
      "Step 1, Loss = [0.93449676], Learning Rate = 1.5\n",
      "Step 40, Loss = [0.81541437], Learning Rate = 1.5\n",
      "Step 80, Loss = [0.75660807], Learning Rate = 1.5\n",
      "Valid_auc_taskid: 0.9974737 Valid_auc_ccssm: 0.9931429 with k = 5\n",
      "Optimization Finished!\n",
      "6-fold cross-validation\n",
      "Current Learning Rate: 1.5\n",
      "Picking validation set from position: 5\n",
      "Step 1, Loss = [0.9344968], Learning Rate = 1.5\n",
      "Step 40, Loss = [0.8153728], Learning Rate = 1.5\n",
      "Step 80, Loss = [0.75654817], Learning Rate = 1.5\n",
      "Valid_auc_taskid: 0.99705267 Valid_auc_ccssm: 0.99200004 with k = 6\n",
      "Optimization Finished!\n",
      "7-fold cross-validation\n",
      "Current Learning Rate: 1.5\n",
      "Picking validation set from position: 6\n",
      "Step 1, Loss = [0.93449736], Learning Rate = 1.5\n",
      "Step 40, Loss = [0.8154578], Learning Rate = 1.5\n",
      "Step 80, Loss = [0.7566657], Learning Rate = 1.5\n",
      "Valid_auc_taskid: 0.99789476 Valid_auc_ccssm: 0.99428576 with k = 7\n",
      "Optimization Finished!\n",
      "8-fold cross-validation\n",
      "Current Learning Rate: 1.5\n",
      "Picking validation set from position: 7\n",
      "Step 1, Loss = [0.9344985], Learning Rate = 1.5\n",
      "Step 40, Loss = [0.81554234], Learning Rate = 1.5\n",
      "Step 80, Loss = [0.756784], Learning Rate = 1.5\n",
      "Valid_auc_taskid: 0.9987065 Valid_auc_ccssm: 0.9965303 with k = 8\n",
      "Optimization Finished!\n",
      "9-fold cross-validation\n",
      "Current Learning Rate: 1.5\n",
      "Picking validation set from position: 8\n",
      "Step 1, Loss = [0.93449724], Learning Rate = 1.5\n",
      "Step 40, Loss = [0.8154578], Learning Rate = 1.5\n",
      "Step 80, Loss = [0.7566656], Learning Rate = 1.5\n",
      "Valid_auc_taskid: 0.99789476 Valid_auc_ccssm: 0.99428576 with k = 9\n",
      "Optimization Finished!\n",
      "Train_auc_taskid: 0.9946274\n",
      "Train_auc_ccssm: 0.99487156\n",
      "Average Valid_auc_taskid: 0.994289\n",
      "Average Valid_auc_ccssm: 0.9950431\n"
     ]
    }
   ],
   "source": [
    "plot_lr = []\n",
    "plot_valid_auc_taskid = []\n",
    "plot_valid_auc_ccssm = []\n",
    "plot_train_auc_ccssm = []\n",
    "plot_train_auc_taskid = []\n",
    "with tf.Session() as sess:\n",
    "    for l_r in learning_rate:\n",
    "        plot_lr.append(l_r)    \n",
    "        valid_taskid_list = []\n",
    "        valid_ccssm_list = []\n",
    "        for k_fold in range(1,maximum_position+1):\n",
    "            # Initialize the variables (i.e. assign their default value)\n",
    "            print(str(k_fold)+\"-fold cross-validation\")\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            sess.run(tf.local_variables_initializer())\n",
    "            assign_op = learning_tf_rate.assign(l_r)\n",
    "            sess.run(assign_op)\n",
    "            print(\"Current Learning Rate: \"+str(learning_tf_rate.eval()))\n",
    "            train_set_seqlen,valid_set_seqlen,valid_set_x,valid_set_y,valid_set_y_ccssm,valid_set_y_taskid,train_set_x,train_set_y,train_set_y_ccssm,train_set_y_taskid = get_next_train_valid_set(k_fold-1)\n",
    "            for step in range(1, training_steps+1):\n",
    "                batch_x = train_set_x\n",
    "                batch_y = train_set_y\n",
    "                sess.run(optimizer, feed_dict={x: batch_x, y: batch_y, y_taskid: train_set_y_taskid, y_ccssm: train_set_y_ccssm, seqlen_tf: train_set_seqlen})\n",
    "\n",
    "                if step % display_step == 0 or step == 1:\n",
    "                    loss= sess.run([cost], feed_dict={x: batch_x, y: batch_y, y_taskid: train_set_y_taskid, y_ccssm: train_set_y_ccssm, seqlen_tf: train_set_seqlen})\n",
    "                    #print status\n",
    "                    print(\"Step \" + str(step) + \", Loss = \" + str(loss) + \", Learning Rate = \"+str(learning_tf_rate.eval()))\n",
    "            #calculate validation AUC\n",
    "            valid_auc_ccssm, valid_opts_ccssm = sess.run([auc_ccssm,  opts_ccssm], feed_dict={x: valid_set_x, y: valid_set_y, y_taskid: valid_set_y_taskid, y_ccssm: valid_set_y_ccssm, seqlen_tf: valid_set_seqlen})\n",
    "            valid_auc_taskid, valid_opts_taskid = sess.run([auc, opts], feed_dict={x: valid_set_x, y: valid_set_y, y_taskid: valid_set_y_taskid, y_ccssm: valid_set_y_ccssm, seqlen_tf: valid_set_seqlen})\n",
    "            print(\"Valid_auc_taskid: \" + str(valid_opts_taskid) + \" Valid_auc_ccssm: \" + str(valid_opts_ccssm) + \" with k = \"+str(k_fold))\n",
    "            valid_taskid_list.append(valid_opts_taskid)\n",
    "            valid_ccssm_list.append(valid_opts_ccssm)\n",
    "            print(\"Optimization Finished!\")\n",
    "    \n",
    "        #calculate training AUC (it should take both validation and training sets)\n",
    "        train_auc_ccssm, train_opts_ccssm, train_auc_taskid, train_opts_taskid = sess.run([auc_ccssm,  opts_ccssm,auc, opts], feed_dict={x: training_x, y: training_y, y_taskid: training_y_taskid, y_ccssm: training_y_ccssm, seqlen_tf: training_seqlen})\n",
    "\n",
    "        print(\"Train_auc_taskid: \" + str(train_opts_taskid))\n",
    "        plot_train_auc_taskid.append(train_opts_taskid)\n",
    "        print(\"Train_auc_ccssm: \" + str(train_opts_ccssm))\n",
    "        plot_train_auc_ccssm.append(train_opts_ccssm)\n",
    "        \n",
    "        #take average of validation AUCs\n",
    "        valid_avg_ccssm = np.mean(valid_ccssm_list)\n",
    "        valid_avg_taskid = np.mean(valid_taskid_list)\n",
    "        \n",
    "        print(\"Average Valid_auc_taskid: \" + str(valid_avg_taskid))\n",
    "        plot_valid_auc_taskid.append(valid_avg_taskid)\n",
    "        print(\"Average Valid_auc_ccssm: \" + str(valid_avg_ccssm))\n",
    "        plot_valid_auc_ccssm.append(valid_avg_ccssm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting validation set ccssm auc across different learning rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1297f8470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1296642e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Training Set AUC\")\n",
    "plt.xlabel(\"Learning Rate Index\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.plot(plot_train_auc_taskid,'r--',label='taskid')\n",
    "plt.plot(plot_train_auc_ccssm,'g--',label='ccssm')\n",
    "plt.legend(loc='best', fancybox=True, framealpha=0.5)\n",
    "plt.show()\n",
    "\n",
    "plt.xlabel(\"Learning Rate Index\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.title(\"Validation Set AUC\")\n",
    "plt.plot(plot_valid_auc_taskid,label='taskid')\n",
    "plt.plot(plot_valid_auc_ccssm,label='ccssm')\n",
    "plt.legend(loc='best', fancybox=True, framealpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#http://www.wildml.com/2016/08/rnns-in-tensorflow-a-practical-guide-and-undocumented-features/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Training the model with hyperparameters chosen from above and calculating testing AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Learning Rate: 1.5\n",
      "Step 1, Loss = [0.934497], Learning Rate = 1.5\n",
      "Step 40, Loss = [0.8154692], Learning Rate = 1.5\n",
      "Step 80, Loss = [0.75667655], Learning Rate = 1.5\n",
      "Optimization Finished!\n",
      "Train_auc_taskid: 0.9942653\n",
      "Train_auc_ccssm: 0.9949387\n",
      "Testing auc for taskid: 0.9859248\n",
      "Testing auc for ccssm: 0.9883286\n"
     ]
    }
   ],
   "source": [
    "final_l_r = plot_lr[np.argmax(plot_valid_auc_taskid)]\n",
    "with tf.Session() as sess:\n",
    "    for l_r in [final_l_r]:\n",
    "        # Initialize the variables (i.e. assign their default value)\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sess.run(tf.local_variables_initializer())\n",
    "        assign_op = learning_tf_rate.assign(l_r)\n",
    "        sess.run(assign_op)\n",
    "        print(\"Final Learning Rate: \"+str(learning_tf_rate.eval()))\n",
    "        for step in range(1, training_steps+1):\n",
    "            sess.run(optimizer, feed_dict={x: training_x, y: training_y, y_taskid: training_y_taskid, y_ccssm: training_y_ccssm, seqlen_tf: training_seqlen})\n",
    "            \n",
    "            if step % display_step == 0 or step == 1:\n",
    "                loss= sess.run([cost], feed_dict={x: training_x, y: training_y, y_taskid: training_y_taskid, y_ccssm: training_y_ccssm, seqlen_tf: training_seqlen})\n",
    "                #print status\n",
    "                print(\"Step \" + str(step) + \", Loss = \" + str(loss) + \", Learning Rate = \"+str(learning_tf_rate.eval()))\n",
    "        print(\"Optimization Finished!\")\n",
    "    \n",
    "        #calculate training AUC\n",
    "        train_auc_ccssm, train_opts_ccssm = sess.run([auc_ccssm,  opts_ccssm], feed_dict={x: training_x, y: training_y, y_taskid: training_y_taskid, y_ccssm: training_y_ccssm, seqlen_tf: training_seqlen})\n",
    "        train_auc_taskid, train_opts_taskid = sess.run([auc, opts], feed_dict={x: training_x, y: training_y, y_taskid: training_y_taskid, y_ccssm: training_y_ccssm, seqlen_tf: training_seqlen})\n",
    "        print(\"Train_auc_taskid: \" + str(train_opts_taskid))\n",
    "        print(\"Train_auc_ccssm: \" + str(train_opts_ccssm))\n",
    "        \n",
    "    # Calculate test auc\n",
    "    temp_auc_ccssm, temp_opts_ccssm = sess.run([auc_ccssm,  opts_ccssm], feed_dict={x: test_x, y: test_y, y_taskid: test_y_taskid, y_ccssm: test_y_ccssm,seqlen_tf: test_seqlen})\n",
    "    temp_auc_taskid, temp_opts_taskid = sess.run([auc, opts], feed_dict={x: test_x, y: test_y, y_taskid: test_y_taskid, y_ccssm: test_y_ccssm,seqlen_tf: test_seqlen})\n",
    "    print(\"Testing auc for taskid: \" + str(temp_opts_taskid))\n",
    "    print(\"Testing auc for ccssm: \" + str(temp_opts_ccssm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
