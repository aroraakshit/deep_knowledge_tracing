{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T20:28:38.654074Z",
     "start_time": "2018-04-11T20:28:38.586443Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pprint as pp\n",
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from collections import Counter\n",
    "%matplotlib inline\n",
    "np.set_printoptions(threshold=np.nan)\n",
    "import pickle\n",
    "def save_obj(obj, name ):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f)\n",
    "        \n",
    "def load_obj(name ):\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T20:28:39.289115Z",
     "start_time": "2018-04-11T20:28:39.115915Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Loading data from file\n",
    "'''\n",
    "filepath = \"../data/student_vectors_n_task_10_n_limit_10000.json\"\n",
    "student_vectors = json.load(open(filepath))\n",
    "#filepath2 = \"../../../student_vectors_n_task_10_n_limit_100000.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T20:28:39.681180Z",
     "start_time": "2018-04-11T20:28:39.622966Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Generate one hot encoding from task IDs\n",
    "'''\n",
    "#Collect task IDs\n",
    "task_ids = []\n",
    "for i in student_vectors:\n",
    "    for j in student_vectors[i]:\n",
    "        if j['task_id'] not in task_ids:\n",
    "            task_ids.append(j['task_id'])\n",
    "\n",
    "#pre-processing for using MultiLabelBinarizer\n",
    "temp_ids = [[x] for x in task_ids]\n",
    "\n",
    "#generating encodings\n",
    "enc = MultiLabelBinarizer()\n",
    "task_ids_1hot = (enc.fit_transform(temp_ids)).astype(float)\n",
    "task_ids_dict = dict(zip(task_ids, task_ids_1hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T21:37:12.212206Z",
     "start_time": "2018-04-11T21:37:12.203369Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Split train and test student_vectors\n",
    "'''\n",
    "split = int(0.8*len(student_vectors))\n",
    "train_student_vectors = {}\n",
    "test_student_vectors = {}\n",
    "\n",
    "for idx,keys in enumerate(student_vectors):\n",
    "    if(idx < split):\n",
    "        train_student_vectors[keys] = student_vectors[keys]\n",
    "    else:\n",
    "        test_student_vectors[keys] = student_vectors[keys]\n",
    "length_interaction_vector = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T01:31:21.044990Z",
     "start_time": "2018-04-12T01:31:06.530135Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sequence length is: 56\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Gather Training Data from train_student_vectors\n",
    "train_X, train_Y, train_Seqlen\n",
    "'''\n",
    "train_sequences = {}\n",
    "train_sequences['overall'] = []\n",
    "incorrect_vec = np.zeros((len(task_ids)), dtype=np.float)\n",
    "temp_seqlen = {}\n",
    "temp_seqlen['overall'] = []\n",
    "\n",
    "for i in task_ids: #go per task IDs\n",
    "    train_sequences[i] = []\n",
    "    temp_seqlen[i] = []\n",
    "    for j in train_student_vectors: #go per student\n",
    "        temp = [] #one student sequence\n",
    "        temp.append(np.concatenate([incorrect_vec,incorrect_vec])) #for getting first output\n",
    "        for k in train_student_vectors[j]: #per question\n",
    "            if(k['second_try'] == False and k['task_id'] == i):\n",
    "                if(k['correct'] == True):\n",
    "                    temp.append(np.concatenate([task_ids_dict[k['task_id']],incorrect_vec]))\n",
    "                else:\n",
    "                    temp.append(np.concatenate([incorrect_vec,task_ids_dict[k['task_id']]]))\n",
    "        if(len(temp) > 1):\n",
    "            train_sequences['overall'].append(temp)\n",
    "            train_sequences[i].append(temp)\n",
    "            random.shuffle(train_sequences['overall'])\n",
    "            temp_seqlen['overall'].append(len(temp)-1)\n",
    "            temp_seqlen[i].append(len(temp)-1)\n",
    "\n",
    "print(\"Maximum sequence length is: \"+ str(max(temp_seqlen['overall'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T01:32:09.391216Z",
     "start_time": "2018-04-12T01:32:08.934969Z"
    }
   },
   "outputs": [],
   "source": [
    "'''continued\n",
    "Gather Training Data\n",
    "train_X, train_Y, train_Seqlen, train_mask\n",
    "'''\n",
    "train_X = {}\n",
    "train_Y = {}\n",
    "train_Seqlen = {}\n",
    "train_mask = {}\n",
    "\n",
    "for i in task_ids:\n",
    "    train_X[i] = np.zeros(shape=(len(train_sequences[i]),max(temp_seqlen[i]),len(train_sequences[i][0][0])),dtype=float)\n",
    "    train_Y[i] = np.zeros(shape=(len(train_sequences[i]),max(temp_seqlen[i]),len(train_sequences[i][0][0])),dtype=float)\n",
    "    train_Seqlen[i] = np.zeros(shape=(len(train_sequences[i])),dtype=int)\n",
    "    train_mask[i] = np.zeros(shape=(len(train_sequences[i]),1),dtype=int)\n",
    "    for idx, seq in enumerate(train_sequences[i]):\n",
    "        vec1 = np.concatenate([task_ids_dict[i],incorrect_vec])\n",
    "        vec2 = np.concatenate([incorrect_vec,task_ids_dict[i]])\n",
    "        if(train_sequences[i][idx][1].all() == vec1.all() or train_sequences[i][idx][1].all() == vec2.all()):\n",
    "            leng = len(train_sequences[i][idx])\n",
    "            train_Seqlen[i][idx] = leng-1\n",
    "            train_mask[i][idx] = [leng-1]\n",
    "            for pos in range(leng-1):\n",
    "                train_X[i][idx][pos] = train_sequences[i][idx][pos]\n",
    "                train_Y[i][idx][pos] = train_sequences[i][idx][pos+1]\n",
    "\n",
    "train_X['overall'] = np.zeros(shape =(len(train_sequences['overall']), max(temp_seqlen['overall']), len(train_sequences['overall'][0][0])),dtype=float)\n",
    "train_Y['overall'] = np.zeros(shape =(len(train_sequences['overall']), max(temp_seqlen['overall']), len(train_sequences['overall'][0][0])),dtype=float)\n",
    "train_Seqlen['overall'] = np.zeros(shape=(len(train_sequences['overall'])),dtype=int)\n",
    "train_mask['overall'] = np.zeros(shape=(len(train_sequences['overall']),1),dtype=int)\n",
    "\n",
    "for idx, seq in enumerate(train_sequences['overall']):\n",
    "    leng = len(seq)\n",
    "    train_Seqlen['overall'][idx] = leng-1\n",
    "    train_mask['overall'][idx] = [leng-1]\n",
    "    for pos in range(leng-1):\n",
    "        train_X['overall'][idx][pos] = train_sequences['overall'][idx][pos]\n",
    "        train_Y['overall'][idx][pos] = train_sequences['overall'][idx][pos+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T21:43:05.375101Z",
     "start_time": "2018-04-11T21:43:04.597157Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sequence length is: 39\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Gathering test data for evaluation metric 1 from test_student_vectors\n",
    "1) Input one skill at a time and get predictions for each separately\n",
    "a- calculate 10 separate AUCs\n",
    "b- concatenate separate predictions to calculate 1 AUC\n",
    "\n",
    "test_1_X, test_1_Y, test_1_Seqlen\n",
    "'''\n",
    "test_sequences = {}\n",
    "incorrect_vec = np.zeros((len(task_ids)), dtype=np.float)\n",
    "temp_seqlen = {}\n",
    "temp_seqlen['overall'] = []\n",
    "test_sequences['overall'] = []\n",
    "\n",
    "for i in task_ids: #go per task IDs\n",
    "    temp_seqlen[i] = []\n",
    "    test_sequences[i] = []\n",
    "    for j in test_student_vectors: #go per student\n",
    "        temp = [] #one student sequence\n",
    "        temp.append(np.concatenate([incorrect_vec,incorrect_vec])) #for getting first output\n",
    "        for k in test_student_vectors[j]: #per question\n",
    "            if(k['second_try'] == False and k['task_id'] == i):\n",
    "                if(k['correct'] == True):\n",
    "                    temp.append(np.concatenate([task_ids_dict[k['task_id']],incorrect_vec]))\n",
    "                else:\n",
    "                    temp.append(np.concatenate([incorrect_vec,task_ids_dict[k['task_id']]]))\n",
    "        if(len(temp) > 1):\n",
    "            test_sequences[i].append(temp)\n",
    "            test_sequences['overall'].append(temp)\n",
    "            random.shuffle(test_sequences['overall'])\n",
    "            temp_seqlen['overall'].append(len(temp)-1)\n",
    "            temp_seqlen[i].append(len(temp)-1)\n",
    "\n",
    "print(\"Maximum sequence length is: \"+ str(max(temp_seqlen['overall'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T21:43:59.746955Z",
     "start_time": "2018-04-11T21:43:59.580834Z"
    }
   },
   "outputs": [],
   "source": [
    "'''continued\n",
    "Gathering test data for evaluation metric 1\n",
    "test_1_X, test_1_Y, test_1_Seqlen\n",
    "'''\n",
    "test_1_X = {}\n",
    "test_1_Y = {}\n",
    "test_1_Seqlen = {}\n",
    "test_1_mask = {}\n",
    "\n",
    "for i in task_ids:\n",
    "    test_1_X[i] = np.zeros(shape=(len(test_sequences[i]),max(temp_seqlen[i]),len(test_sequences[i][0][0])),dtype=float)\n",
    "    test_1_Y[i] = np.zeros(shape=(len(test_sequences[i]),max(temp_seqlen[i]),len(test_sequences[i][0][0])),dtype=float)\n",
    "    test_1_Seqlen[i] = np.zeros(shape=(len(test_sequences[i])),dtype=int)\n",
    "    test_1_mask[i] = np.zeros(shape=(len(test_sequences[i]),1),dtype=int)\n",
    "\n",
    "    for idx, seq in enumerate(test_sequences[i]): #go per student\n",
    "        vec1 = np.concatenate([task_ids_dict[i],incorrect_vec])\n",
    "        vec2 = np.concatenate([incorrect_vec,task_ids_dict[i]])\n",
    "        if(test_sequences[i][idx][1].all() == vec1.all() or test_sequences[i][idx][1].all() == vec2.all()):\n",
    "            leng = len(test_sequences[i][idx])\n",
    "            test_1_Seqlen[i][idx] = leng-1\n",
    "            test_1_mask[i][idx] = [leng-1]\n",
    "            for pos in range(leng-1):\n",
    "                test_1_X[i][idx][pos] = test_sequences[i][idx][pos]\n",
    "                test_1_Y[i][idx][pos] = test_sequences[i][idx][pos+1]\n",
    "\n",
    "test_1_X['overall'] = np.zeros(shape=(len(test_sequences['overall']),max(temp_seqlen['overall']),len(test_sequences['overall'][0][0])),dtype=float)\n",
    "test_1_Y['overall'] = np.zeros(shape=(len(test_sequences['overall']),max(temp_seqlen['overall']),len(test_sequences['overall'][0][0])),dtype=float)\n",
    "test_1_Seqlen['overall'] = np.zeros(shape=(len(test_sequences['overall'])),dtype=int)\n",
    "test_1_mask['overall'] = np.zeros(shape=(len(test_sequences['overall']),1),dtype=int)\n",
    "for idx, seq in enumerate(test_sequences['overall']):\n",
    "    leng = len(seq)\n",
    "    test_1_Seqlen['overall'][idx] = leng-1\n",
    "    test_1_mask['overall'][idx] = [leng-1]\n",
    "    for pos in range(leng-1):\n",
    "        test_1_X['overall'][idx][pos] = test_sequences['overall'][idx][pos]\n",
    "        test_1_Y['overall'][idx][pos] = test_sequences['overall'][idx][pos+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T21:44:38.145957Z",
     "start_time": "2018-04-11T21:44:38.054892Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sequence length is: 85\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Gathering test data for evaluation metric 2 from test_student_vectors\n",
    "2) Input the natural sequence of students and get predictions for the same\n",
    "a- calculate 1 AUC with natural sequence predictions\n",
    "b- filter predictions per skill, and calculate 10 separate AUCs\n",
    "\n",
    "test_2_X, test_2_Y, test_2_Seqlen\n",
    "'''\n",
    "test_sequences_2 = {}\n",
    "incorrect_vec = np.zeros((len(task_ids)), dtype=np.float)\n",
    "temp_seqlen = {}\n",
    "temp_seqlen['overall'] = []\n",
    "test_sequences_2['overall'] = []\n",
    "\n",
    "#first lets get a natural sequence in overall!, rest part will be done after getting predictions from the model\n",
    "for j in test_student_vectors: #go per student\n",
    "    temp = [] #one student sequence\n",
    "    temp.append(np.concatenate([incorrect_vec,incorrect_vec])) #for getting first output\n",
    "    for k in test_student_vectors[j]: #per question\n",
    "        if(k['second_try'] == False):\n",
    "            if(k['correct'] == True):\n",
    "                temp.append(np.concatenate([task_ids_dict[k['task_id']],incorrect_vec]))\n",
    "            else:\n",
    "                temp.append(np.concatenate([incorrect_vec,task_ids_dict[k['task_id']]]))\n",
    "    if(len(temp) > 1):\n",
    "        test_sequences_2['overall'].append(temp)\n",
    "        random.shuffle(test_sequences_2['overall'])\n",
    "        temp_seqlen['overall'].append(len(temp)-1)\n",
    "\n",
    "print(\"Maximum sequence length is: \"+ str(max(temp_seqlen['overall'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T21:45:24.590861Z",
     "start_time": "2018-04-11T21:45:24.550677Z"
    }
   },
   "outputs": [],
   "source": [
    "'''continued\n",
    "Gathering test data for evaluation metric 2\n",
    "test_2_X, test_2_Y, test_2_Seqlen\n",
    "'''\n",
    "test_2_X = {}\n",
    "test_2_Y = {}\n",
    "test_2_Seqlen = {}\n",
    "test_2_mask = {}\n",
    "\n",
    "test_2_X['overall'] = np.zeros(shape=(len(test_sequences_2['overall']),max(temp_seqlen['overall']),len(test_sequences_2['overall'][0][0])),dtype=float)\n",
    "test_2_Y['overall'] = np.zeros(shape=(len(test_sequences_2['overall']),max(temp_seqlen['overall']),len(test_sequences_2['overall'][0][0])),dtype=float)\n",
    "test_2_Seqlen['overall'] = np.zeros(shape=(len(test_sequences_2['overall'])),dtype=int)\n",
    "test_2_mask['overall'] = np.zeros(shape=(len(test_sequences_2['overall']),1),dtype=int)\n",
    "for idx, seq in enumerate(test_sequences_2['overall']):\n",
    "    leng = len(seq)\n",
    "    test_2_Seqlen['overall'][idx] = leng-1\n",
    "    test_2_mask['overall'][idx] = [leng-1]\n",
    "    for pos in range(leng-1):\n",
    "        test_2_X['overall'][idx][pos] = test_sequences_2['overall'][idx][pos]\n",
    "        test_2_Y['overall'][idx][pos] = test_sequences_2['overall'][idx][pos+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T18:08:19.312642Z",
     "start_time": "2018-04-12T18:08:19.154013Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "let's define AUC functions\n",
    "'''\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "def calculate_auc (y_true, y_pred, sequence_lengths=[], plot=False, debug=False, idx = 0):\n",
    "    if sequence_lengths == []:\n",
    "        con1_y_true = np.zeros([len(y_true)])\n",
    "        con1_y_pred = np.zeros([len(y_true)])\n",
    "        index_two = idx\n",
    "        right = 0\n",
    "        index_one = index_two + int(length_interaction_vector/2)\n",
    "        for i in range(len(y_true)): #go up to sequence length\n",
    "            if(np.argmax(y_true[i]) == index_one):\n",
    "                print(\"incorrect true label\")\n",
    "                con1_y_true[i] = 0.\n",
    "                con1_y_pred[i] = 1.0 - y_pred[i][index_one]\n",
    "            elif (np.argmax(y_true[i]) == index_two):\n",
    "                print(\"correct true label\")\n",
    "                right += 1\n",
    "                con1_y_true[i] = 1.\n",
    "                con1_y_pred[i] = y_pred[i][index_two]\n",
    "        return [roc_auc_score(con1_y_true, con1_y_pred),con1_y_pred,con1_y_true, (right/len(y_true))]\n",
    "    else:\n",
    "        con_y_true = np.zeros([sum(sequence_lengths), length_interaction_vector])\n",
    "        con_y_pred = np.zeros([sum(sequence_lengths), length_interaction_vector],dtype=np.float)\n",
    "        index = 0\n",
    "        for i in range(len(y_true)): #per sequence\n",
    "            for j in range(sequence_lengths[i]): #up to the sequence length\n",
    "                con_y_true[index] = y_true[i][j]\n",
    "                con_y_pred[index] = y_pred[i][j]\n",
    "                index += 1\n",
    "        con1_y_true = np.zeros([sum(sequence_lengths)])\n",
    "        con1_y_pred = np.zeros([sum(sequence_lengths)])\n",
    "        right = 0\n",
    "        for l in range(sum(sequence_lengths)): # go per interaction vector\n",
    "            index_one = np.argmax(con_y_true[l]) #detect its indices!, index_two => correct\n",
    "            if(index_one >= int(length_interaction_vector/2)):\n",
    "                index_two = index_one - int(length_interaction_vector/2)\n",
    "            else:\n",
    "                index_two = index_one\n",
    "                index_one = index_one + int(length_interaction_vector/2)\n",
    "            if(np.argmax(con_y_true[l]) == index_one): #true is incorrect\n",
    "                con1_y_true[l] = 0.\n",
    "                con1_y_pred[l] = 1.0 - con_y_pred[l][index_one]\n",
    "            elif(np.argmax(con_y_true[l]) == index_two):\n",
    "                right += 1\n",
    "                con1_y_true[l] = 1.\n",
    "                con1_y_pred[l] = con_y_pred[l][index_two]\n",
    "        debug=False\n",
    "        if(debug):\n",
    "            print(np.c_[con1_y_true,con1_y_pred])\n",
    "        fpr, tpr, thresholds = roc_curve(con1_y_true, con1_y_pred)\n",
    "        #print(\"tpr: \"+str(tpr) + \", fpr: \"+str(fpr) + \", thresholds: \"+str(thresholds))\n",
    "        if(plot):\n",
    "            return [roc_auc_score(con1_y_true, con1_y_pred),fpr,tpr]\n",
    "        else:\n",
    "            return [roc_auc_score(con1_y_true, con1_y_pred),(right)/sum(sequence_lengths)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T00:40:23.534832Z",
     "start_time": "2018-04-12T00:40:23.531931Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Filter Predictions per skill and calculate separate AUCs\n",
    "For evaluation algorithm 2b\n",
    "'''\n",
    "def extract_2(true, predictions):\n",
    "    print(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T21:31:38.455361Z",
     "start_time": "2018-04-11T21:31:38.440375Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "load and save model functions\n",
    "'''\n",
    "def loadmodel(session, saver, checkpoint_dir):\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n",
    "        saver.restore(session, os.path.join(checkpoint_dir, ckpt_name))\n",
    "        print(\"Model restored successfully\")\n",
    "        return int(ckpt_name[6:])\n",
    "    else:\n",
    "        print(\"No pre-trained model exists, starting from the beginning!\")\n",
    "        return 0\n",
    "\n",
    "def save(session, saver, checkpoint_dir, step):\n",
    "    dir1 = os.path.join(checkpoint_dir, \"model\")\n",
    "    saver.save(session, dir1, global_step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T17:35:21.914952Z",
     "start_time": "2018-04-12T17:35:21.124254Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Build the model\n",
    "'''\n",
    "num_units = 50\n",
    "lr = 0.001\n",
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(1234)\n",
    "\n",
    "#defining placeholders\n",
    "x = tf.placeholder(tf.float32, [None, None, length_interaction_vector])\n",
    "y = tf.placeholder(tf.float32, [None, None, length_interaction_vector])\n",
    "seqlen_tf = tf.placeholder(tf.float32,[None])\n",
    "\n",
    "#variables\n",
    "converged = tf.Variable(0,trainable=False)\n",
    "\n",
    "#dynamic RNN definition\n",
    "def dynamicRNN(x):\n",
    "    rnn_cell = tf.nn.rnn_cell.BasicLSTMCell(num_units)\n",
    "    outputs, states = tf.nn.dynamic_rnn(rnn_cell, x, dtype=tf.float32,sequence_length=seqlen_tf)\n",
    "    out_size = int(length_interaction_vector / 2)\n",
    "    outputs = tf.contrib.layers.fully_connected(outputs, out_size, activation_fn = tf.nn.sigmoid, weights_initializer=tf.contrib.layers.xavier_initializer(uniform=False))\n",
    "    opposites = tf.subtract(tf.ones(tf.shape(outputs)),outputs)\n",
    "    outputs1 = tf.concat([outputs,opposites],2)\n",
    "    return outputs1\n",
    "\n",
    "#making predictions\n",
    "pred = dynamicRNN(x)\n",
    "pred = pred*y\n",
    "# Define loss and optimizer\n",
    "cost1 = tf.nn.sigmoid_cross_entropy_with_logits(logits=pred, labels=y)\n",
    "mask = tf.cast(tf.sequence_mask(lengths = train_mask['overall'], maxlen = max(train_Seqlen['overall'])), tf.float32)\n",
    "cost1 = tf.multiply(cost1,tf.transpose(mask, perm=[0, 2, 1]))\n",
    "cost1 = tf.reduce_sum(cost1, 1)\n",
    "cost1 /= tf.cast(train_mask['overall'],tf.float32)\n",
    "cost = tf.reduce_mean(cost1)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=lr).minimize(cost)\n",
    "\n",
    "saver = tf.train.Saver(max_to_keep=5)\n",
    "saver_url = 'saved_models/4_combined_model_D_small/model.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T17:22:22.514329Z",
     "start_time": "2018-04-12T17:22:22.317642Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "All the recorders\n",
    "'''\n",
    "predictions = {}\n",
    "for i in ['train','test1','test2']:\n",
    "    predictions[i] = {}\n",
    "    for j in task_ids:\n",
    "        predictions[i][j] = []\n",
    "    predictions[i]['overall'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T17:46:16.241953Z",
     "start_time": "2018-04-12T17:40:37.021207Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No pre-trained model exists, starting from the beginning!\n",
      "converged = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:10: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC (similar to 1b): 0.532386272530059\n",
      "Training AUC (similar to 1a): \n",
      "p7cfRPp-kQ.partb: 0.4176430607416092\n",
      "Ok-iIHxjgx.partb: 0.6774267332132992\n",
      "1zsCldT4p8.set1: 0.5169500183186315\n",
      "DebcfZEEmI.proper_fractions: 0.45470743595275087\n",
      "9wRCzK1G7F.partb: 0.5237828389792547\n",
      "1zsCldT4p8.set2: 0.44822613216577506\n",
      "nl-M69Ez9k.parta: 0.6716490562794464\n",
      "kvig7fcCVc.partb: 0.34885097958241734\n",
      "Ok-iIHxjgx.parta: 0.32306255835667597\n",
      "hyei4uD81i.parta: 0.36158862072454967\n",
      "Test AUC 1b: 0.5160816973115523\n",
      "Test AUC 1a: \n",
      "p7cfRPp-kQ.partb: 0.5244224872674359\n",
      "Ok-iIHxjgx.partb: 0.7043184289209025\n",
      "1zsCldT4p8.set1: 0.41515326009922043\n",
      "DebcfZEEmI.proper_fractions: 0.418241458677624\n",
      "9wRCzK1G7F.partb: 0.5216552056942936\n",
      "1zsCldT4p8.set2: 0.48960964753999764\n",
      "nl-M69Ez9k.parta: 0.634175342670961\n",
      "kvig7fcCVc.partb: 0.31746651785714286\n",
      "Ok-iIHxjgx.parta: 0.32078858641358643\n",
      "hyei4uD81i.parta: 0.4570061226071457\n",
      "Test AUC 2a: 0.49738922953193365\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training AUC (similar to 1b): 0.5718729854580326\n",
      "Training AUC (similar to 1a): \n",
      "p7cfRPp-kQ.partb: 0.5248331612908708\n",
      "Ok-iIHxjgx.partb: 0.6178563538935841\n",
      "1zsCldT4p8.set1: 0.5491068838267207\n",
      "DebcfZEEmI.proper_fractions: 0.5768351649545497\n",
      "9wRCzK1G7F.partb: 0.393247896441869\n",
      "1zsCldT4p8.set2: 0.49121903266958206\n",
      "nl-M69Ez9k.parta: 0.6002393484721025\n",
      "kvig7fcCVc.partb: 0.5599419821614378\n",
      "Ok-iIHxjgx.parta: 0.7412348272642391\n",
      "hyei4uD81i.parta: 0.6404226118194697\n",
      "Test AUC 1b: 0.5869852882728567\n",
      "Test AUC 1a: \n",
      "p7cfRPp-kQ.partb: 0.6228302671239996\n",
      "Ok-iIHxjgx.partb: 0.674289888556673\n",
      "1zsCldT4p8.set1: 0.4702117292700213\n",
      "DebcfZEEmI.proper_fractions: 0.59534127843987\n",
      "9wRCzK1G7F.partb: 0.38970144699211573\n",
      "1zsCldT4p8.set2: 0.5228166726813425\n",
      "nl-M69Ez9k.parta: 0.5618212118942402\n",
      "kvig7fcCVc.partb: 0.6345982142857143\n",
      "Ok-iIHxjgx.parta: 0.741165084915085\n",
      "hyei4uD81i.parta: 0.6324013795241415\n",
      "Test AUC 2a: 0.5782289155030338\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training AUC (similar to 1b): 0.5570414754976809\n",
      "Training AUC (similar to 1a): \n",
      "p7cfRPp-kQ.partb: 0.5210555902472456\n",
      "Ok-iIHxjgx.partb: 0.6014875244613612\n",
      "1zsCldT4p8.set1: 0.5533553971993217\n",
      "DebcfZEEmI.proper_fractions: 0.5410105900867413\n",
      "9wRCzK1G7F.partb: 0.4093394890181365\n",
      "1zsCldT4p8.set2: 0.4943396086089922\n",
      "nl-M69Ez9k.parta: 0.5600173456020043\n",
      "kvig7fcCVc.partb: 0.5638914868032697\n",
      "Ok-iIHxjgx.parta: 0.6786998132586368\n",
      "hyei4uD81i.parta: 0.6149311880186198\n",
      "Test AUC 1b: 0.5940211982755531\n",
      "Test AUC 1a: \n",
      "p7cfRPp-kQ.partb: 0.6226418771437481\n",
      "Ok-iIHxjgx.partb: 0.6515867083446588\n",
      "1zsCldT4p8.set1: 0.4749955705173635\n",
      "DebcfZEEmI.proper_fractions: 0.5612109380850862\n",
      "9wRCzK1G7F.partb: 0.40108435701461187\n",
      "1zsCldT4p8.set2: 0.523189582581499\n",
      "nl-M69Ez9k.parta: 0.5249201058597359\n",
      "kvig7fcCVc.partb: 0.6466517857142857\n",
      "Ok-iIHxjgx.parta: 0.675792957042957\n",
      "hyei4uD81i.parta: 0.6256490738587925\n",
      "Test AUC 2a: 0.5823812981513317\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training AUC (similar to 1b): 0.5373003030141064\n",
      "Training AUC (similar to 1a): \n",
      "p7cfRPp-kQ.partb: 0.5231545082913139\n",
      "Ok-iIHxjgx.partb: 0.5737760522050904\n",
      "1zsCldT4p8.set1: 0.5540458686927128\n",
      "DebcfZEEmI.proper_fractions: 0.5233446344957312\n",
      "9wRCzK1G7F.partb: 0.4141090024762499\n",
      "1zsCldT4p8.set2: 0.4879860232496688\n",
      "nl-M69Ez9k.parta: 0.5530817092449974\n",
      "kvig7fcCVc.partb: 0.5743209321721668\n",
      "Ok-iIHxjgx.parta: 0.6454248366013072\n",
      "hyei4uD81i.parta: 0.5747286733454766\n",
      "Test AUC 1b: 0.5747231615016903\n",
      "Test AUC 1a: \n",
      "p7cfRPp-kQ.partb: 0.6227653050618438\n",
      "Ok-iIHxjgx.partb: 0.6125611579233488\n",
      "1zsCldT4p8.set1: 0.4764572997873848\n",
      "DebcfZEEmI.proper_fractions: 0.5452241987907595\n",
      "9wRCzK1G7F.partb: 0.4093979973458801\n",
      "1zsCldT4p8.set2: 0.5181252255503428\n",
      "nl-M69Ez9k.parta: 0.5091098045090255\n",
      "kvig7fcCVc.partb: 0.65546875\n",
      "Ok-iIHxjgx.parta: 0.6438561438561439\n",
      "hyei4uD81i.parta: 0.6010423932418817\n",
      "Test AUC 2a: 0.5807843552884443\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training AUC (similar to 1b): 0.533739509984724\n",
      "Training AUC (similar to 1a): \n",
      "p7cfRPp-kQ.partb: 0.5275650256789305\n",
      "Ok-iIHxjgx.partb: 0.5653091466430509\n",
      "1zsCldT4p8.set1: 0.5596823706795798\n",
      "DebcfZEEmI.proper_fractions: 0.519866985654844\n",
      "9wRCzK1G7F.partb: 0.42021306141171333\n",
      "1zsCldT4p8.set2: 0.4955459717315106\n",
      "nl-M69Ez9k.parta: 0.5482285869064145\n",
      "kvig7fcCVc.partb: 0.5786267222147997\n",
      "Ok-iIHxjgx.parta: 0.6268674136321195\n",
      "hyei4uD81i.parta: 0.6216700819672132\n",
      "Test AUC 1b: 0.5748999177053509\n",
      "Test AUC 1a: \n",
      "p7cfRPp-kQ.partb: 0.6231355888161314\n",
      "Ok-iIHxjgx.partb: 0.620790296276162\n",
      "1zsCldT4p8.set1: 0.47665662650602414\n",
      "DebcfZEEmI.proper_fractions: 0.5434193248822963\n",
      "9wRCzK1G7F.partb: 0.4112963317791829\n",
      "1zsCldT4p8.set2: 0.5182876217971851\n",
      "nl-M69Ez9k.parta: 0.5039978278780616\n",
      "kvig7fcCVc.partb: 0.6577008928571428\n",
      "Ok-iIHxjgx.parta: 0.6300262237762239\n",
      "hyei4uD81i.parta: 0.6109625668449197\n",
      "Test AUC 2a: 0.573029097704634\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training AUC (similar to 1b): 0.5347243501784167\n",
      "Training AUC (similar to 1a): \n",
      "p7cfRPp-kQ.partb: 0.5275085277837958\n",
      "Ok-iIHxjgx.partb: 0.5740380160345323\n",
      "1zsCldT4p8.set1: 0.559881409655991\n",
      "DebcfZEEmI.proper_fractions: 0.5211502004410792\n",
      "9wRCzK1G7F.partb: 0.41899296633948635\n",
      "1zsCldT4p8.set2: 0.49946670656524034\n",
      "nl-M69Ez9k.parta: 0.5293109420537088\n",
      "kvig7fcCVc.partb: 0.5784495916888334\n",
      "Ok-iIHxjgx.parta: 0.634360410830999\n",
      "hyei4uD81i.parta: 0.6558989829993929\n",
      "Test AUC 1b: 0.5834780243673209\n",
      "Test AUC 1a: \n",
      "p7cfRPp-kQ.partb: 0.6291997973183661\n",
      "Ok-iIHxjgx.partb: 0.6376291111715141\n",
      "1zsCldT4p8.set1: 0.48332299787384836\n",
      "DebcfZEEmI.proper_fractions: 0.5438711674513583\n",
      "9wRCzK1G7F.partb: 0.40881607800557795\n",
      "1zsCldT4p8.set2: 0.5191537351136774\n",
      "nl-M69Ez9k.parta: 0.49674181709235266\n",
      "kvig7fcCVc.partb: 0.6573660714285714\n",
      "Ok-iIHxjgx.parta: 0.6312437562437563\n",
      "hyei4uD81i.parta: 0.6350073626288459\n",
      "Test AUC 2a: 0.5814095043306\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training AUC (similar to 1b): 0.5388713086392635\n",
      "Training AUC (similar to 1a): \n",
      "p7cfRPp-kQ.partb: 0.5232125637725301\n",
      "Ok-iIHxjgx.partb: 0.5882505312587363\n",
      "1zsCldT4p8.set1: 0.5602084096609644\n",
      "DebcfZEEmI.proper_fractions: 0.5237454390536512\n",
      "9wRCzK1G7F.partb: 0.42530162497177937\n",
      "1zsCldT4p8.set2: 0.5029075210561222\n",
      "nl-M69Ez9k.parta: 0.5287015019832846\n",
      "kvig7fcCVc.partb: 0.5748442263545931\n",
      "Ok-iIHxjgx.parta: 0.6352591036414565\n",
      "hyei4uD81i.parta: 0.6704140103217973\n",
      "Test AUC 1b: 0.5872908246921353\n",
      "Test AUC 1a: \n",
      "p7cfRPp-kQ.partb: 0.6227815455773829\n",
      "Ok-iIHxjgx.partb: 0.6532243816254417\n",
      "1zsCldT4p8.set1: 0.48866052445074415\n",
      "DebcfZEEmI.proper_fractions: 0.5453065789276603\n",
      "9wRCzK1G7F.partb: 0.40969960188201227\n",
      "1zsCldT4p8.set2: 0.5217430530494407\n",
      "nl-M69Ez9k.parta: 0.498267920005992\n",
      "kvig7fcCVc.partb: 0.6465401785714286\n",
      "Ok-iIHxjgx.parta: 0.6348026973026973\n",
      "hyei4uD81i.parta: 0.6068937456405487\n",
      "Test AUC 2a: 0.583872742547113\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training AUC (similar to 1b): 0.5403300661551962\n",
      "Training AUC (similar to 1a): \n",
      "p7cfRPp-kQ.partb: 0.5220038769733554\n",
      "Ok-iIHxjgx.partb: 0.5812244267586276\n",
      "1zsCldT4p8.set1: 0.5620448317421266\n",
      "DebcfZEEmI.proper_fractions: 0.5222315579463287\n",
      "9wRCzK1G7F.partb: 0.4152669449312133\n",
      "1zsCldT4p8.set2: 0.5004258910243958\n",
      "nl-M69Ez9k.parta: 0.5302232790480232\n",
      "kvig7fcCVc.partb: 0.5713967602320713\n",
      "Ok-iIHxjgx.parta: 0.63828197945845\n",
      "hyei4uD81i.parta: 0.6813872444849219\n",
      "Test AUC 1b: 0.5902637773399814\n",
      "Test AUC 1a: \n",
      "p7cfRPp-kQ.partb: 0.6223462997609397\n",
      "Ok-iIHxjgx.partb: 0.6465581679804294\n",
      "1zsCldT4p8.set1: 0.47853915662650603\n",
      "DebcfZEEmI.proper_fractions: 0.5443230100204203\n",
      "9wRCzK1G7F.partb: 0.4143833429137127\n",
      "1zsCldT4p8.set2: 0.5218633465656202\n",
      "nl-M69Ez9k.parta: 0.5000530547025192\n",
      "kvig7fcCVc.partb: 0.6482142857142857\n",
      "Ok-iIHxjgx.parta: 0.6375811688311689\n",
      "hyei4uD81i.parta: 0.6274703557312252\n",
      "Test AUC 2a: 0.5848149714696298\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training AUC (similar to 1b): 0.5429083430854036\n",
      "Training AUC (similar to 1a): \n",
      "p7cfRPp-kQ.partb: 0.5222430372362192\n",
      "Ok-iIHxjgx.partb: 0.587818486435552\n",
      "1zsCldT4p8.set1: 0.5588842461427261\n",
      "DebcfZEEmI.proper_fractions: 0.5227135516172638\n",
      "9wRCzK1G7F.partb: 0.4151935936441726\n",
      "1zsCldT4p8.set2: 0.5026725919548376\n",
      "nl-M69Ez9k.parta: 0.5355066556585468\n",
      "kvig7fcCVc.partb: 0.568994870299968\n",
      "Ok-iIHxjgx.parta: 0.6419876283846871\n",
      "hyei4uD81i.parta: 0.6845179366524995\n",
      "Test AUC 1b: 0.5928810257840982\n",
      "Test AUC 1a: \n",
      "p7cfRPp-kQ.partb: 0.6231096039912691\n",
      "Ok-iIHxjgx.partb: 0.6492695025822234\n",
      "1zsCldT4p8.set1: 0.47282512402551385\n",
      "DebcfZEEmI.proper_fractions: 0.5445776395344774\n",
      "9wRCzK1G7F.partb: 0.4147665580890336\n",
      "1zsCldT4p8.set2: 0.5213460844460484\n",
      "nl-M69Ez9k.parta: 0.5041351459316405\n",
      "kvig7fcCVc.partb: 0.6426339285714286\n",
      "Ok-iIHxjgx.parta: 0.640827922077922\n",
      "hyei4uD81i.parta: 0.6268212818724328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUC 2a: 0.5877458903330284\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-347-0c2ed96baa53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstop\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# train on train_X['overall']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'overall'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'overall'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseqlen_tf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_Seqlen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'overall'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdisplay_step\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "Training the model\n",
    "'''\n",
    "display_step = 20\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    cost_prev = 1.0\n",
    "    stop = False\n",
    "    step = loadmodel(sess, saver,saver_url)\n",
    "    print(\"converged = \"+str(converged.eval()))\n",
    "    if(sess.run(converged) == 1):\n",
    "        print(\"Model has already converged! Stop training\")\n",
    "        stop = True\n",
    "        \n",
    "    \n",
    "    while(stop == False):\n",
    "        # train on train_X['overall']\n",
    "        sess.run(optimizer, feed_dict={x: train_X['overall'], y: train_Y['overall'], seqlen_tf: train_Seqlen['overall']})\n",
    "        step += 1\n",
    "        if step % display_step == 0 or step == 1:\n",
    "            # first lets check convergence\n",
    "            loss = sess.run(cost, feed_dict={x: train_X['overall'], y: train_Y['overall'], seqlen_tf: train_Seqlen['overall']})\n",
    "            cost_current = loss\n",
    "            if cost_prev - cost_current <= 0.00005:\n",
    "                stop = True\n",
    "                sess.run(converged.assign(1))\n",
    "                print(\"Model has converged!\")\n",
    "            else:\n",
    "                cost_prev = cost_current\n",
    "                \n",
    "            # save the model\n",
    "            #save(sess, saver, saver_url, step)\n",
    "\n",
    "            # report the AUC scores till now\n",
    "            # train AUC\n",
    "            predict = sess.run(pred, feed_dict={x: train_X['overall'], y: train_Y['overall'], seqlen_tf: train_Seqlen['overall']})\n",
    "            predictions['train']['overall'].append(predict)\n",
    "            print(\"Training AUC (similar to 1b): \"+str(calculate_auc(train_Y['overall'], predict, train_Seqlen['overall'])))\n",
    "            print(\"Training AUC (similar to 1a): \")\n",
    "            for i in task_ids:\n",
    "                predict = sess.run(pred, feed_dict={x: train_X[i], y: train_Y[i], seqlen_tf: train_Seqlen[i]})\n",
    "                predictions['train'][i].append(predict)\n",
    "                print(str(i)+\": \"+str(calculate_auc(train_Y[i], predict, sequence_lengths= train_Seqlen[i])))\n",
    "            \n",
    "            # test AUC 1\n",
    "            predict = sess.run(pred, feed_dict={x: test_1_X['overall'], y: test_1_Y['overall'], seqlen_tf: test_1_Seqlen['overall']})\n",
    "            predictions['test1']['overall'].append(predict)\n",
    "            print(\"Test AUC 1b: \"+str(calculate_auc(test_1_Y['overall'], predict, test_1_Seqlen['overall'])))\n",
    "            print(\"Test AUC 1a: \")\n",
    "            for i in task_ids:\n",
    "                predict = sess.run(pred, feed_dict={x: test_1_X[i], y: test_1_Y[i], seqlen_tf: test_1_Seqlen[i]})\n",
    "                predictions['test1'][i].append(predict)\n",
    "                print(str(i)+\": \"+str(calculate_auc(test_1_Y[i], predict, test_1_Seqlen[i])))\n",
    "            \n",
    "            # test AUC 2\n",
    "            predict = sess.run(pred, feed_dict={x: test_2_X['overall'], y: test_2_Y['overall'], seqlen_tf: test_2_Seqlen['overall']})\n",
    "            predictions['test2']['overall'].append(predict)\n",
    "            print(\"Test AUC 2a: \"+str(calculate_auc(test_2_Y['overall'], predict, test_2_Seqlen['overall'])))\n",
    "#             print(\"Test AUC 2b: \")\n",
    "            #extract_2(test_2_Y['overall'], predict)\n",
    "            print(\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T18:10:40.295716Z",
     "start_time": "2018-04-12T18:10:40.289266Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.2713712e-01, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [8.9657325e-01, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [9.9700743e-01, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [9.9987400e-01, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 5.3286552e-05, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 4.0292740e-05, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 3.5643578e-05, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 3.3855438e-05, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 3.3259392e-05, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions['test1']['1zsCldT4p8.set1'][-1][5][:test_1_Seqlen['1zsCldT4p8.set1'][5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T18:10:31.138161Z",
     "start_time": "2018-04-12T18:10:31.131768Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_1_Y['1zsCldT4p8.set1'][5][:test_1_Seqlen['1zsCldT4p8.set1'][5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T01:47:35.597536Z",
     "start_time": "2018-04-12T01:47:35.590152Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(test_1_Seqlen['1zsCldT4p8.set2'][:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T01:47:43.606874Z",
     "start_time": "2018-04-12T01:47:43.597288Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_1_Seqlen['1zsCldT4p8.set2'][9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T18:10:13.044619Z",
     "start_time": "2018-04-12T18:10:13.033793Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct true label\n",
      "correct true label\n",
      "correct true label\n",
      "correct true label\n",
      "incorrect true label\n",
      "incorrect true label\n",
      "incorrect true label\n",
      "incorrect true label\n",
      "incorrect true label\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0, array([0.62713712, 0.89657325, 0.99700743, 0.999874  , 0.99994671,\n",
       "        0.99995971, 0.99996436, 0.99996614, 0.99996674]), array([1., 1., 1., 1., 0., 0., 0., 0., 0.]), 0.4444444444444444]"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pat = 5\n",
    "calculate_auc(test_1_Y['1zsCldT4p8.set1'][pat][:test_1_Seqlen['1zsCldT4p8.set1'][pat]], predictions['test1']['1zsCldT4p8.set1'][-1][pat][:test_1_Seqlen['1zsCldT4p8.set1'][pat]], idx = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T17:51:15.686513Z",
     "start_time": "2018-04-12T17:51:15.681389Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p7cfRPp-kQ.partb\n",
      "Ok-iIHxjgx.partb\n",
      "1zsCldT4p8.set1\n",
      "DebcfZEEmI.proper_fractions\n",
      "9wRCzK1G7F.partb\n",
      "1zsCldT4p8.set2\n",
      "nl-M69Ez9k.parta\n",
      "kvig7fcCVc.partb\n",
      "Ok-iIHxjgx.parta\n",
      "hyei4uD81i.parta\n"
     ]
    }
   ],
   "source": [
    "for i in task_ids:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
